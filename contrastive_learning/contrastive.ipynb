{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on device: CUDA\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model, model_selection\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.nn.utils import prune\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Running on device:\", DEVICE.upper())\n",
    "\n",
    "# manual random seed is used for dataset partitioning\n",
    "# to ensure reproducible results across runs\n",
    "SEED = 42\n",
    "RNG = torch.Generator().manual_seed(SEED)\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "\n",
    "# Create an unverified SSL context\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download and pre-process CIFAR10\n",
    "normalize = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "train_set = torchvision.datasets.CIFAR10(\n",
    "    root=\"../example notebooks/data\", train=True, download=False, transform=normalize\n",
    ")\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=1)\n",
    "\n",
    "# we split held out data into test and validation set\n",
    "held_out = torchvision.datasets.CIFAR10(\n",
    "    root=\"../example notebooks/data\", train=False, download=False, transform=normalize\n",
    ")\n",
    "test_set, val_set = torch.utils.data.random_split(held_out, [0.5, 0.5], generator=RNG)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=True, num_workers=1)\n",
    "val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=True, num_workers=1)\n",
    "\n",
    "# download the forget and retain index split\n",
    "local_path = \"../example notebooks/forget_idx.npy\"\n",
    "# if not os.path.exists(local_path):\n",
    "#     response = requests.get(\n",
    "#         \"https://storage.googleapis.com/unlearning-challenge/\" + local_path\n",
    "#     )\n",
    "#     open(local_path, \"wb\").write(response.content)\n",
    "forget_idx = np.load(local_path)\n",
    "\n",
    "# construct indices of retain from those of the forget set\n",
    "forget_mask = np.zeros(len(train_set.targets), dtype=bool)\n",
    "forget_mask[forget_idx] = True\n",
    "retain_idx = np.arange(forget_mask.size)[~forget_mask]\n",
    "\n",
    "# split train set into a forget and a retain set\n",
    "forget_set = torch.utils.data.Subset(train_set, forget_idx)\n",
    "retain_set = torch.utils.data.Subset(train_set, retain_idx)\n",
    "\n",
    "forget_loader = torch.utils.data.DataLoader(\n",
    "    forget_set, batch_size=batch_size, shuffle=True, num_workers=1\n",
    ")\n",
    "# retain_loader = torch.utils.data.DataLoader(\n",
    "#     retain_set, batch_size=128, shuffle=True, num_workers=1, generator=RNG\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "retain_loader = torch.utils.data.DataLoader(\n",
    "    retain_set, batch_size=batch_size, shuffle=True, num_workers=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Retain set accuracy: 99.5%\n",
    "- Forget set accuracy: 99.3%\n",
    "- Val set accuracy: 88.9%\n",
    "- Test set accuracy: 88.3%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_path = \"../example notebooks/weights/weights_resnet18_cifar10.pth\"\n",
    "if not os.path.exists(local_path):\n",
    "    response = requests.get(\n",
    "        \"https://storage.googleapis.com/unlearning-challenge/weights_resnet18_cifar10.pth\"\n",
    "    )\n",
    "    open(local_path, \"wb\").write(response.content)\n",
    "\n",
    "weights_pretrained = torch.load(local_path, map_location=DEVICE) #43Mbs\n",
    "\n",
    "# load net with pre-trained weights\n",
    "net = resnet18(weights=None, num_classes=10)\n",
    "net.load_state_dict(weights_pretrained)\n",
    "net.to(DEVICE)\n",
    "net.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_losses = compute_losses(net, val_loader)\n",
    "# test_losses = compute_losses(net, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract feature and pooling layers to create a Custom Model\n",
    "class CustomResNet18(nn.Module):\n",
    "    def __init__(self, original_model):\n",
    "        super(CustomResNet18, self).__init__()\n",
    "        \n",
    "        # Extract features and pooling layers\n",
    "        self.features = nn.Sequential(*list(original_model.children())[:-2])\n",
    "        self.pooling = list(original_model.children())[-2]\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.pooling(x)\n",
    "        x = torch.squeeze(x)\n",
    "        return x\n",
    "\n",
    "custom_model = CustomResNet18(net).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize\n",
    "val_embeddings = {}\n",
    "retain_embeddings = {}\n",
    "\n",
    "# Compute embeddings for val_loader\n",
    "for val_batch in val_loader:\n",
    "    images = val_batch[0].to(DEVICE)\n",
    "    person_ids = val_batch[1]\n",
    "    embeddings = custom_model(images)\n",
    "    for i, person_id in enumerate(person_ids):\n",
    "        val_embeddings.setdefault(person_id.item(), []).append(embeddings[i].detach())\n",
    "\n",
    "# Compute embeddings for retain_loader\n",
    "for retain_batch in retain_loader:\n",
    "    images = retain_batch[0].to(DEVICE)\n",
    "    targets = retain_batch[1]\n",
    "    embeddings = custom_model(images)\n",
    "    for i, target in enumerate(targets):\n",
    "        if target in range(0,10): # TODO [0, 1]:  # Only consider targets 0 and 1\n",
    "            retain_embeddings.setdefault(target.item(), []).append(embeddings[i].detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forget set accuracy: 96.18%\n",
      "--------------------\n",
      "Forget set accuracy: 91.30%\n",
      "--------------------\n",
      "Forget set accuracy: 90.00%\n",
      "--------------------\n",
      "Forget set accuracy: 88.40%\n",
      "--------------------\n",
      "Forget set accuracy: 86.24%\n",
      "--------------------\n",
      "Forget set accuracy: 84.54%\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "# Contrastive Loss\n",
    "class ContrastiveLoss(nn.Module):\n",
    "    def __init__(self, margin=1.0):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "    \n",
    "    def forward(self, output1, output2, label):\n",
    "        euclidean_distance = nn.functional.pairwise_distance(output1, output2)\n",
    "        loss_contrastive = torch.mean((1-label) * torch.pow(euclidean_distance, 2) + (label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))\n",
    "        return loss_contrastive\n",
    "\n",
    "criterion = ContrastiveLoss()\n",
    "optimizer = optim.AdamW(custom_model.parameters(), lr=0.001)\n",
    "\n",
    "# Step 3: Contrastive Learning for one epoch\n",
    "for batch in forget_loader:\n",
    "    custom_model.train()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    inputs = batch[0].to(DEVICE)\n",
    "    targets = batch[1]\n",
    "    person_ids = batch[1]\n",
    "    \n",
    "    # Forward pass to get embeddings for the forget_batch\n",
    "    forget_embeddings = custom_model(inputs)\n",
    "    \n",
    "    positive_pairs = []\n",
    "    negative_pairs = []\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient computation to save memory\n",
    "        # Fetch Positive Pairs\n",
    "        for pid in person_ids:\n",
    "            pid = pid.item()\n",
    "            if pid in val_embeddings:\n",
    "                selected_embedding = random.choice(val_embeddings[pid])\n",
    "                positive_pairs.append(selected_embedding)\n",
    "            else:\n",
    "                print(f\"Skipping person_id {pid} for positive pairs, not found in val_embeddings.\")\n",
    "                continue\n",
    "\n",
    "        # Convert to tensors for ease of computation\n",
    "        positive_pairs = torch.stack(positive_pairs).to(DEVICE)\n",
    "\n",
    "        # Fetch Negative Pairs\n",
    "        for tgt in targets:\n",
    "            tgt = tgt.item()\n",
    "            if tgt in retain_embeddings:\n",
    "                selected_embedding = random.choice(retain_embeddings[tgt])\n",
    "                negative_pairs.append(selected_embedding)\n",
    "            else:\n",
    "                print(f\"Skipping target {tgt} for negative pairs, not found in retain_embeddings.\")\n",
    "                continue\n",
    "\n",
    "        # Convert to tensors for ease of computation\n",
    "        negative_pairs = torch.stack(negative_pairs).to(DEVICE)\n",
    "    \n",
    "    # Compute Contrastive Loss\n",
    "    positive_loss = criterion(forget_embeddings, positive_pairs, torch.zeros(positive_pairs.shape[0]).to(DEVICE))\n",
    "    negative_loss = criterion(forget_embeddings, negative_pairs, torch.ones(negative_pairs.shape[0]).to(DEVICE))\n",
    "    \n",
    "    # Total loss\n",
    "    loss = positive_loss + negative_loss\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        net.eval()\n",
    "        forget_acc = accuracy(net, forget_loader)\n",
    "    print(f\"Forget set accuracy: {100.0 * forget_acc:0.2f}%\")\n",
    "    print('--'*10)\n",
    "\n",
    "    if forget_acc < 0.86:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize custom model with original model's weights\n",
    "custom_model = CustomResNet18(net)\n",
    "\n",
    "# Enable training for layers before pooling\n",
    "for param in custom_model.features[-1].parameters():  # Assuming the last layer is layer4\n",
    "    param.requires_grad = True\n",
    "\n",
    "# Contrastive Learning\n",
    "optimizer = optim.SGD(custom_model.features[-1].parameters(), lr=0.001)\n",
    "triplet_loss = nn.TripletMarginLoss(margin=1.0, p=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\luizi\\OneDrive\\Documentos\\GitHub\\machine-unlearning\\contrastive_learning\\contrastive.ipynb Cell 15\u001b[0m line \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/luizi/OneDrive/Documentos/GitHub/machine-unlearning/contrastive_learning/contrastive.ipynb#X16sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# For Contrastive Learning\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/luizi/OneDrive/Documentos/GitHub/machine-unlearning/contrastive_learning/contrastive.ipynb#X16sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfor\u001b[39;00m sample \u001b[39min\u001b[39;00m forget_loader:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/luizi/OneDrive/Documentos/GitHub/machine-unlearning/contrastive_learning/contrastive.ipynb#X16sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/luizi/OneDrive/Documentos/GitHub/machine-unlearning/contrastive_learning/contrastive.ipynb#X16sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     inputs_forget \u001b[39m=\u001b[39m sample[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\luizi\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:438\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    436\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterator\n\u001b[0;32m    437\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 438\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_iterator()\n",
      "File \u001b[1;32mc:\\Users\\luizi\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:386\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    384\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    385\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_worker_number_rationality()\n\u001b[1;32m--> 386\u001b[0m     \u001b[39mreturn\u001b[39;00m _MultiProcessingDataLoaderIter(\u001b[39mself\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\luizi\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1039\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m   1032\u001b[0m w\u001b[39m.\u001b[39mdaemon \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   1033\u001b[0m \u001b[39m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[0;32m   1034\u001b[0m \u001b[39m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[0;32m   1035\u001b[0m \u001b[39m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[0;32m   1036\u001b[0m \u001b[39m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[0;32m   1037\u001b[0m \u001b[39m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[0;32m   1038\u001b[0m \u001b[39m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[1;32m-> 1039\u001b[0m w\u001b[39m.\u001b[39;49mstart()\n\u001b[0;32m   1040\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_queues\u001b[39m.\u001b[39mappend(index_queue)\n\u001b[0;32m   1041\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_workers\u001b[39m.\u001b[39mappend(w)\n",
      "File \u001b[1;32mc:\\Users\\luizi\\AppData\\Local\\Programs\\Python\\Python38\\lib\\multiprocessing\\process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m _current_process\u001b[39m.\u001b[39m_config\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mdaemon\u001b[39m\u001b[39m'\u001b[39m), \\\n\u001b[0;32m    119\u001b[0m        \u001b[39m'\u001b[39m\u001b[39mdaemonic processes are not allowed to have children\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    120\u001b[0m _cleanup()\n\u001b[1;32m--> 121\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_Popen(\u001b[39mself\u001b[39;49m)\n\u001b[0;32m    122\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sentinel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen\u001b[39m.\u001b[39msentinel\n\u001b[0;32m    123\u001b[0m \u001b[39m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[39m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\luizi\\AppData\\Local\\Programs\\Python\\Python38\\lib\\multiprocessing\\context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m    223\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[1;32m--> 224\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_context\u001b[39m.\u001b[39;49mget_context()\u001b[39m.\u001b[39;49mProcess\u001b[39m.\u001b[39;49m_Popen(process_obj)\n",
      "File \u001b[1;32mc:\\Users\\luizi\\AppData\\Local\\Programs\\Python\\Python38\\lib\\multiprocessing\\context.py:327\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    324\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m    325\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[0;32m    326\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mpopen_spawn_win32\u001b[39;00m \u001b[39mimport\u001b[39;00m Popen\n\u001b[1;32m--> 327\u001b[0m     \u001b[39mreturn\u001b[39;00m Popen(process_obj)\n",
      "File \u001b[1;32mc:\\Users\\luizi\\AppData\\Local\\Programs\\Python\\Python38\\lib\\multiprocessing\\popen_spawn_win32.py:93\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     92\u001b[0m     reduction\u001b[39m.\u001b[39mdump(prep_data, to_child)\n\u001b[1;32m---> 93\u001b[0m     reduction\u001b[39m.\u001b[39;49mdump(process_obj, to_child)\n\u001b[0;32m     94\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     95\u001b[0m     set_spawning_popen(\u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\luizi\\AppData\\Local\\Programs\\Python\\Python38\\lib\\multiprocessing\\reduction.py:60\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdump\u001b[39m(obj, file, protocol\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m     59\u001b[0m \u001b[39m    \u001b[39m\u001b[39m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m     ForkingPickler(file, protocol)\u001b[39m.\u001b[39;49mdump(obj)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# For Contrastive Learning\n",
    "for sample in forget_loader:\n",
    "    optimizer.zero_grad()\n",
    "    inputs_forget = sample[0]\n",
    "    person_id_forget = sample[1]\n",
    "    \n",
    "    embeddings_forget = custom_model(inputs_forget)\n",
    "\n",
    "    # Find Positive Pairs in val_loader\n",
    "    embeddings_val = []\n",
    "    for val_sample in val_loader:\n",
    "        if val_sample[1] == person_id_forget:\n",
    "            embeddings_val.append(custom_model(val_sample[0]))\n",
    "    embeddings_val = torch.stack(embeddings_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply pruning\n",
    "# pct = 0.10\n",
    "# unstructure_prune(net, pct, global_pruning=True, random_init=False)\n",
    "\n",
    "torch.save({\n",
    "    'net': net.state_dict(),\n",
    "}, f'./checkpoints/temp_checkpoint.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forget_step(net, forget_loader, starting_forget_acc, counter_bool=0):\n",
    "\n",
    "    # Initialize for all epochs\n",
    "    forget_acc = copy.copy(starting_forget_acc)\n",
    "    print(f'Starting with {100.0 * forget_acc:0.2f}% forget accuracy')\n",
    "    forget_acc_threshold_1 = forget_acc*0.90\n",
    "    forget_acc_threshold_2 = forget_acc*0.80\n",
    "    print(f'Thresholds: {100.0 * forget_acc_threshold_1:0.2f}%, {100.0 * forget_acc_threshold_2:0.2f}%')\n",
    "\n",
    "    \n",
    "    iter_forget = iter(forget_loader)\n",
    "    current_batch = 0\n",
    "\n",
    "    initial_forget_lr = LR\n",
    "    if counter_bool>0:\n",
    "        initial_forget_lr = initial_forget_lr*(1.5**counter_bool)\n",
    "    criterion = nn.CrossEntropyLoss(label_smoothing=0.0)\n",
    "    forget_optimizer = optim.AdamW(net.parameters(), lr=initial_forget_lr)\n",
    "\n",
    "    not_depleted = True\n",
    "    counter = 0\n",
    "\n",
    "    net.train()\n",
    "\n",
    "    while (forget_acc > forget_acc_threshold_1) & (not_depleted):\n",
    "\n",
    "        try:\n",
    "            sample = next(iter_forget)\n",
    "            counter+=1\n",
    "            \n",
    "        except StopIteration:\n",
    "            not_depleted = False\n",
    "            print('depleted')\n",
    "            break\n",
    "\n",
    "        inputs, targets = sample\n",
    "        inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
    "\n",
    "        forget_optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        logits = net(inputs)\n",
    "\n",
    "        # Calculate loss\n",
    "        classification_loss = criterion(logits, targets)\n",
    "\n",
    "        loss = -1*classification_loss\n",
    "        loss.backward()\n",
    "        forget_optimizer.step()\n",
    "\n",
    "        current_batch+=1\n",
    "        print(current_batch)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            net.eval()\n",
    "            forget_acc = accuracy(net, forget_loader)\n",
    "        print(f\"Forget set accuracy: {100.0 * forget_acc:0.2f}%\")\n",
    "        print('--'*10)\n",
    "\n",
    "        if (forget_acc<forget_acc_threshold_2):\n",
    "            initial_forget_lr = initial_forget_lr/2\n",
    "            current_batch = 0\n",
    "            forget_acc = starting_forget_acc\n",
    "            print('Restoring')\n",
    "            checkpoint = torch.load(f'./checkpoints/temp_checkpoint.pth')\n",
    "            net.load_state_dict(checkpoint['net'])\n",
    "            forget_optimizer = optim.AdamW(net.parameters(), lr=initial_forget_lr)\n",
    "\n",
    "        if counter>=10:\n",
    "            break\n",
    "\n",
    "    return net, counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrain_step(net, retain_loader):\n",
    "\n",
    "    initial_retain_lr = LR\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer_retain = optim.SGD(net.parameters(), lr=initial_retain_lr, momentum=0.9, weight_decay=5e-4)\n",
    "\n",
    "    warmup_current_batch = 0\n",
    "    warmup_batches = math.ceil(0.4*len(retain_loader.dataset))\n",
    "    \n",
    "    net.train()\n",
    "\n",
    "    for sample in retain_loader:\n",
    "\n",
    "        inputs, targets = sample\n",
    "        inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
    "\n",
    "        warmup_current_batch += 1\n",
    "\n",
    "        # Warm-up for the first 'warmup_batches' batches\n",
    "        if warmup_current_batch <= warmup_batches:\n",
    "            adjust_learning_rate(optimizer_retain, warmup_current_batch, warmup_batches, initial_retain_lr)\n",
    "\n",
    "        optimizer_retain.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        logits = net(inputs)\n",
    "\n",
    "        # Calculate loss\n",
    "        criterion = nn.CrossEntropyLoss(label_smoothing=0.4)\n",
    "        classification_loss = criterion(logits, targets)\n",
    "        loss = classification_loss\n",
    "        loss.backward()\n",
    "        optimizer_retain.step()\n",
    "\n",
    "    torch.save({\n",
    "        'net': net.state_dict(),\n",
    "    }, f'./checkpoints/temp_checkpoint.pth')\n",
    "\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "counter_bool = 0\n",
    "\n",
    "for ep in range(epochs):\n",
    "\n",
    "    print(f'Epoch: {ep}')\n",
    "    print('****'*10)\n",
    "\n",
    "    if ep!=epochs-1:\n",
    "        with torch.no_grad():\n",
    "            net.eval()\n",
    "            starting_forget_acc = accuracy(net, forget_loader)\n",
    "\n",
    "        if starting_forget_acc > 0.86:\n",
    "            net, counter = forget_step(net, forget_loader, starting_forget_acc, counter_bool)\n",
    "            if counter>=10:\n",
    "                counter_bool+=1\n",
    "                print(f'COUNTER BOOL ON = {counter_bool}')\n",
    "        else:\n",
    "            print('Not doing forget step')\n",
    "\n",
    "    print('\"\"\" \"\"\"'*5)\n",
    "    print('Retrain')\n",
    "    net = retrain_step(net, retain_loader)\n",
    "\n",
    "    ft_forget_losses = compute_losses(net, forget_loader)\n",
    "\n",
    "    ft_mia_scores = calc_mia_acc(ft_forget_losses, val_losses)\n",
    "\n",
    "    print(\n",
    "        f\"The MIA has an accuracy of {ft_mia_scores.mean():.3f} on forgotten vs unseen images\"\n",
    "    )\n",
    "\n",
    "    if np.abs(0.5-ft_mia_scores.mean())<0.01:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.Figure(figsize=(16, 6))\n",
    "\n",
    "plt.title(\n",
    "    f\"Unlearned by fine-tuning.\\nAttack accuracy: {ft_mia_scores.mean():0.2f}\"\n",
    ")\n",
    "plt.hist(val_losses, density=True, alpha=0.5, bins=50, label=\"Test set\")\n",
    "plt.hist(ft_forget_losses, density=True, alpha=0.5, bins=50, label=\"Forget set\")\n",
    "\n",
    "plt.xlabel(\"Loss\")\n",
    "plt.yscale(\"log\")\n",
    "plt.xlim((0, np.max(val_losses)))\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
