{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on device: CUDA\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model, model_selection\n",
    "from sklearn.utils import shuffle\n",
    "import copy\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.nn.utils import prune\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.models import resnet18\n",
    "from torchvision.models.feature_extraction import create_feature_extractor\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Running on device:\", DEVICE.upper())\n",
    "\n",
    "# manual random seed is used for dataset partitioning\n",
    "# to ensure reproducible results across runs\n",
    "SEED = 42\n",
    "RNG = torch.Generator().manual_seed(SEED)\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "\n",
    "# Create an unverified SSL context\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download and pre-process CIFAR10\n",
    "normalize = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "train_set = torchvision.datasets.CIFAR10(\n",
    "    root=\"../example notebooks/data\", train=True, download=False, transform=normalize\n",
    ")\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=1)\n",
    "\n",
    "# we split held out data into test and validation set\n",
    "held_out = torchvision.datasets.CIFAR10(\n",
    "    root=\"../example notebooks/data\", train=False, download=False, transform=normalize\n",
    ")\n",
    "test_set, val_set = torch.utils.data.random_split(held_out, [0.5, 0.5], generator=RNG)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=True, num_workers=1)\n",
    "val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=True, num_workers=1)\n",
    "\n",
    "# download the forget and retain index split\n",
    "local_path = \"../example notebooks/forget_idx.npy\"\n",
    "# if not os.path.exists(local_path):\n",
    "#     response = requests.get(\n",
    "#         \"https://storage.googleapis.com/unlearning-challenge/\" + local_path\n",
    "#     )\n",
    "#     open(local_path, \"wb\").write(response.content)\n",
    "forget_idx = np.load(local_path)\n",
    "\n",
    "# construct indices of retain from those of the forget set\n",
    "forget_mask = np.zeros(len(train_set.targets), dtype=bool)\n",
    "forget_mask[forget_idx] = True\n",
    "retain_idx = np.arange(forget_mask.size)[~forget_mask]\n",
    "\n",
    "# split train set into a forget and a retain set\n",
    "forget_set = torch.utils.data.Subset(train_set, forget_idx)\n",
    "retain_set = torch.utils.data.Subset(train_set, retain_idx)\n",
    "\n",
    "forget_loader = torch.utils.data.DataLoader(\n",
    "    forget_set, batch_size=batch_size, shuffle=True, num_workers=1\n",
    ")\n",
    "# retain_loader = torch.utils.data.DataLoader(\n",
    "#     retain_set, batch_size=128, shuffle=True, num_workers=1, generator=RNG\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "retain_loader = torch.utils.data.DataLoader(\n",
    "    retain_set, batch_size=batch_size, shuffle=True, num_workers=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Retain set accuracy: 99.5%\n",
    "- Forget set accuracy: 99.3%\n",
    "- Val set accuracy: 88.9%\n",
    "- Test set accuracy: 88.3%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_path = \"../example notebooks/weights/weights_resnet18_cifar10.pth\"\n",
    "if not os.path.exists(local_path):\n",
    "    response = requests.get(\n",
    "        \"https://storage.googleapis.com/unlearning-challenge/weights_resnet18_cifar10.pth\"\n",
    "    )\n",
    "    open(local_path, \"wb\").write(response.content)\n",
    "\n",
    "weights_pretrained = torch.load(local_path, map_location=DEVICE) #43Mbs\n",
    "\n",
    "# load net with pre-trained weights\n",
    "net = resnet18(weights=None, num_classes=10)\n",
    "net.load_state_dict(weights_pretrained)\n",
    "net.to(DEVICE)\n",
    "net.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contrastive Loss\n",
    "class ContrastiveLoss(nn.Module):\n",
    "    def __init__(self, margin=1.0):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "    \n",
    "    def forward(self, output1, output2, label):\n",
    "        euclidean_distance = nn.functional.pairwise_distance(output1, output2)\n",
    "        loss_contrastive = torch.mean((1-label) * torch.pow(euclidean_distance, 2) + (label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))\n",
    "        return loss_contrastive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_losses = compute_losses(net, val_loader)\n",
    "\n",
    "# test_losses = compute_losses(net, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract feature and pooling layers to create a Custom Model\n",
    "class CustomResNet18(nn.Module):\n",
    "    def __init__(self, original_model):\n",
    "        super(CustomResNet18, self).__init__()\n",
    "        \n",
    "        # Extract features and pooling layers\n",
    "        self.features = nn.Sequential(*list(original_model.children())[:-2])\n",
    "        self.pooling = list(original_model.children())[-2]\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.pooling(x)\n",
    "        x = torch.squeeze(x)\n",
    "        return x\n",
    "\n",
    "custom_model = CustomResNet18(net).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(\n",
    "    net, \n",
    "    retain_loader,\n",
    "    val_loader\n",
    "):\n",
    "    \n",
    "    '''\n",
    "    Feature extraction\n",
    "    '''\n",
    "    \n",
    "    feat_extractor = create_feature_extractor(net, {'avgpool': 'feat1'})\n",
    "    \n",
    "    '''\n",
    "    Get class weights\n",
    "    '''\n",
    "    \n",
    "    # Retain logits\n",
    "    data = np.empty((len(retain_loader.dataset), 513), dtype=object)\n",
    "    idx = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for sample in retain_loader:\n",
    "            # Get logits\n",
    "            targets = sample[1]\n",
    "            \n",
    "            # Feature extraction\n",
    "            inputs = sample[0]\n",
    "            person_id = sample[1]\n",
    "            outputs = feat_extractor(inputs.to(DEVICE))['feat1']\n",
    "            feats = torch.flatten(outputs, start_dim=1)\n",
    "        \n",
    "            for i in range(len(targets)):\n",
    "                data[idx] = [targets[i].item()] + feats[i].cpu().numpy().tolist()\n",
    "                idx +=1\n",
    "       \n",
    "    columns = ['unique_id'] + [f'feat_{i}' for i in range(512)]\n",
    "    embeddings_retain_df = pd.DataFrame(data, columns=columns)\n",
    "    \n",
    "\n",
    "    # Val logits\n",
    "    data = np.empty((len(val_loader.dataset), 513), dtype=object)\n",
    "    idx = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for sample in val_loader:\n",
    "            # Get logits\n",
    "            targets = sample[1]\n",
    "            \n",
    "            # Feature extraction\n",
    "            inputs = sample[0]\n",
    "            person_id = sample[1]\n",
    "            outputs = feat_extractor(inputs.to(DEVICE))['feat1']\n",
    "            feats = torch.flatten(outputs, start_dim=1)\n",
    "        \n",
    "            for i in range(len(targets)):\n",
    "                data[idx] = [str(person_id[i].item())+'a'] + feats[i].cpu().numpy().tolist()\n",
    "                idx +=1\n",
    "\n",
    "    columns = ['unique_id'] + [f'feat_{i}' for i in range(512)]\n",
    "    embeddings_val_df = pd.DataFrame(data, columns=columns)\n",
    "    \n",
    "\n",
    "    return embeddings_retain_df, embeddings_val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_retain_df, embeddings_val_df = get_embeddings(net, retain_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-group embeddings by unique_id for fast lookup\n",
    "grouped_val_df = embeddings_val_df.groupby('unique_id').apply(lambda x: x.iloc[:, 1:].values)\n",
    "grouped_retain_df = embeddings_retain_df.groupby('unique_id').apply(lambda x: x.iloc[:, 1:].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contrastive_unlearning(net, forget_loader, grouped_retain_df, grouped_val_df, LR=1e-3, max_num_steps=3):\n",
    "    \n",
    "    custom_model = CustomResNet18(net).to(DEVICE)\n",
    "    criterion = ContrastiveLoss()\n",
    "    optimizer = optim.AdamW(custom_model.parameters(), lr=LR)\n",
    "    \n",
    "    warmup_current_batch = 0\n",
    "    warmup_batches = math.ceil(1*len(forget_loader.dataset))\n",
    "    \n",
    "    for i, batch in enumerate(forget_loader):\n",
    "        custom_model.train()\n",
    "        optimizer.zero_grad()\n",
    "        inputs = batch[0].to(DEVICE)\n",
    "        targets = batch[1]\n",
    "        person_ids = batch[1]\n",
    "\n",
    "        # Forward pass to get embeddings for the forget_batch\n",
    "        forget_embeddings = custom_model(inputs)\n",
    "\n",
    "        positive_pairs = []\n",
    "        negative_pairs = []\n",
    "\n",
    "        with torch.no_grad():  # Disable gradient computation to save memory\n",
    "            \n",
    "            # Fetch Positive Pairs\n",
    "            for index, pid in enumerate(person_ids):\n",
    "                candidate_embeddings = grouped_val_df.get(str(pid), None)\n",
    "                if candidate_embeddings is not None:  # If a positive pair exists\n",
    "                    selected_embedding = shuffle(candidate_embeddings, n_samples=1)[0]  # Randomly select one\n",
    "                else:  # Fallback to using the instance's own embedding\n",
    "                    selected_embedding = forget_embeddings[index].cpu().detach().numpy()\n",
    "\n",
    "                positive_pairs.append(torch.tensor(selected_embedding.astype(float)).float())\n",
    "\n",
    "\n",
    "            # Convert to tensors for ease of computation\n",
    "            positive_pairs = torch.stack(positive_pairs).to(DEVICE)\n",
    "\n",
    "            # Fetch Negative Pairs\n",
    "            for tgt in targets.cpu().numpy():\n",
    "                candidate_embeddings = grouped_retain_df.get(tgt, None)\n",
    "                if candidate_embeddings is not None:\n",
    "                    selected_embedding = shuffle(candidate_embeddings, n_samples=1)[0]  # Randomly select one\n",
    "                    negative_pairs.append(torch.tensor(selected_embedding.astype(float)).float())\n",
    "                else:\n",
    "                    break\n",
    "\n",
    "\n",
    "            # Convert to tensors for ease of computation\n",
    "            negative_pairs = torch.stack(negative_pairs).to(DEVICE)\n",
    "\n",
    "        # Compute Contrastive Loss\n",
    "        positive_loss = criterion(forget_embeddings, positive_pairs, torch.zeros(positive_pairs.shape[0]).to(DEVICE))\n",
    "        negative_loss = criterion(forget_embeddings, negative_pairs, torch.ones(negative_pairs.shape[0]).to(DEVICE))\n",
    "\n",
    "        # warmup_current_batch += 1\n",
    "\n",
    "        # # Warm-up for the first 'warmup_batches' batches\n",
    "        # if warmup_current_batch <= warmup_batches:\n",
    "        #     adjust_learning_rate(optimizer, warmup_current_batch, warmup_batches, LR)\n",
    "        \n",
    "        \n",
    "        # Total loss\n",
    "        loss = positive_loss # + negative_loss\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if i==max_num_steps:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "contrastive_unlearning(net, forget_loader, grouped_retain_df, grouped_val_df, LR=1e-4, max_num_steps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unlearning(net, retain, forget, validation):\n",
    "    \"\"\"Unlearning by fine-tuning.\n",
    "\n",
    "    Fine-tuning is a very simple algorithm that trains using only\n",
    "    the retain set.\n",
    "\n",
    "    Args:\n",
    "      net : nn.Module.\n",
    "        pre-trained model to use as base of unlearning.\n",
    "      retain : torch.utils.data.DataLoader.\n",
    "        Dataset loader for access to the retain set. This is the subset\n",
    "        of the training set that we don't want to forget.\n",
    "      forget : torch.utils.data.DataLoader.\n",
    "        Dataset loader for access to the forget set. This is the subset\n",
    "        of the training set that we want to forget. This method doesn't\n",
    "        make use of the forget set.\n",
    "      validation : torch.utils.data.DataLoader.\n",
    "        Dataset loader for access to the validation set. This method doesn't\n",
    "        make use of the validation set.\n",
    "    Returns:\n",
    "      net : updated model\n",
    "    \"\"\"\n",
    "    epochs = 1\n",
    "\n",
    "    net.fc.requires_grad_(False)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "    net.train()\n",
    "\n",
    "    for _ in range(epochs):\n",
    "        for inputs, targets in retain:\n",
    "            inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "    net.eval()\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Apply pruning\n",
    "# pct = 0.25\n",
    "# unstructure_prune(net, pct, global_pruning=True, random_init=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net = unlearning(net, retain_loader, forget_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forget set accuracy: 67.38%\n",
      "Test set accuracy: 60.40%\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    net.eval()\n",
    "    forget_acc = accuracy(net, forget_loader)\n",
    "    test_acc = accuracy(net, test_loader)\n",
    "print(f\"Forget set accuracy: {100.0 * forget_acc:0.2f}%\")\n",
    "print(f\"Test set accuracy: {100.0 * test_acc:0.2f}%\")\n",
    "print('--'*10)\n",
    "\n",
    "ft_forget_losses = compute_losses(net, forget_loader)\n",
    "\n",
    "ft_mia_scores = calc_mia_acc(ft_forget_losses, val_losses)\n",
    "\n",
    "fig = plt.Figure(figsize=(16, 6))\n",
    "\n",
    "plt.title(\n",
    "    f\"Unlearned by fine-tuning.\\nAttack accuracy: {ft_mia_scores.mean():0.2f}\"\n",
    ")\n",
    "plt.hist(val_losses, density=True, alpha=0.5, bins=50, label=\"Test set\")\n",
    "plt.hist(ft_forget_losses, density=True, alpha=0.5, bins=50, label=\"Forget set\")\n",
    "\n",
    "plt.xlabel(\"Loss\")\n",
    "plt.yscale(\"log\")\n",
    "plt.xlim((0, np.max(val_losses)))\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luis.pinto1\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py:3441: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrain_step(net, retain_loader, steps):\n",
    "\n",
    "    initial_retain_lr = 0.1\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer_retain = optim.SGD(net.parameters(), lr=initial_retain_lr, momentum=0.9, weight_decay=5e-4)\n",
    "\n",
    "    warmup_current_batch = 0\n",
    "    warmup_batches = math.ceil(0.5*len(retain_loader.dataset))\n",
    "    \n",
    "    net.train()\n",
    "\n",
    "    for counter, sample in enumerate(retain_loader):\n",
    "\n",
    "        inputs, targets = sample\n",
    "        inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
    "\n",
    "        warmup_current_batch += 1\n",
    "\n",
    "        # Warm-up for the first 'warmup_batches' batches\n",
    "        # if warmup_current_batch <= warmup_batches:\n",
    "        #     adjust_learning_rate(optimizer_retain, warmup_current_batch, warmup_batches, initial_retain_lr)\n",
    "\n",
    "        optimizer_retain.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        logits = net(inputs)\n",
    "\n",
    "        # Calculate loss\n",
    "        criterion = nn.CrossEntropyLoss(label_smoothing=0.0)\n",
    "        classification_loss = criterion(logits, targets)\n",
    "        loss = classification_loss\n",
    "        loss.backward()\n",
    "        optimizer_retain.step()\n",
    "\n",
    "        if counter==steps:\n",
    "            break\n",
    "\n",
    "    # torch.save({\n",
    "    #     'net': net.state_dict(),\n",
    "    # }, f'./checkpoints/temp_checkpoint.pth')\n",
    "\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = retrain_step(net, retain_loader, steps=len(retain_loader.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    net.eval()\n",
    "    forget_acc = accuracy(net, forget_loader)\n",
    "    test_acc = accuracy(net, test_loader)\n",
    "print(f\"Forget set accuracy: {100.0 * forget_acc:0.2f}%\")\n",
    "print(f\"Test set accuracy: {100.0 * test_acc:0.2f}%\")\n",
    "print('--'*10)\n",
    "\n",
    "ft_forget_losses = compute_losses(net, forget_loader)\n",
    "\n",
    "ft_mia_scores = calc_mia_acc(ft_forget_losses, val_losses)\n",
    "\n",
    "fig = plt.Figure(figsize=(16, 6))\n",
    "\n",
    "plt.title(\n",
    "    f\"Unlearned by fine-tuning.\\nAttack accuracy: {ft_mia_scores.mean():0.2f}\"\n",
    ")\n",
    "plt.hist(val_losses, density=True, alpha=0.5, bins=50, label=\"Test set\")\n",
    "plt.hist(ft_forget_losses, density=True, alpha=0.5, bins=50, label=\"Forget set\")\n",
    "\n",
    "plt.xlabel(\"Loss\")\n",
    "plt.yscale(\"log\")\n",
    "plt.xlim((0, np.max(val_losses)))\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "criterion = ContrastiveLoss()\n",
    "LR = 1e-3\n",
    "optimizer = optim.AdamW(custom_model.parameters(), lr=LR)\n",
    "\n",
    "warmup_current_batch = 0\n",
    "warmup_batches = math.ceil(1*len(forget_loader.dataset))\n",
    "\n",
    "for x in range(3):\n",
    "    for i, batch in enumerate(forget_loader):\n",
    "        custom_model.train()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        inputs = batch[0].to(DEVICE)\n",
    "        targets = batch[1]\n",
    "        person_ids = batch[1]\n",
    "        \n",
    "        # Forward pass to get embeddings for the forget_batch\n",
    "        forget_embeddings = custom_model(inputs)\n",
    "        \n",
    "        positive_pairs = []\n",
    "        negative_pairs = []\n",
    "\n",
    "        with torch.no_grad():  # Disable gradient computation to save memory\n",
    "            \n",
    "            # Fetch Positive Pairs\n",
    "            for index, pid in enumerate(person_ids.cpu().numpy()):\n",
    "                candidate_embeddings = grouped_val_df.get(str(pid)+'a', None)\n",
    "                if candidate_embeddings is not None:  # If a positive pair exists\n",
    "                    selected_embedding = shuffle(candidate_embeddings, n_samples=1)[0]  # Randomly select one\n",
    "                else:  # Fallback to using the instance's own embedding\n",
    "                    selected_embedding = forget_embeddings[index].cpu().detach().numpy()\n",
    "\n",
    "                positive_pairs.append(torch.tensor(selected_embedding.astype(float)).float())\n",
    "            # Convert to tensors for ease of computation\n",
    "            positive_pairs = torch.stack(positive_pairs).to(DEVICE)\n",
    "\n",
    "\n",
    "            # Fetch Negative Pairs\n",
    "            for tgt in targets.cpu().numpy():\n",
    "                candidate_embeddings = grouped_retain_df.get(tgt, None)\n",
    "                if candidate_embeddings is not None:\n",
    "                    selected_embedding = shuffle(candidate_embeddings, n_samples=1)[0]  # Randomly select one\n",
    "                    negative_pairs.append(torch.tensor(selected_embedding.astype(float)).float())\n",
    "                else:\n",
    "                    break\n",
    "            # Convert to tensors for ease of computation\n",
    "            negative_pairs = torch.stack(negative_pairs).to(DEVICE)\n",
    "        \n",
    "\n",
    "        # Compute Contrastive Loss\n",
    "        positive_loss = criterion(forget_embeddings, positive_pairs, torch.zeros(positive_pairs.shape[0]).to(DEVICE))\n",
    "        # print(f'Positive loss: {positive_loss}')\n",
    "        negative_loss = criterion(forget_embeddings, negative_pairs, torch.ones(negative_pairs.shape[0]).to(DEVICE))\n",
    "        # print(f'Neg loss: {negative_loss}')\n",
    "\n",
    "        warmup_current_batch += 1\n",
    "\n",
    "        # Warm-up for the first 'warmup_batches' batches\n",
    "        if warmup_current_batch <= warmup_batches:\n",
    "            adjust_learning_rate(optimizer, warmup_current_batch, warmup_batches, LR)\n",
    "\n",
    "        # Total loss\n",
    "        loss = positive_loss + negative_loss\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    #     if i==5:\n",
    "    #         # print('END')\n",
    "    #         break\n",
    "\n",
    "    LR = 1e-3\n",
    "    net = retrain_step(net, retain_loader, steps=len(retain_loader.dataset))\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        net.eval()\n",
    "        forget_acc = accuracy(net, forget_loader)\n",
    "        test_acc = accuracy(net, test_loader)\n",
    "    print(f\"Forget set accuracy: {100.0 * forget_acc:0.2f}%\")\n",
    "    print(f\"Test set accuracy: {100.0 * test_acc:0.2f}%\")\n",
    "    print('--'*10)\n",
    "\n",
    "    ft_forget_losses = compute_losses(net, forget_loader)\n",
    "\n",
    "    ft_mia_scores = calc_mia_acc(ft_forget_losses, val_losses)\n",
    "\n",
    "    fig = plt.Figure(figsize=(16, 6))\n",
    "\n",
    "    plt.title(\n",
    "        f\"Unlearned by fine-tuning.\\nAttack accuracy: {ft_mia_scores.mean():0.2f}\"\n",
    "    )\n",
    "    plt.hist(val_losses, density=True, alpha=0.5, bins=50, label=\"Test set\")\n",
    "    plt.hist(ft_forget_losses, density=True, alpha=0.5, bins=50, label=\"Forget set\")\n",
    "\n",
    "    plt.xlabel(\"Loss\")\n",
    "    plt.yscale(\"log\")\n",
    "    plt.xlim((0, np.max(val_losses)))\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy(net, forget_loader))\n",
    "print(accuracy(net, val_loader))\n",
    "print(accuracy(net, test_loader))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
