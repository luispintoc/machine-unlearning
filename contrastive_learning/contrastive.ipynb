{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on device: CUDA\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model, model_selection\n",
    "from sklearn.utils import shuffle\n",
    "import copy\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.nn.utils import prune\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.models import resnet18\n",
    "from torchvision.models.feature_extraction import create_feature_extractor\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Running on device:\", DEVICE.upper())\n",
    "\n",
    "# manual random seed is used for dataset partitioning\n",
    "# to ensure reproducible results across runs\n",
    "SEED = 42\n",
    "RNG = torch.Generator().manual_seed(SEED)\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "\n",
    "# Create an unverified SSL context\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download and pre-process CIFAR10\n",
    "normalize = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "train_set = torchvision.datasets.CIFAR10(\n",
    "    root=\"../example notebooks/data\", train=True, download=False, transform=normalize\n",
    ")\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=1)\n",
    "\n",
    "# we split held out data into test and validation set\n",
    "held_out = torchvision.datasets.CIFAR10(\n",
    "    root=\"../example notebooks/data\", train=False, download=False, transform=normalize\n",
    ")\n",
    "test_set, val_set = torch.utils.data.random_split(held_out, [0.5, 0.5], generator=RNG)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=True, num_workers=1)\n",
    "val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=True, num_workers=1)\n",
    "\n",
    "# download the forget and retain index split\n",
    "local_path = \"../example notebooks/forget_idx.npy\"\n",
    "# if not os.path.exists(local_path):\n",
    "#     response = requests.get(\n",
    "#         \"https://storage.googleapis.com/unlearning-challenge/\" + local_path\n",
    "#     )\n",
    "#     open(local_path, \"wb\").write(response.content)\n",
    "forget_idx = np.load(local_path)\n",
    "\n",
    "# construct indices of retain from those of the forget set\n",
    "forget_mask = np.zeros(len(train_set.targets), dtype=bool)\n",
    "forget_mask[forget_idx] = True\n",
    "retain_idx = np.arange(forget_mask.size)[~forget_mask]\n",
    "\n",
    "# split train set into a forget and a retain set\n",
    "forget_set = torch.utils.data.Subset(train_set, forget_idx)\n",
    "retain_set = torch.utils.data.Subset(train_set, retain_idx)\n",
    "\n",
    "forget_loader = torch.utils.data.DataLoader(\n",
    "    forget_set, batch_size=batch_size, shuffle=True, num_workers=1\n",
    ")\n",
    "# retain_loader = torch.utils.data.DataLoader(\n",
    "#     retain_set, batch_size=128, shuffle=True, num_workers=1, generator=RNG\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "retain_loader = torch.utils.data.DataLoader(\n",
    "    retain_set, batch_size=batch_size, shuffle=True, num_workers=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Retain set accuracy: 99.5%\n",
    "- Forget set accuracy: 99.3%\n",
    "- Val set accuracy: 88.9%\n",
    "- Test set accuracy: 88.3%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_path = \"../example notebooks/weights/weights_resnet18_cifar10.pth\"\n",
    "if not os.path.exists(local_path):\n",
    "    response = requests.get(\n",
    "        \"https://storage.googleapis.com/unlearning-challenge/weights_resnet18_cifar10.pth\"\n",
    "    )\n",
    "    open(local_path, \"wb\").write(response.content)\n",
    "\n",
    "weights_pretrained = torch.load(local_path, map_location=DEVICE) #43Mbs\n",
    "\n",
    "# load net with pre-trained weights\n",
    "net = resnet18(weights=None, num_classes=10)\n",
    "net.load_state_dict(weights_pretrained)\n",
    "net.to(DEVICE)\n",
    "net.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_losses = compute_losses(net, val_loader)\n",
    "# test_losses = compute_losses(net, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract feature and pooling layers to create a Custom Model\n",
    "class CustomResNet18(nn.Module):\n",
    "    def __init__(self, original_model):\n",
    "        super(CustomResNet18, self).__init__()\n",
    "        \n",
    "        # Extract features and pooling layers\n",
    "        self.features = nn.Sequential(*list(original_model.children())[:-2])\n",
    "        self.pooling = list(original_model.children())[-2]\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.pooling(x)\n",
    "        x = torch.squeeze(x)\n",
    "        return x\n",
    "\n",
    "custom_model = CustomResNet18(net).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(\n",
    "    net, \n",
    "    retain_loader,\n",
    "    val_loader\n",
    "):\n",
    "    \n",
    "    '''\n",
    "    Feature extraction\n",
    "    '''\n",
    "    \n",
    "    feat_extractor = create_feature_extractor(net, {'avgpool': 'feat1'})\n",
    "    \n",
    "    '''\n",
    "    Get class weights\n",
    "    '''\n",
    "    \n",
    "    # Retain logits\n",
    "    data = np.empty((len(retain_loader.dataset), 513), dtype=object)\n",
    "    idx = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for sample in retain_loader:\n",
    "            # Get logits\n",
    "            targets = sample[1]\n",
    "            \n",
    "            # Feature extraction\n",
    "            inputs = sample[0]\n",
    "            person_id = sample[1]\n",
    "            outputs = feat_extractor(inputs.to(DEVICE))['feat1']\n",
    "            feats = torch.flatten(outputs, start_dim=1)\n",
    "        \n",
    "            for i in range(len(targets)):\n",
    "                data[idx] = [targets[i].item()] + feats[i].cpu().numpy().tolist()\n",
    "                idx +=1\n",
    "       \n",
    "    columns = ['unique_id'] + [f'feat_{i}' for i in range(512)]\n",
    "    embeddings_retain_df = pd.DataFrame(data, columns=columns)\n",
    "    \n",
    "\n",
    "    # Val logits\n",
    "    data = np.empty((len(val_loader.dataset), 513), dtype=object)\n",
    "    idx = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for sample in val_loader:\n",
    "            # Get logits\n",
    "            targets = sample[1]\n",
    "            \n",
    "            # Feature extraction\n",
    "            inputs = sample[0]\n",
    "            person_id = sample[1]\n",
    "            outputs = feat_extractor(inputs.to(DEVICE))['feat1']\n",
    "            feats = torch.flatten(outputs, start_dim=1)\n",
    "        \n",
    "            for i in range(len(targets)):\n",
    "                data[idx] = [str(person_id[i].item())+'a'] + feats[i].cpu().numpy().tolist()\n",
    "                idx +=1\n",
    "\n",
    "    columns = ['unique_id'] + [f'feat_{i}' for i in range(512)]\n",
    "    embeddings_val_df = pd.DataFrame(data, columns=columns)\n",
    "    \n",
    "\n",
    "    return embeddings_retain_df, embeddings_val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_retain_df, embeddings_val_df = get_embeddings(net, retain_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-group embeddings by unique_id for fast lookup\n",
    "grouped_val_df = embeddings_val_df.groupby('unique_id').apply(lambda x: x.iloc[:, 1:].values)\n",
    "grouped_retain_df = embeddings_retain_df.groupby('unique_id').apply(lambda x: x.iloc[:, 1:].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrain_step(net, retain_loader, steps):\n",
    "\n",
    "    initial_retain_lr = LR\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer_retain = optim.SGD(net.parameters(), lr=initial_retain_lr, momentum=0.9, weight_decay=5e-4)\n",
    "\n",
    "    warmup_current_batch = 0\n",
    "    warmup_batches = math.ceil(0.4*len(retain_loader.dataset))\n",
    "    \n",
    "    net.train()\n",
    "\n",
    "    for param in net.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    net.fc.weight.requires_grad = True\n",
    "    net.fc.bias.requires_grad = True\n",
    "\n",
    "    for counter, sample in enumerate(retain_loader):\n",
    "\n",
    "        inputs, targets = sample\n",
    "        inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
    "\n",
    "        warmup_current_batch += 1\n",
    "\n",
    "        # Warm-up for the first 'warmup_batches' batches\n",
    "        if warmup_current_batch <= warmup_batches:\n",
    "            adjust_learning_rate(optimizer_retain, warmup_current_batch, warmup_batches, initial_retain_lr)\n",
    "\n",
    "        optimizer_retain.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        logits = net(inputs)\n",
    "\n",
    "        # Calculate loss\n",
    "        criterion = nn.CrossEntropyLoss(label_smoothing=0.4)\n",
    "        classification_loss = criterion(logits, targets)\n",
    "        loss = classification_loss\n",
    "        loss.backward()\n",
    "        optimizer_retain.step()\n",
    "\n",
    "        if counter==steps:\n",
    "            break\n",
    "\n",
    "    # torch.save({\n",
    "    #     'net': net.state_dict(),\n",
    "    # }, f'./checkpoints/temp_checkpoint.pth')\n",
    "\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive loss: 18.774150848388672\n",
      "Neg loss: 0.0\n",
      "Positive loss: 20.00497055053711\n",
      "Neg loss: 0.0\n",
      "Positive loss: 16.31462860107422\n",
      "Neg loss: 0.0\n",
      "Positive loss: 17.213193893432617\n",
      "Neg loss: 0.0\n",
      "Positive loss: 17.079627990722656\n",
      "Neg loss: 0.0\n",
      "Positive loss: 16.334117889404297\n",
      "Neg loss: 0.0\n",
      "Positive loss: 15.587055206298828\n",
      "Neg loss: 5.403821342042647e-05\n",
      "Positive loss: 15.050177574157715\n",
      "Neg loss: 0.00013845025387126952\n",
      "Positive loss: 17.377483367919922\n",
      "Neg loss: 0.0\n",
      "Positive loss: 14.489279747009277\n",
      "Neg loss: 0.0\n",
      "Positive loss: 16.08514404296875\n",
      "Neg loss: 0.0\n",
      "Forget set accuracy: 95.90%\n",
      "Test set accuracy: 85.48%\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive loss: 16.024856567382812\n",
      "Neg loss: 0.0\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "element 0 of tensors does not require grad and does not have a grad_fn",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\luis.pinto1\\Documents\\GitHub\\machine-unlearning\\contrastive_learning\\contrastive.ipynb Cell 14\u001b[0m line \u001b[0;36m7\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/luis.pinto1/Documents/GitHub/machine-unlearning/contrastive_learning/contrastive.ipynb#X16sZmlsZQ%3D%3D?line=69'>70</a>\u001b[0m \u001b[39m# Total loss\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/luis.pinto1/Documents/GitHub/machine-unlearning/contrastive_learning/contrastive.ipynb#X16sZmlsZQ%3D%3D?line=70'>71</a>\u001b[0m loss \u001b[39m=\u001b[39m positive_loss \u001b[39m+\u001b[39m negative_loss\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/luis.pinto1/Documents/GitHub/machine-unlearning/contrastive_learning/contrastive.ipynb#X16sZmlsZQ%3D%3D?line=72'>73</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/luis.pinto1/Documents/GitHub/machine-unlearning/contrastive_learning/contrastive.ipynb#X16sZmlsZQ%3D%3D?line=73'>74</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/luis.pinto1/Documents/GitHub/machine-unlearning/contrastive_learning/contrastive.ipynb#X16sZmlsZQ%3D%3D?line=75'>76</a>\u001b[0m \u001b[39mif\u001b[39;00m i\u001b[39m==\u001b[39m\u001b[39m10\u001b[39m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/luis.pinto1/Documents/GitHub/machine-unlearning/contrastive_learning/contrastive.ipynb#X16sZmlsZQ%3D%3D?line=76'>77</a>\u001b[0m     \u001b[39m# print('END')\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\luis.pinto1\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[0;32m    486\u001b[0m     )\n\u001b[1;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[0;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[0;32m    489\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\luis.pinto1\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\autograd\\__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"
     ]
    }
   ],
   "source": [
    "# Contrastive Loss\n",
    "class ContrastiveLoss(nn.Module):\n",
    "    def __init__(self, margin=1.0):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "    \n",
    "    def forward(self, output1, output2, label):\n",
    "        euclidean_distance = nn.functional.pairwise_distance(output1, output2)\n",
    "        loss_contrastive = torch.mean((1-label) * torch.pow(euclidean_distance, 2) + (label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))\n",
    "        return loss_contrastive\n",
    "\n",
    "criterion = ContrastiveLoss()\n",
    "optimizer = optim.AdamW(custom_model.parameters(), lr=5e-4)\n",
    "\n",
    "\n",
    "\n",
    "for x in range(3):\n",
    "    for i, batch in enumerate(forget_loader):\n",
    "        custom_model.train()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        inputs = batch[0].to(DEVICE)\n",
    "        targets = batch[1]\n",
    "        person_ids = batch[1]\n",
    "        \n",
    "        # Forward pass to get embeddings for the forget_batch\n",
    "        forget_embeddings = custom_model(inputs)\n",
    "        \n",
    "        positive_pairs = []\n",
    "        negative_pairs = []\n",
    "\n",
    "        with torch.no_grad():  # Disable gradient computation to save memory\n",
    "            \n",
    "            # Fetch Positive Pairs\n",
    "            for index, pid in enumerate(person_ids.cpu().numpy()):\n",
    "                candidate_embeddings = grouped_val_df.get(str(pid)+'a', None)\n",
    "                if candidate_embeddings is not None:  # If a positive pair exists\n",
    "                    selected_embedding = shuffle(candidate_embeddings, n_samples=1)[0]  # Randomly select one\n",
    "                else:  # Fallback to using the instance's own embedding\n",
    "                    selected_embedding = forget_embeddings[index].cpu().detach().numpy()\n",
    "\n",
    "                positive_pairs.append(torch.tensor(selected_embedding.astype(float)).float())\n",
    "            # Convert to tensors for ease of computation\n",
    "            positive_pairs = torch.stack(positive_pairs).to(DEVICE)\n",
    "\n",
    "\n",
    "            # Fetch Negative Pairs\n",
    "            for tgt in targets.cpu().numpy():\n",
    "                candidate_embeddings = grouped_retain_df.get(tgt, None)\n",
    "                if candidate_embeddings is not None:\n",
    "                    selected_embedding = shuffle(candidate_embeddings, n_samples=1)[0]  # Randomly select one\n",
    "                    negative_pairs.append(torch.tensor(selected_embedding.astype(float)).float())\n",
    "                else:\n",
    "                    break\n",
    "            # Convert to tensors for ease of computation\n",
    "            negative_pairs = torch.stack(negative_pairs).to(DEVICE)\n",
    "        \n",
    "\n",
    "        custom_model.train()\n",
    "\n",
    "        for name, param in custom_model.named_parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "        # Compute Contrastive Loss\n",
    "        positive_loss = criterion(forget_embeddings, positive_pairs, torch.zeros(positive_pairs.shape[0]).to(DEVICE))\n",
    "        print(f'Positive loss: {positive_loss}')\n",
    "        negative_loss = criterion(forget_embeddings, negative_pairs, torch.ones(negative_pairs.shape[0]).to(DEVICE))\n",
    "        print(f'Neg loss: {negative_loss}')\n",
    "        \n",
    "        # Total loss\n",
    "        loss = positive_loss + negative_loss\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if i==10:\n",
    "            # print('END')\n",
    "            break\n",
    "\n",
    "    LR = 1e-5\n",
    "    net = retrain_step(net, retain_loader, steps=3)#len(retain_loader.dataset))\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        net.eval()\n",
    "        forget_acc = accuracy(net, forget_loader)\n",
    "        test_acc = accuracy(net, test_loader)\n",
    "    print(f\"Forget set accuracy: {100.0 * forget_acc:0.2f}%\")\n",
    "    print(f\"Test set accuracy: {100.0 * test_acc:0.2f}%\")\n",
    "    print('--'*10)\n",
    "\n",
    "    ft_forget_losses = compute_losses(net, forget_loader)\n",
    "\n",
    "    ft_mia_scores = calc_mia_acc(ft_forget_losses, val_losses)\n",
    "\n",
    "    fig = plt.Figure(figsize=(16, 6))\n",
    "\n",
    "    plt.title(\n",
    "        f\"Unlearned by fine-tuning.\\nAttack accuracy: {ft_mia_scores.mean():0.2f}\"\n",
    "    )\n",
    "    plt.hist(val_losses, density=True, alpha=0.5, bins=50, label=\"Test set\")\n",
    "    plt.hist(ft_forget_losses, density=True, alpha=0.5, bins=50, label=\"Forget set\")\n",
    "\n",
    "    plt.xlabel(\"Loss\")\n",
    "    plt.yscale(\"log\")\n",
    "    plt.xlim((0, np.max(val_losses)))\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9698\n",
      "0.8576\n",
      "0.8582\n"
     ]
    }
   ],
   "source": [
    "print(accuracy(net, forget_loader))\n",
    "print(accuracy(net, val_loader))\n",
    "print(accuracy(net, test_loader))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
