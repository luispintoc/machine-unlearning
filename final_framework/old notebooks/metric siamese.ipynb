{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on device: CUDA\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model, model_selection\n",
    "from tqdm import tqdm\n",
    "from scipy.special import kl_div\n",
    "import gc\n",
    "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances\n",
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.nn.utils import prune\n",
    "from torch import optim\n",
    "from torch.nn.functional import softmax\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset, Subset\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.models import resnet18\n",
    "from torchvision.models.feature_extraction import create_feature_extractor\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Running on device:\", DEVICE.upper())\n",
    "\n",
    "# manual random seed is used for dataset partitioning\n",
    "# to ensure reproducible results across runs\n",
    "SEED = 42\n",
    "RNG = torch.Generator().manual_seed(SEED)\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from utils import *\n",
    "\n",
    "# sys.path.append('../SSD/')\n",
    "# import importlib\n",
    "# importlib.reload(ssd)\n",
    "# import ssd as ssd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "\n",
    "# Create an unverified SSL context\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "\n",
    "# download and pre-process CIFAR10\n",
    "normalize = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "train_set = torchvision.datasets.CIFAR10(\n",
    "    root=\"../example notebooks/data\", train=True, download=False, transform=normalize\n",
    ")\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=1)\n",
    "\n",
    "# we split held out data into test and validation set\n",
    "held_out = torchvision.datasets.CIFAR10(\n",
    "    root=\"../example notebooks/data\", train=False, download=False, transform=normalize\n",
    ")\n",
    "test_set, val_set = torch.utils.data.random_split(held_out, [0.5, 0.5], generator=RNG)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=1)\n",
    "val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False, num_workers=1)\n",
    "\n",
    "# download the forget and retain index split\n",
    "local_path = \"../example notebooks/forget_idx.npy\"\n",
    "# if not os.path.exists(local_path):\n",
    "#     response = requests.get(\n",
    "#         \"https://storage.googleapis.com/unlearning-challenge/\" + local_path\n",
    "#     )\n",
    "#     open(local_path, \"wb\").write(response.content)\n",
    "forget_idx = np.load(local_path)\n",
    "forget_idx = random.sample(list(forget_idx),600)\n",
    "\n",
    "# construct indices of retain from those of the forget set\n",
    "forget_mask = np.zeros(len(train_set.targets), dtype=bool)\n",
    "forget_mask[forget_idx] = True\n",
    "retain_idx = np.arange(forget_mask.size)[~forget_mask]\n",
    "retain_idx = random.sample(list(retain_idx),29400)\n",
    "\n",
    "# split train set into a forget and a retain set\n",
    "forget_set = torch.utils.data.Subset(train_set, forget_idx)\n",
    "retain_set = torch.utils.data.Subset(train_set, retain_idx)\n",
    "\n",
    "forget_loader = torch.utils.data.DataLoader(\n",
    "    forget_set, batch_size=batch_size, shuffle=True, num_workers=1\n",
    ")\n",
    "retain_loader = torch.utils.data.DataLoader(\n",
    "    retain_set, batch_size=batch_size, shuffle=True, num_workers=1, generator=RNG\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_retain_similar_to_forget(feats_retain_df, feats_forget_df, batch_size=64, similarity_metric='cosine', similarity_pct=0.1):\n",
    "    features_retain = feats_retain_df.iloc[:,1:].values\n",
    "    features_forget = feats_forget_df.iloc[:,1:].values\n",
    "\n",
    "    # Compute max similarity\n",
    "    max_similarity = np.empty(features_retain.shape[0])\n",
    "    for i in range(0, features_retain.shape[0], 512):\n",
    "        batch_features_retain = features_retain[i:i+512]\n",
    "        if similarity_metric=='euclidean':\n",
    "            similarity_matrix = euclidean_distances(batch_features_retain, features_forget)\n",
    "            max_similarity[i:i+512] = np.min(similarity_matrix, axis=1)\n",
    "            top_X_pct_idx = np.argsort(max_similarity)[:int(similarity_pct * len(max_similarity))]\n",
    "        elif similarity_metric=='cosine':\n",
    "            similarity_matrix = cosine_similarity(batch_features_retain, features_forget)\n",
    "            max_similarity[i:i+512] = np.max(similarity_matrix, axis=1)\n",
    "            top_X_pct_idx = np.argsort(max_similarity)[-int(similarity_pct * len(max_similarity)):]\n",
    "\n",
    "    # Get X% of data points\n",
    "    similar_df = feats_retain_df.iloc[top_X_pct_idx]\n",
    "    similar_ids_set = set(top_X_pct_idx)\n",
    "    \n",
    "    include_indices = [i for i,data_id in enumerate(feats_retain_df['unique_id']) if data_id not in similar_ids_set]\n",
    "    filtered_dataset = Subset(retain_loader.dataset, include_indices)\n",
    "    \n",
    "    return DataLoader(filtered_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_dataset(\n",
    "    net, \n",
    "    retain_loader, \n",
    "    forget_loader,\n",
    "    similarity_pct\n",
    "):\n",
    "    \n",
    "    '''\n",
    "    Feature extraction\n",
    "    '''\n",
    "    \n",
    "    feat_extractor = create_feature_extractor(net, {'avgpool': 'feat1'})\n",
    "    \n",
    "    '''\n",
    "    Get class weights\n",
    "    '''\n",
    "    \n",
    "    # Retain logits\n",
    "    list_of_targets = []\n",
    "    start_idx = 0\n",
    "    data = np.empty((len(retain_loader.dataset), 513), dtype=object)\n",
    "    idx = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for sample in retain_loader:\n",
    "            # Get logits\n",
    "            targets = sample[1]\n",
    "            list_of_targets.append(np.array(targets))\n",
    "            \n",
    "            # Feature extraction\n",
    "            inputs = sample[0]\n",
    "            person_id = sample[1]\n",
    "            image_id = sample[1]\n",
    "            outputs = feat_extractor(inputs.to(DEVICE))['feat1']\n",
    "            feats = torch.flatten(outputs, start_dim=1)\n",
    "        \n",
    "            for i in range(len(targets)):\n",
    "                data[idx] = [str(person_id[i])+'-'+str(image_id[i])] + feats[i].cpu().numpy().tolist()\n",
    "                idx +=1\n",
    "            \n",
    "    retain_class_weights = torch.tensor(1/np.bincount(np.concatenate(list_of_targets).ravel())).to(DEVICE, dtype=torch.float32)\n",
    "       \n",
    "    columns = ['unique_id'] + [f'feat_{i}' for i in range(512)]\n",
    "    feats_retain_df = pd.DataFrame(data, columns=columns)\n",
    "    \n",
    "    # Forget logits\n",
    "    list_of_targets = []\n",
    "    start_idx = 0\n",
    "    data = np.empty((len(forget_loader.dataset), 513), dtype=object)\n",
    "    idx = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for sample in forget_loader:\n",
    "            # Get logits\n",
    "            targets = sample[1]\n",
    "            list_of_targets.append(np.array(targets))\n",
    "            \n",
    "            # Feature extraction\n",
    "            inputs = sample[0]\n",
    "            person_id = sample[1]\n",
    "            image_id = sample[1]\n",
    "            outputs = feat_extractor(inputs.to(DEVICE))['feat1']\n",
    "            feats = torch.flatten(outputs, start_dim=1)\n",
    "        \n",
    "            for i in range(len(targets)):\n",
    "                data[idx] = [str(person_id[i])+'-'+str(image_id[i])] + feats[i].cpu().numpy().tolist()\n",
    "                idx +=1\n",
    "            \n",
    "    forget_class_weights = torch.tensor(1/np.bincount(np.concatenate(list_of_targets).ravel())).to(DEVICE, dtype=torch.float32)\n",
    "       \n",
    "    columns = ['unique_id'] + [f'feat_{i}' for i in range(512)]\n",
    "    feats_forget_df = pd.DataFrame(data, columns=columns)\n",
    "    \n",
    "    '''\n",
    "    Reduce retain dataset\n",
    "    '''\n",
    "    \n",
    "    retain_loader = remove_retain_similar_to_forget(feats_retain_df, feats_forget_df, batch_size=retain_loader.batch_size, similarity_metric='euclidean', similarity_pct=similarity_pct)\n",
    "    \n",
    "    return retain_class_weights, forget_class_weights, retain_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_path = \"../example notebooks/weights/weights_resnet18_cifar10.pth\"\n",
    "if not os.path.exists(local_path):\n",
    "    response = requests.get(\n",
    "        \"https://storage.googleapis.com/unlearning-challenge/weights_resnet18_cifar10.pth\"\n",
    "    )\n",
    "    open(local_path, \"wb\").write(response.content)\n",
    "\n",
    "weights_pretrained = torch.load(local_path, map_location=DEVICE) #43Mbs\n",
    "# weights_pretrained = torch.load(\"../checkpoints/0.pt\", map_location=DEVICE)\n",
    "\n",
    "# load model with pre-trained weights\n",
    "net = resnet18(weights=None, num_classes=10)\n",
    "net.load_state_dict(weights_pretrained)\n",
    "net.to(DEVICE)\n",
    "net.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce retain set and calculate class weights\n",
    "retain_class_weights, forget_class_weights, retain_loader = reduce_dataset(net, retain_loader, forget_loader, similarity_pct=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_loss(model, inputs, targets):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(inputs)\n",
    "        loss = torch.nn.CrossEntropyLoss(reduction=\"none\")(outputs, targets)\n",
    "    return loss.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_gradient_from_loader(model, optimizer, loader, num_batches):\n",
    "    last_linear_layer = model.fc\n",
    "    avg_grad = None\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    count = 0\n",
    "    for i, (data, target) in enumerate(loader):\n",
    "        if i >= num_batches:\n",
    "            break\n",
    "        data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        if avg_grad is None:\n",
    "            avg_grad = last_linear_layer.weight.grad.clone()\n",
    "        else:\n",
    "            avg_grad += last_linear_layer.weight.grad.clone()\n",
    "\n",
    "        count +=1\n",
    "\n",
    "        return avg_grad / count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate losses from trained from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_losses = [[] for _ in range(len(forget_loader.dataset))]\n",
    "\n",
    "for checkpoint in os.listdir('../unlearn metric/checkpoints/'):\n",
    "\n",
    "    weights_pretrained = torch.load(f\"../unlearn metric/checkpoints/{checkpoint}\", map_location=DEVICE)\n",
    "    try:\n",
    "        net.load_state_dict(weights_pretrained['net'])\n",
    "    except:\n",
    "        net.load_state_dict(weights_pretrained['model_state_dict'])\n",
    "    net.to(DEVICE)\n",
    "    net.eval();\n",
    "\n",
    "    run_losses = []\n",
    "\n",
    "    for inputs, targets in forget_loader:\n",
    "        inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
    "        batch_losses = calculate_loss(net, inputs, targets)\n",
    "        run_losses.extend(batch_losses)\n",
    "\n",
    "    for idx, loss in enumerate(run_losses):\n",
    "        original_losses[idx].append(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unlearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to inject noise into the model's weights\n",
    "def inject_noise(model, noise_level=0.01):\n",
    "    with torch.no_grad():\n",
    "        for name, param in model.named_parameters():\n",
    "            if 'weight' in name:\n",
    "                noise = torch.randn_like(param) * param.abs() * noise_level\n",
    "                param.add_(noise)\n",
    "            elif 'bias' in name:\n",
    "                noise = torch.randn_like(param) * param.abs() * noise_level\n",
    "                param.add_(noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inject_decay_noise(model, base_noise_level, decay_rate, global_step, min_noise_level=1e-6):\n",
    "    with torch.no_grad():\n",
    "        decayed_noise_level = max(base_noise_level * (decay_rate ** global_step), min_noise_level)\n",
    "        if decayed_noise_level <= min_noise_level:\n",
    "            return  # Skip noise injection if the level is below the threshold\n",
    "        for name, param in model.named_parameters():\n",
    "            if 'weight' in name:\n",
    "                noise = torch.randn_like(param) * decayed_noise_level * param.abs()\n",
    "                param.add_(noise)\n",
    "            elif 'bias' in name:\n",
    "                noise = torch.randn_like(param) * decayed_noise_level * param.abs()\n",
    "                param.add_(noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forget(net, forget_loader, optimizer):\n",
    "\n",
    "    epochs = 1\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss(label_smoothing=0.0)\n",
    "    net.train()\n",
    "\n",
    "    for _ in range(epochs):\n",
    "        for inputs, targets in forget_loader:\n",
    "            inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
    "\n",
    "            # Warm-up for the first 'warmup_batches' batches\n",
    "            # if current_batch <= warmup_batches:\n",
    "            #     adjust_learning_rate(optimizer, current_batch, warmup_batches, initial_lr)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inputs)\n",
    "            loss = -1.0*criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "\n",
    "            nn.utils.clip_grad_value_(net.parameters(), 2)\n",
    "\n",
    "            optimizer.step()\n",
    "        # scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forget_slow(net, forget, initial_lr=0.1, noise_level=0, epochs=1):\n",
    "\n",
    "    current_batch = 0\n",
    "    warmup_batches = len(forget)\n",
    "    global_step = 0\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss(label_smoothing=0.0)\n",
    "    optimizer = optim.SGD(net.parameters(), lr=initial_lr, momentum=0.9, weight_decay=5e-3)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "\n",
    "    net.train()\n",
    "\n",
    "    if noise_level>0:\n",
    "        inject_noise(net, noise_level=noise_level)\n",
    "\n",
    "    for ep in range(epochs):\n",
    "\n",
    "        # if ep<epochs-2:\n",
    "        #     inject_noise(net, noise_level=0.20/(ep+1))\n",
    "\n",
    "        for inputs, targets in forget:\n",
    "            inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
    "\n",
    "            current_batch += 1\n",
    "\n",
    "            # Warm-up for the first 'warmup_batches' batches\n",
    "            if current_batch <= warmup_batches:\n",
    "                adjust_learning_rate(optimizer, current_batch, warmup_batches, initial_lr)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inputs)\n",
    "            loss = -1.0*criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "\n",
    "            nn.utils.clip_grad_value_(net.parameters(), 2)\n",
    "            \n",
    "            optimizer.step()\n",
    "\n",
    "        # print(accuracy(net, retain_loader))\n",
    "        # print(accuracy(net, forget_loader))\n",
    "\n",
    "        scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrain_slow(net, retain, initial_lr=0.1, noise_level=0.2, epochs=1, steps_per_epoch=len(retain_loader)):\n",
    "\n",
    "    current_batch = 0\n",
    "    warmup_batches = steps_per_epoch\n",
    "    global_step = 0\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss(label_smoothing=0.0)\n",
    "    optimizer = optim.SGD(net.parameters(), lr=initial_lr, momentum=0.9, weight_decay=5e-3)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs+1)\n",
    "\n",
    "    net.train()\n",
    "\n",
    "    if noise_level>0:\n",
    "        inject_noise(net, noise_level=noise_level)\n",
    "\n",
    "    for ep in range(epochs):\n",
    "\n",
    "        # if ep<epochs-2:\n",
    "        #     inject_noise(net, noise_level=0.20/(ep+1))\n",
    "\n",
    "        for inputs, targets in retain:\n",
    "            inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
    "\n",
    "            current_batch += 1\n",
    "\n",
    "            # Warm-up for the first 'warmup_batches' batches\n",
    "            if current_batch <= warmup_batches:\n",
    "                adjust_learning_rate(optimizer, current_batch, warmup_batches, initial_lr)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "\n",
    "            nn.utils.clip_grad_value_(net.parameters(), 2)\n",
    "            \n",
    "            optimizer.step()\n",
    "            global_step += 1\n",
    "\n",
    "            # if global_step>=steps_per_epoch:\n",
    "            #     break\n",
    "\n",
    "        scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrain(net, retain, optimizer, steps_per_epoch=len(retain_loader)):\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss(label_smoothing=0.0)\n",
    "    steps = 0\n",
    "    net.train()\n",
    "\n",
    "    for ep in range(1):\n",
    "\n",
    "        # if ep<epochs-1:\n",
    "        #     inject_noise(net, noise_level=0.2/(ep+1))\n",
    "\n",
    "        for inputs, targets in retain:\n",
    "            inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
    "\n",
    "            # current_batch += 1\n",
    "\n",
    "            # # Warm-up for the first 'warmup_batches' batches\n",
    "            # if current_batch <= warmup_batches:\n",
    "            #     adjust_learning_rate(optimizer, current_batch, warmup_batches, initial_lr)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "\n",
    "            nn.utils.clip_grad_value_(net.parameters(), 2)\n",
    "            \n",
    "            optimizer.step()\n",
    "\n",
    "            steps+=1\n",
    "\n",
    "            if steps>=steps_per_epoch:\n",
    "                break\n",
    "        # scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseNetwork(nn.Module):\n",
    "    def __init__(self, feature_size):\n",
    "        super(SiameseNetwork, self).__init__()\n",
    "        self.branch = nn.Sequential(\n",
    "            nn.Linear(feature_size, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(32, 16)\n",
    "        )\n",
    "\n",
    "    def forward(self, input1, input2):\n",
    "        output1 = self.branch(input1)\n",
    "        output2 = self.branch(input2)\n",
    "        return output1, output2\n",
    "\n",
    "def contrastive_loss(output1, output2, label, margin=1.0):\n",
    "    euclidean_distance = nn.functional.pairwise_distance(output1, output2)\n",
    "    loss_contrastive = torch.mean((1 - label) * torch.pow(euclidean_distance, 2) +\n",
    "                                  label * torch.pow(torch.clamp(margin - euclidean_distance, min=0.0), 2))\n",
    "    return loss_contrastive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_siamese_net(siamese_net, net, optimizer, retain_loader, forget_loader, val_loader, epochs=20):\n",
    "\n",
    "    # Training Loop\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        iter_retain = iter(retain_loader)\n",
    "        iter_forget = iter(forget_loader)\n",
    "        iter_val = iter(val_loader)\n",
    "        running_loss = 0\n",
    "        retain_loss = 0\n",
    "        val_loss = 0\n",
    "\n",
    "        sample_retain = next(iter_retain)\n",
    "        sample_forget = next(iter_forget)\n",
    "        sample_val = next(iter_val)\n",
    "\n",
    "        # Get inputs and labels from dataloader\n",
    "        input_retain, _ = sample_retain\n",
    "        input_forget, _ = sample_forget\n",
    "        input_val, _ = sample_val\n",
    "\n",
    "        input_retain = net(input_retain.to(DEVICE))\n",
    "        input_forget = net(input_forget.to(DEVICE))\n",
    "        input_val = net(input_val.to(DEVICE))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass with retain and forget\n",
    "        output_retain, output_forget = siamese_net(input_retain, input_forget)\n",
    "        loss_retain_forget = contrastive_loss(output_retain, output_forget, label=0)  # Label 0 for similar\n",
    "\n",
    "        # Forward pass with val and forget\n",
    "        output_val, _ = siamese_net(input_val, input_forget)\n",
    "        loss_val_forget = contrastive_loss(output_val, output_forget, label=1)  # Label 1 for dissimilar\n",
    "\n",
    "        # Combine losses and backpropagate\n",
    "        total_loss = loss_retain_forget + loss_val_forget\n",
    "        running_loss += total_loss.item()\n",
    "        retain_loss += loss_retain_forget.item()\n",
    "        val_loss += loss_val_forget.item()\n",
    "        total_loss.backward()\n",
    "\n",
    "        nn.utils.clip_grad_value_(siamese_net.parameters(), 2)\n",
    "        \n",
    "        optimizer.step()\n",
    "\n",
    "        # Print loss after epoch\n",
    "        print(f'Epoch {epoch} - Total loss: {running_loss:.4f} - Retain loss: {retain_loss:.4f} - Val loss: {val_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unlearn Loop\n",
    "def siamese_unlearn(net, siamese_net, retain_loader, forget_loader, val_loader, epochs=10):\n",
    "\n",
    "    optimizer_net = optim.Adam(net.parameters(), lr=0.001)#, momentum=0.9, weight_decay=5e-3)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        iter_retain = iter(retain_loader)\n",
    "        iter_forget = iter(forget_loader)\n",
    "        iter_val = iter(val_loader)\n",
    "        running_loss = 0\n",
    "        retain_loss = 0\n",
    "        val_loss = 0\n",
    "\n",
    "        sample_retain = next(iter_retain)\n",
    "        sample_forget = next(iter_forget)\n",
    "        sample_val = next(iter_val)\n",
    "            \n",
    "\n",
    "        # Get inputs and labels from dataloader\n",
    "        input_retain, _ = sample_retain\n",
    "        input_forget, _ = sample_forget\n",
    "        input_val, _ = sample_val\n",
    "\n",
    "        input_retain = net(input_retain.to(DEVICE))\n",
    "        input_forget = net(input_forget.to(DEVICE))\n",
    "        input_val = net(input_val.to(DEVICE))\n",
    "\n",
    "        optimizer_net.zero_grad()\n",
    "\n",
    "        # Forward pass with retain and forget\n",
    "        output_retain, output_forget = siamese_net(input_retain, input_forget)\n",
    "        loss_retain_forget = contrastive_loss(output_retain, output_forget, label=1)  # Label 0 for similar\n",
    "\n",
    "        # Forward pass with val and forget\n",
    "        output_val, _ = siamese_net(input_val, input_forget)\n",
    "        loss_val_forget = contrastive_loss(output_val, output_forget, label=0)  # Label 1 for dissimilar\n",
    "\n",
    "        # Combine losses and backpropagate\n",
    "        total_loss = loss_retain_forget + loss_val_forget\n",
    "        # total_loss = -total_loss\n",
    "\n",
    "\n",
    "        running_loss += total_loss.item()\n",
    "        retain_loss += loss_retain_forget.item()\n",
    "        val_loss += loss_val_forget.item()\n",
    "        total_loss.backward()\n",
    "        optimizer_net.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate losses from unlearn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/14 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 - Total loss: 21.4171 - Retain loss: 21.4171 - Val loss: 0.0000\n",
      "Epoch 1 - Total loss: 13.0252 - Retain loss: 13.0252 - Val loss: 0.0001\n",
      "Epoch 2 - Total loss: 2.5257 - Retain loss: 2.5225 - Val loss: 0.0032\n",
      "Epoch 3 - Total loss: 0.8522 - Retain loss: 0.7948 - Val loss: 0.0574\n",
      "Epoch 4 - Total loss: 0.5725 - Retain loss: 0.3840 - Val loss: 0.1886\n",
      "Epoch 5 - Total loss: 0.5494 - Retain loss: 0.3059 - Val loss: 0.2435\n",
      "Epoch 6 - Total loss: 0.5416 - Retain loss: 0.2843 - Val loss: 0.2574\n",
      "Epoch 7 - Total loss: 0.5328 - Retain loss: 0.3074 - Val loss: 0.2254\n",
      "Epoch 8 - Total loss: 0.5291 - Retain loss: 0.2826 - Val loss: 0.2465\n",
      "Epoch 9 - Total loss: 0.5377 - Retain loss: 0.3033 - Val loss: 0.2343\n",
      "Epoch 10 - Total loss: 0.5429 - Retain loss: 0.2826 - Val loss: 0.2603\n",
      "Epoch 11 - Total loss: 0.5555 - Retain loss: 0.3063 - Val loss: 0.2492\n",
      "Epoch 12 - Total loss: 0.5405 - Retain loss: 0.2835 - Val loss: 0.2570\n",
      "Epoch 13 - Total loss: 0.5331 - Retain loss: 0.2856 - Val loss: 0.2475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/14 [01:03<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\luis.pinto1\\Documents\\GitHub\\machine-unlearning\\unlearn metric\\metric siamese.ipynb Cell 24\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/luis.pinto1/Documents/GitHub/machine-unlearning/unlearn%20metric/metric%20siamese.ipynb#X32sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m siamese_optimizer \u001b[39m=\u001b[39m optim\u001b[39m.\u001b[39mNAdam(siamese_net\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39m\u001b[39m0.1\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/luis.pinto1/Documents/GitHub/machine-unlearning/unlearn%20metric/metric%20siamese.ipynb#X32sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m siamese_net\u001b[39m.\u001b[39mtrain()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/luis.pinto1/Documents/GitHub/machine-unlearning/unlearn%20metric/metric%20siamese.ipynb#X32sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m train_siamese_net(siamese_net, net, siamese_optimizer, retain_loader, forget_loader, val_loader, epochs\u001b[39m=\u001b[39;49m\u001b[39m20\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/luis.pinto1/Documents/GitHub/machine-unlearning/unlearn%20metric/metric%20siamese.ipynb#X32sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m siamese_net\u001b[39m.\u001b[39meval()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/luis.pinto1/Documents/GitHub/machine-unlearning/unlearn%20metric/metric%20siamese.ipynb#X32sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m \u001b[39m# Unlearn\u001b[39;00m\n",
      "\u001b[1;32mc:\\Users\\luis.pinto1\\Documents\\GitHub\\machine-unlearning\\unlearn metric\\metric siamese.ipynb Cell 24\u001b[0m line \u001b[0;36m7\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/luis.pinto1/Documents/GitHub/machine-unlearning/unlearn%20metric/metric%20siamese.ipynb#X32sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/luis.pinto1/Documents/GitHub/machine-unlearning/unlearn%20metric/metric%20siamese.ipynb#X32sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     iter_retain \u001b[39m=\u001b[39m \u001b[39miter\u001b[39m(retain_loader)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/luis.pinto1/Documents/GitHub/machine-unlearning/unlearn%20metric/metric%20siamese.ipynb#X32sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     iter_forget \u001b[39m=\u001b[39m \u001b[39miter\u001b[39;49m(forget_loader)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/luis.pinto1/Documents/GitHub/machine-unlearning/unlearn%20metric/metric%20siamese.ipynb#X32sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     iter_val \u001b[39m=\u001b[39m \u001b[39miter\u001b[39m(val_loader)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/luis.pinto1/Documents/GitHub/machine-unlearning/unlearn%20metric/metric%20siamese.ipynb#X32sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     running_loss \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\luis.pinto1\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:441\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    439\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterator\n\u001b[0;32m    440\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 441\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_iterator()\n",
      "File \u001b[1;32mc:\\Users\\luis.pinto1\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:388\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    386\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    387\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_worker_number_rationality()\n\u001b[1;32m--> 388\u001b[0m     \u001b[39mreturn\u001b[39;00m _MultiProcessingDataLoaderIter(\u001b[39mself\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\luis.pinto1\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1084\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m   1082\u001b[0m _utils\u001b[39m.\u001b[39msignal_handling\u001b[39m.\u001b[39m_set_SIGCHLD_handler()\n\u001b[0;32m   1083\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_worker_pids_set \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m-> 1084\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_reset(loader, first_iter\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[1;32mc:\\Users\\luis.pinto1\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1117\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._reset\u001b[1;34m(self, loader, first_iter)\u001b[0m\n\u001b[0;32m   1115\u001b[0m \u001b[39m# prime the prefetch loop\u001b[39;00m\n\u001b[0;32m   1116\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prefetch_factor \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_workers):\n\u001b[1;32m-> 1117\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_try_put_index()\n",
      "File \u001b[1;32mc:\\Users\\luis.pinto1\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1362\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_put_index\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1358\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1359\u001b[0m     \u001b[39m# not found (i.e., didn't break)\u001b[39;00m\n\u001b[0;32m   1360\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m-> 1362\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_index_queues[worker_queue_idx]\u001b[39m.\u001b[39;49mput((\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send_idx, index))\n\u001b[0;32m   1363\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_task_info[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_send_idx] \u001b[39m=\u001b[39m (worker_queue_idx,)\n\u001b[0;32m   1364\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\luis.pinto1\\AppData\\Local\\Programs\\Python\\Python310\\lib\\multiprocessing\\queues.py:94\u001b[0m, in \u001b[0;36mQueue.put\u001b[1;34m(self, obj, block, timeout)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_notempty:\n\u001b[0;32m     93\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_thread \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m---> 94\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_start_thread()\n\u001b[0;32m     95\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_buffer\u001b[39m.\u001b[39mappend(obj)\n\u001b[0;32m     96\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_notempty\u001b[39m.\u001b[39mnotify()\n",
      "File \u001b[1;32mc:\\Users\\luis.pinto1\\AppData\\Local\\Programs\\Python\\Python310\\lib\\multiprocessing\\queues.py:177\u001b[0m, in \u001b[0;36mQueue._start_thread\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_thread\u001b[39m.\u001b[39mdaemon \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    176\u001b[0m debug(\u001b[39m'\u001b[39m\u001b[39mdoing self._thread.start()\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m--> 177\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_thread\u001b[39m.\u001b[39;49mstart()\n\u001b[0;32m    178\u001b[0m debug(\u001b[39m'\u001b[39m\u001b[39m... done self._thread.start()\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    180\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_joincancelled:\n",
      "File \u001b[1;32mc:\\Users\\luis.pinto1\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py:940\u001b[0m, in \u001b[0;36mThread.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    938\u001b[0m         \u001b[39mdel\u001b[39;00m _limbo[\u001b[39mself\u001b[39m]\n\u001b[0;32m    939\u001b[0m     \u001b[39mraise\u001b[39;00m\n\u001b[1;32m--> 940\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_started\u001b[39m.\u001b[39;49mwait()\n",
      "File \u001b[1;32mc:\\Users\\luis.pinto1\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py:607\u001b[0m, in \u001b[0;36mEvent.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    605\u001b[0m signaled \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flag\n\u001b[0;32m    606\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m signaled:\n\u001b[1;32m--> 607\u001b[0m     signaled \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cond\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[0;32m    608\u001b[0m \u001b[39mreturn\u001b[39;00m signaled\n",
      "File \u001b[1;32mc:\\Users\\luis.pinto1\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 320\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[0;32m    321\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    322\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X = len(os.listdir('../unlearn metric/checkpoints/'))  # number of times to run the unlearning algorithm\n",
    "unlearn_losses = [[] for _ in range(len(forget_loader.dataset))]  # List of lists to hold losses per sample index\n",
    "forget_accs = []\n",
    "test_accs = []\n",
    "\n",
    "for i in tqdm(range(X)):\n",
    "    \n",
    "    # Load original model\n",
    "    weights_pretrained = torch.load(local_path, map_location=DEVICE)\n",
    "    net = resnet18(weights=None, num_classes=10)\n",
    "    net.load_state_dict(weights_pretrained)\n",
    "    net.to(DEVICE)\n",
    "    net.train()\n",
    "\n",
    "    epochs = 1\n",
    "    retain_lr = 0.01\n",
    "    forget_lr = 0.01\n",
    "    retain_slow_lr = 0.01\n",
    "    pruning = 0.5\n",
    "    noise_level = 0.05\n",
    "    unlearn_steps = 5\n",
    "    reset_fc = False\n",
    "    retain_unlear_multiplier = 5\n",
    "\n",
    "\n",
    "    retain_optimizer = optim.SGD(net.parameters(), lr=retain_lr, momentum=0.9, weight_decay=5e-3)\n",
    "    retain_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(retain_optimizer, T_max=epochs+1)\n",
    "    forget_optimizer = optim.SGD(net.parameters(), lr=forget_lr, momentum=0.9, weight_decay=5e-3)\n",
    "    forget_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(forget_optimizer, T_max=epochs)\n",
    "\n",
    "\n",
    "    # Siamese Network\n",
    "    siamese_net = SiameseNetwork(feature_size=10).to('cuda')  # Define the appropriate feature size\n",
    "    siamese_optimizer = optim.NAdam(siamese_net.parameters(), lr=0.1)\n",
    "    siamese_net.train()\n",
    "\n",
    "    train_siamese_net(siamese_net, net, siamese_optimizer, retain_loader, forget_loader, val_loader, epochs=20)\n",
    "    siamese_net.eval()\n",
    "\n",
    "\n",
    "    # Unlearn\n",
    "    for _ in range(unlearn_steps):\n",
    "\n",
    "        # forget(net, forget_loader, forget_optimizer)\n",
    "        siamese_unlearn(net, siamese_net, retain_loader, forget_loader, val_loader, epochs=3)\n",
    "        # print(f'Forget acc: {accuracy(net, forget_loader)}')\n",
    "        # print(f'Test acc: {accuracy(net, test_loader)}')\n",
    "        # print('............')\n",
    "\n",
    "        retrain(net, retain_loader, retain_optimizer, steps_per_epoch=len(forget_loader)*retain_unlear_multiplier)\n",
    "        # print(f'Forget acc: {accuracy(net, forget_loader)}')\n",
    "        # print(f'Test acc: {accuracy(net, test_loader)}')\n",
    "        # print('-----')\n",
    "\n",
    "    if reset_fc:\n",
    "        net.fc.reset_parameters()\n",
    "\n",
    "    # unstructure_prune(net, pruning_amount=pruning, global_pruning=True, random_init=False, only_fc=False)\n",
    "    # retrain_slow(net, retain_loader, retain_slow_lr, noise_level=noise_level, epochs=epochs)\n",
    "\n",
    "    \n",
    "    net.eval()\n",
    "    run_losses = []\n",
    "\n",
    "    for inputs, targets in forget_loader:\n",
    "        inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
    "        batch_losses = calculate_loss(net, inputs, targets)\n",
    "        run_losses.extend(batch_losses)\n",
    "\n",
    "    for idx, loss in enumerate(run_losses):\n",
    "        unlearn_losses[idx].append(loss)\n",
    "\n",
    "    # Calc metrics\n",
    "    forget_accs.append(accuracy(net, forget_loader))\n",
    "    test_accs.append(accuracy(net, test_loader))\n",
    "\n",
    "    # print(accuracy(net, retain_loader))\n",
    "    # print(f'Forget acc: {forget_accs[-1]}')\n",
    "    # print(f'Test acc: {test_accs[-1]}')\n",
    "\n",
    "    # Clean\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9560544217687075\n"
     ]
    }
   ],
   "source": [
    "# retrain(net, retain_loader, retain_optimizer, steps_per_epoch=len(retain_loader))\n",
    "print(accuracy(net, retain_loader))\n",
    "# print(accuracy(net, forget_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiUAAAGdCAYAAADNHANuAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAhmUlEQVR4nO3deXDU5eHH8c+ykE0IORSEJJBAQMohhnJPBMUDBaTWowpjqQakqGMQMDpipCUgYpy24lE5rAcwGgVUQKsIRUagoJQbD4ZDCBIQRQbIkiAbSJ7fH5nsz5Vzk/3uPpD3a2Znst98j+f7ZEPe7OkyxhgBAABEWJ1IDwAAAEAiSgAAgCWIEgAAYAWiBAAAWIEoAQAAViBKAACAFYgSAABgBaIEAABYoW64D1hRUaHvv/9ecXFxcrlc4T48AACoBmOMjh49qpSUFNWp48x9GmGPku+//16pqanhPiwAAAiBoqIiNWvWzJF9hz1K4uLiJFWeVHx8fLgPD0kqLZVSUiq//v57KTY2suMBLiL8euFi5fV6lZqa6v877oSwR0nVQzbx8fFESaS43f//dXw8/2oCIcSvFy52Tj71gie6AgAAKxAlAADACkQJAACwQtifUwIAwPkwxujkyZMqLy+P9FBqBbfbrbp160b07TqIEgCAdcrKyrR//34dO3Ys0kOpVerXr6/k5GRFRUVF5PhECQDAKhUVFSosLJTb7VZKSoqioqJ4s02HGWNUVlamn376SYWFhWrdurVjb5B2NkQJAMAqZWVlqqioUGpqqurXrx/p4dQaMTExqlevnr777juVlZUpOjo67GPgia4AACtF4n/qtV2k55yfOAAAsAJRAgAArBBUlIwfP14ulyvg0rZtW6fGBgBAAJcrvJdgDRky5JS/ky6XS99++23oJyMILVq00AsvvBDRMZyPoJ/oesUVV+jTTz/9/x3U5bmyAABU6devn2bMmBGw7LLLLgt6P2VlZRF7aW6kBP3wTd26dZWUlOS/NGrUyIlxAQBwQfJ4PAF/J5OSkuR2u7V8+XJ1795dHo9HycnJeuKJJ3Ty5En/dtdee61GjBih0aNHq1GjRurbt68k6cMPP1Tr1q0VHR2t6667TrNmzZLL5dKRI0f8265cuVJXX321YmJilJqaqpEjR6q0tNS/3++++06PPPKI/54bWwUdJTt27FBKSopatmypwYMHa8+ePWdd3+fzyev1BlwAAKhN9u3bp5tvvlndunXT5s2bNW3aNL3++ut6+umnA9abNWuWoqKitGrVKk2fPl2FhYW68847ddttt2nz5s164IEHNHbs2IBtdu7cqX79+ukPf/iDvvzyS82ZM0crV67UiBEjJEnz5s1Ts2bN9NRTT2n//v3av39/2M47aCYICxcuNHPnzjWbN282ixYtMpmZmSYtLc14vd4zbpOXl2cknXIpLi4O5tAIpZISY6TKS0nJqd+v+t75XgD4nevXC+f2888/my1btpiff/75lO8F+89TTS/BysrKMm6328TGxvovd955p3nyySdNmzZtTEVFhX/dKVOmmAYNGpjy8nJjjDG9e/c2nTp1CtjfmDFjTIcOHQKWjR071kgyhw8fNsYYM2zYMHP//fcHrPPf//7X1KlTxz+HzZs3N88///w5x3+2uS8uLnb873dQTwjp37+//+uMjAz16NFDzZs319y5czVs2LDTbpObm6ucnBz/da/Xq9TU1GDbCQCAC8J1112nadOm+a/HxsYqOztbmZmZAQ+d9OzZUyUlJdq7d6/S0tIkSV26dAnY17Zt29StW7eAZd27dw+4vnnzZn355ZcqKCjwLzPG+N8Zt127diE7N6fV6FmqiYmJ+s1vfnPWZxV7PB55PJ6aHAYAgAtGbGysLr/88mpvG6ySkhI98MADGjly5Cnfq4qdC0WNoqSkpEQ7d+7UPffcE6rxAABw0WnXrp3ef/99GWP895asWrVKcXFxatas2Rm3a9OmjRYuXBiwbO3atQHXO3furC1btpw1hKKioi6IT1sO6omujz32mJYvX67du3fr888/1+233y632627777bqfEBAHDBe+ihh1RUVKSHH35YW7du1QcffKC8vDzl5OSc9a3dH3jgAW3dulVjxozR9u3bNXfuXM2cOVOS/HEzZswYff755xoxYoQ2bdqkHTt26IMPPvA/0VWqfJ+SFStWaN++fTp48KCj51oTQUXJ3r17dffdd6tNmzYaOHCgGjZsqNWrV1fr9dcAANQWTZs21cKFC7VmzRp17NhRDz74oIYNG6a//OUvZ90uPT1d7733nubNm6eMjAxNmzbN/+qbqqdGZGRkaPny5dq+fbuuvvpqderUSePGjVNKSop/P0899ZR2796tVq1aWf0322WMMeE8oNfrVUJCgoqLixUfHx/OQ6NKaanUoEHl1yUl0q8fwwz2NezhvQkBVjvXrxfO7fjx4yosLFR6enpEPqnWdpMmTdL06dNVVFQU8n2fbe7D8febt2MFAMBiU6dOVbdu3dSwYUOtWrVKf//73wMemrmYECUAAFhsx44devrpp3Xo0CGlpaXp0UcfVW5ubqSH5QiiBAAAiz3//PN6/vnnIz2MsAj6beYBAACcQJQAAAArECUAAMAKRAkAALACUQIAAKxAlAAAACsQJQAAwApECQDgwuFyhfcS1NBcZ72MHz++Bqft0oIFC6q9/YWCN08DACAE9u/f7/96zpw5GjdunLZt2+Zf1qDqQ5FwRtxTAgBACCQlJfkvCQkJcrlcActmz56tdu3aKTo6Wm3bttXUqVP925aVlWnEiBFKTk5WdHS0mjdvrvz8fElSixYtJEm33367XC6X//rFiHtKAABwWEFBgcaNG6eXX35ZnTp10saNGzV8+HDFxsYqKytLL730kj788EPNnTtXaWlpKioq8n8K8Nq1a9W4cWPNmDFD/fr1k9vtjvDZOIcoAQDAYXl5eXruued0xx13SJLS09O1ZcsWvfLKK8rKytKePXvUunVr9erVSy6XS82bN/dve9lll0mSEhMTlZSUFJHxhwtRAgCAg0pLS7Vz504NGzZMw4cP9y8/efKkEhISJElDhgzRjTfeqDZt2qhfv3763e9+p5tuuilSQ44YogQAAAeVlJRIkl599VX16NEj4HtVD8V07txZhYWF+uSTT/Tpp59q4MCB6tOnj957772wjzeSiBIAABzUpEkTpaSkaNeuXRo8ePAZ14uPj9egQYM0aNAg3XnnnerXr58OHTqkSy+9VPXq1VN5eXkYRx0ZRAkAAA6bMGGCRo4cqYSEBPXr108+n0/r1q3T4cOHlZOTo8mTJys5OVmdOnVSnTp19O677yopKUmJiYmSKl+Bs3TpUvXs2VMej0eXXHJJZE/IIbwkGAAAh/35z3/Wa6+9phkzZujKK69U7969NXPmTKWnp0uS4uLi9Le//U1du3ZVt27dtHv3bi1cuFB16lT+mX7uuee0ZMkSpaamqlOnTpE8FUe5jDEmnAf0er1KSEhQcXGx4uPjw3loVCktlarexKekRIqNDfx+kO9iqPDehACrnevXC+d2/PhxFRYWKj09XdHR0ZEeTq1ytrkPx99v7ikBAABWIEoAAIAViBIAAGAFogQAAFiBKAEAAFYgSgAAVgrzi0OhyM85UQIAsEq9evUkSceOHYvwSGqfqjmv+hmEG+/oCgCwitvtVmJiog4cOCBJql+/vlzBvn8SgmKM0bFjx3TgwAElJib6P5Mn3IgSAIB1kpKSJMkfJgiPxMRE/9xHAlECALCOy+VScnKyGjdurBMnTkR6OLVCvXr1InYPSRWiBABgLbfbHfE/lAgfnugKAACsQJQAAAArECUAAMAKRAkAALACUQIAAKxAlAAAACsQJQAAwApECQAAsAJRAgAArECUAAAAKxAlAADACkQJAACwAlECAACsQJQAAAArECUAAMAKRAkAALACUQIAAKxAlAAAACsQJQAAwApECQAAsAJRAgAArECUAAAAKxAlAADACkQJAACwAlECAACsQJQAAAArECUAAMAKRAkAALBCjaLk2Weflcvl0ujRo0M0HAAAUFtVO0rWrl2rV155RRkZGaEcDwAAqKWqFSUlJSUaPHiwXn31VV1yySWhHhMAAKiFqhUl2dnZGjBggPr06XPOdX0+n7xeb8AFAADg1+oGu8Hs2bO1YcMGrV279rzWz8/P14QJE4IeGAAAqF2CuqekqKhIo0aNUkFBgaKjo89rm9zcXBUXF/svRUVF1RooAAC4uAV1T8n69et14MABde7c2b+svLxcK1as0Msvvyyfzye32x2wjcfjkcfjCc1oAQDARSuoKLnhhhv01VdfBSwbOnSo2rZtqzFjxpwSJAAAAOcrqCiJi4tThw4dApbFxsaqYcOGpywHAAAIBu/oCgAArBD0q29+bdmyZSEYBgAAqO24pwQAAFiBKAEAAFYgSgAAgBWIEgAAYAWiBAAAWIEoAQAAViBKAACAFYgSAABgBaIEAABYgSgBAABWIEoAAIAViBIAAGAFogQAAFiBKAEAAFYgSgAAgBWIEgAAYAWiBAAAWIEoAQAAViBKAACAFYgSAABgBaIEAABYgSgBAABWIEoAAIAViBIAAGAFogQAAFiBKAEAAFYgSgAAgBWIEgAAYAWiBAAAWIEoAQAAViBKAACAFYgSAABgBaIEAABYgSgBAABWIEoAAIAViBIAAGAFogQAAFiBKAEAAFYgSgAAgBWIEgAAYAWiBAAAWIEoAQAAViBKAACAFYgSAABgBaIEAABYgSgBAABWIEoAAIAViBIAAGAFogQAAFiBKAEAAFYgSgAAgBWIEgAAYAWiBAAAWIEoAQAAViBKAACAFYgSAABgBaIEAABYgSgBAABWIEoAAIAVgoqSadOmKSMjQ/Hx8YqPj1dmZqY++eQTp8YGAABqkaCipFmzZnr22We1fv16rVu3Ttdff71uvfVWffPNN06NDwAA1BJ1g1n5lltuCbg+adIkTZs2TatXr9YVV1wR0oEBAIDaJago+aXy8nK9++67Ki0tVWZm5hnX8/l88vl8/uter7e6hwQAABexoKPkq6++UmZmpo4fP64GDRpo/vz5at++/RnXz8/P14QJE2o0SACozVyuSI/g/xkT6RHYiZ9RaLiMCW74ZWVl2rNnj4qLi/Xee+/ptdde0/Lly88YJqe7pyQ1NVXFxcWKj4+v2ehRPaWlUoMGlV+XlEixsYHfD/a360L+DQBC7Fy/XtXBHzz71YafkdfrVUJCgqN/v4O+pyQqKkqXX365JKlLly5au3atXnzxRb3yyiunXd/j8cjj8dRslAAA4KJX4/cpqaioCLgnBAAAoDqCuqckNzdX/fv3V1pamo4ePaq3335by5Yt0+LFi50aHwAAqCWCipIDBw7o3nvv1f79+5WQkKCMjAwtXrxYN954o1PjAwAAtURQUfL66687NQ4AAFDL8dk3AADACkQJAACwAlECAACsQJQAAAArECUAAMAKRAkAALACUQIAAKxAlAAAACsQJQAAwApECQAAsAJRAgAArECUAAAAKxAlAADACkQJAACwAlECAACsQJQAAAArECUAAMAKRAkAALACUQIAAKxAlAAAACsQJQAAwApECQAAsAJRAgAArECUAAAAKxAlAADACkQJAACwAlECAACsQJQAAAArECUAAMAKRAkAALACUQIAAKxAlAAAACsQJQAAwApECQAAsAJRAgAArECUAAAAKxAlAADACkQJAACwAlECAACsQJQAAAArECUAAMAKRAkAALACUQIAAKxAlAAAACsQJQAAwApECQAAsAJRAgAArECUAAAAKxAlAADACkQJAACwAlECAACsQJQAAAArECUAAMAKRAkAALACUQIAAKxAlAAAACsQJQAAwApECQAAsAJRAgAArBBUlOTn56tbt26Ki4tT48aNddttt2nbtm1OjQ0AANQiQUXJ8uXLlZ2drdWrV2vJkiU6ceKEbrrpJpWWljo1PgAAUEvUDWblRYsWBVyfOXOmGjdurPXr1+uaa64J6cAAAEDtElSU/FpxcbEk6dJLLz3jOj6fTz6fz3/d6/XW5JAAAOAiVe0oqaio0OjRo9WzZ0916NDhjOvl5+drwoQJ1T0MzsTlOv91jXFuHNVxIY8djgnmZnGhaNAg0iMALizVfvVNdna2vv76a82ePfus6+Xm5qq4uNh/KSoqqu4hAQDARaxa95SMGDFCH330kVasWKFmzZqddV2PxyOPx1OtwQEAgNojqCgxxujhhx/W/PnztWzZMqWnpzs1LgAAUMsEFSXZ2dl6++239cEHHyguLk4//PCDJCkhIUExMTGODBAAANQOQT2nZNq0aSouLta1116r5ORk/2XOnDlOjQ8AANQSQT98AwAA4AQ++wYAAFiBKAEAAFYgSgAAgBWIEgAAYAWiBAAAWIEoAQAAViBKAACAFYgSAABgBaIEAABYgSgBAABWIEoAAIAViBIAAGAFogQAAFiBKAEAAFYgSgAAgBWIEgAAYAWiBAAAWIEoAQAAViBKAACAFYgSAABgBaIEAABYgSgBAABWIEoAAIAViBIAAGAFogQAAFiBKAEAAFYgSgAAgBWIEgAAYAWiBAAAWIEoAQAAViBKAACAFYgSAABgBaIEAABYgSgBAABWIEoAAIAViBIAAGAFogQAAFiBKAEAAFYgSgAAgBWIEgAAYAWiBAAAWIEoAQAAViBKAACAFYgSAABgBaIEAABYgSgBAABWIEoAAIAViBIAAGAFogQAAFiBKAEAAFYgSgAAgBWIEgAAYAWiBAAAWIEoAQAAViBKAACAFYgSAABgBaIEAABYgSgBAABWIEoAAIAViBIAAGCFoKNkxYoVuuWWW5SSkiKXy6UFCxY4MCwAAFDbBB0lpaWl6tixo6ZMmeLEeAAAQC1VN9gN+vfvr/79+zsxFgAAUIsFHSXB8vl88vl8/uter9fpQwIAgAuQ41GSn5+vCRMmOH2YSi5XcOsb49z+ndx3sM627wYNnN2/vbsGAFjG8Vff5Obmqri42H8pKipy+pAAAOAC5Pg9JR6PRx6Px+nDAACACxzvUwIAAKwQ9D0lJSUl+vbbb/3XCwsLtWnTJl166aVKS0sL6eAAAEDtEXSUrFu3Ttddd53/ek5OjiQpKytLM2fODNnAAABA7RJ0lFx77bUywb6yBAAA4Bx4TgkAALACUQIAAKxAlAAAACsQJQAAwApECQAAsAJRAgAArECUAAAAKxAlAADACkQJAACwAlECAACsQJQAAAArECUAAMAKRAkAALACUQIAAKxAlAAAACsQJQAAwApECQAAsAJRAgAArECUAAAAKxAlAADACkQJAACwAlECAACsQJQAAAArECUAAMAKRAkAALACUQIAAKxAlAAAACsQJQAAwApECQAAsAJRAgAArECUAAAAKxAlAADACkQJAACwAlECAACsQJQAAAArECUAAMAKRAkAALACUQIAAKxAlAAAACsQJQAAwApECQAAsAJRAgAArECUAAAAKxAlAADACkQJAACwAlECAACsQJQAAAArECUAAMAKRAkAALACUQIAAKxAlAAAACsQJQAAwApECQAAsAJRAgAArECUAAAAKxAlAADACkQJAACwAlECAACsQJQAAAArVCtKpkyZohYtWig6Olo9evTQmjVrQj0uAABQywQdJXPmzFFOTo7y8vK0YcMGdezYUX379tWBAwecGB8AAKglgo6SyZMna/jw4Ro6dKjat2+v6dOnq379+nrjjTecGB8AAKgl6gazcllZmdavX6/c3Fz/sjp16qhPnz764osvTruNz+eTz+fzXy8uLpYkeb3e6ow3tJwcgw3nd1FgHgGb8E+b/Zz6GVX93TbGOHMABRklBw8eVHl5uZo0aRKwvEmTJtq6detpt8nPz9eECRNOWZ6amhrMoZ2RkHBh7rtWYR4Bm/BPm/2c/hkdPXpUCQ4dJKgoqY7c3Fzl5OT4r1dUVOjQoUNq2LChXC6X04c/I6/Xq9TUVBUVFSk+Pj5i44g05qES81CJeWAOqjAPlZiHSlXzsGXLFqWkpDh2nKCipFGjRnK73frxxx8Dlv/4449KSko67TYej0cejydgWWJiYnCjdFB8fHytvqFVYR4qMQ+VmAfmoArzUIl5qNS0aVPVqePcu4kEteeoqCh16dJFS5cu9S+rqKjQ0qVLlZmZGfLBAQCA2iPoh29ycnKUlZWlrl27qnv37nrhhRdUWlqqoUOHOjE+AABQSwQdJYMGDdJPP/2kcePG6YcfftBvf/tbLVq06JQnv9rO4/EoLy/vlIeWahvmoRLzUIl5YA6qMA+VmIdK4ZoHl3HytT0AAADnic++AQAAViBKAACAFYgSAABgBaIEAABY4aKJkilTpqhFixaKjo5Wjx49tGbNmrOu/8ILL6hNmzaKiYlRamqqHnnkER0/fvy06z777LNyuVwaPXq0AyMPrVDPw/jx4+VyuQIubdu2dfo0asyJ28O+ffv0pz/9SQ0bNlRMTIyuvPJKrVu3zsnTqLFQz0OLFi1OuT24XC5lZ2c7fSo1Eup5KC8v11//+lelp6crJiZGrVq10sSJEx39TJBQCPU8HD16VKNHj1bz5s0VExOjq666SmvXrnX6NGosmHk4ceKEnnrqKbVq1UrR0dHq2LGjFi1aVKN92iDUc7BixQrdcsstSklJkcvl0oIFC6o3MHMRmD17tomKijJvvPGG+eabb8zw4cNNYmKi+fHHH0+7fkFBgfF4PKagoMAUFhaaxYsXm+TkZPPII4+csu6aNWtMixYtTEZGhhk1apTDZ1IzTsxDXl6eueKKK8z+/fv9l59++ilcp1QtTszDoUOHTPPmzc2QIUPM//73P7Nr1y6zePFi8+2334brtILmxDwcOHAg4LawZMkSI8l89tlnYTqr4DkxD5MmTTINGzY0H330kSksLDTvvvuuadCggXnxxRfDdVpBc2IeBg4caNq3b2+WL19uduzYYfLy8kx8fLzZu3dvuE4raMHOw+OPP25SUlLMxx9/bHbu3GmmTp1qoqOjzYYNG6q9z0hzYg4WLlxoxo4da+bNm2ckmfnz51drbBdFlHTv3t1kZ2f7r5eXl5uUlBSTn59/2vWzs7PN9ddfH7AsJyfH9OzZM2DZ0aNHTevWrc2SJUtM7969rY8SJ+YhLy/PdOzY0ZHxOsWJeRgzZozp1auXMwN2iFO/F780atQo06pVK1NRURGaQTvAiXkYMGCAue+++wLWueOOO8zgwYNDOPLQCvU8HDt2zLjdbvPRRx8FrNO5c2czduzYEI8+dIKdh+TkZPPyyy8HLPv1zzrYfUaaE3PwSzWJkgv+4ZuysjKtX79effr08S+rU6eO+vTpoy+++OK021x11VVav369/+6qXbt2aeHChbr55psD1svOztaAAQMC9m0rJ+dhx44dSklJUcuWLTV48GDt2bPHuROpIafm4cMPP1TXrl111113qXHjxurUqZNeffVVZ0+mBpy8PfzyGG+99Zbuu+++iH645tk4NQ9XXXWVli5dqu3bt0uSNm/erJUrV6p///4Onk31OTEPJ0+eVHl5uaKjowO2i4mJ0cqVKx06k5qpzjz4fL6znmN19hlJTsxBKDn+KcFOO3jwoMrLy095R9kmTZpo69atp93mj3/8ow4ePKhevXrJGKOTJ0/qwQcf1JNPPulfZ/bs2dqwYcMF8fio5Nw89OjRQzNnzlSbNm20f/9+TZgwQVdffbW+/vprxcXFOXpO1eHUPOzatUvTpk1TTk6OnnzySa1du1YjR45UVFSUsrKyHD2n6nBqHn5pwYIFOnLkiIYMGRLq4YeMU/PwxBNPyOv1qm3btnK73SovL9ekSZM0ePBgR8+nupyYh7i4OGVmZmrixIlq166dmjRponfeeUdffPGFLr/8csfPqTqqMw99+/bV5MmTdc0116hVq1ZaunSp5s2bp/Ly8mrvM5KcmINQuuDvKamOZcuW6ZlnntHUqVO1YcMGzZs3Tx9//LEmTpwoSSoqKtKoUaNUUFBwSh1eTM41D5LUv39/3XXXXcrIyFDfvn21cOFCHTlyRHPnzo3gyEPrfOahoqJCnTt31jPPPKNOnTrp/vvv1/DhwzV9+vQIjjy0zmcefun1119X//79Hf0Y80g4n3mYO3euCgoK9Pbbb2vDhg2aNWuW/vGPf2jWrFkRHHlonc88vPnmmzLGqGnTpvJ4PHrppZd09913O/opsuH24osvqnXr1mrbtq2ioqI0YsQIDR069KI6x3MJ6xxU60Efi/h8PuN2u095/Oree+81v//970+7Ta9evcxjjz0WsOzNN980MTExpry83MyfP99IMm6323+RZFwul3G73ebkyZNOnU61OTEPZ9K1a1fzxBNP1HjMTnBqHtLS0sywYcMC1pk6dapJSUkJ3eBDyOnbw+7du02dOnXMggULQjruUHNqHpo1a3bKY+wTJ040bdq0Cd3gQ8jp20NJSYn5/vvvjTGVT369+eabQzf4EKrOPFT5+eefzd69e01FRYV5/PHHTfv27Wu8z0hwYg5+TbX5OSVRUVHq0qWLli5d6l9WUVGhpUuXKjMz87TbHDt27JTCc7vdkiRjjG644QZ99dVX2rRpk//StWtXDR48WJs2bfKvaxMn5uF0SkpKtHPnTiUnJ4do5KHl1Dz07NlT27ZtC1hn+/btat68eSiHHzJO3x5mzJihxo0ba8CAASEeeWg5NQ9nWqeioiKUww8Zp28PsbGxSk5O1uHDh7V48WLdeuutIT6D0KjOPFSJjo5W06ZNdfLkSb3//vv+c6zJPiPBiTkIqWqljGVmz55tPB6PmTlzptmyZYu5//77TWJiovnhhx+MMcbcc889Af+zz8vLM3Fxceadd94xu3btMv/5z39Mq1atzMCBA894jAvh1TdOzMOjjz5qli1bZgoLC82qVatMnz59TKNGjcyBAwfCfn7ny4l5WLNmjalbt66ZNGmS2bFjhykoKDD169c3b731VtjP73w59XtRXl5u0tLSzJgxY8J6PtXlxDxkZWWZpk2b+l8SPG/ePNOoUSPz+OOPh/38zpcT87Bo0SLzySef+L/fsWNH06NHD1NWVhb28ztfwc7D6tWrzfvvv2927txpVqxYYa6//nqTnp5uDh8+fN77tI0Tc3D06FGzceNGs3HjRiPJTJ482WzcuNF89913QY3toogSY4z55z//adLS0kxUVJTp3r27Wb16tf97vXv3NllZWf7rJ06cMOPHjzetWrUy0dHRJjU11Tz00EMBE/xrF0KUGBP6eRg0aJBJTk42UVFRpmnTpmbQoEFWvzdHFSduD//+979Nhw4djMfjMW3btjX/+te/wnQ21efEPCxevNhIMtu2bQvTWdRcqOfB6/WaUaNGmbS0NBMdHW1atmxpxo4da3w+XxjPKnihnoc5c+aYli1bmqioKJOUlGSys7PNkSNHwnhG1RPMPCxbtsy0a9fOeDwe07BhQ3PPPfeYffv2BbVPG4V6Dj777DMj6ZTLL/dzPlzGWP4WhAAAoFa44J9TAgAALg5ECQAAsAJRAgAArECUAAAAKxAlAADACkQJAACwAlECAACsQJQAAAArECUAAMAKRAkAALACUQIAAKxAlAAAACv8Hy3xpB7neZiYAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(forget_accs, color='blue', label='Forget')\n",
    "plt.axvline(x=np.mean(forget_accs), color='blue')\n",
    "plt.hist(test_accs, color='red', label='Test')\n",
    "plt.axvline(x=np.mean(test_accs), color='red')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kl_losses = []\n",
    "epsilon = 1e-2\n",
    "\n",
    "for idx, original_loss in enumerate(original_losses):\n",
    "    # losses_from_scratch = np.log(np.array(original_loss)/2 + epsilon)\n",
    "    # losses_unlearn = np.log(np.array(unlearn_losses[idx]) + epsilon)\n",
    "\n",
    "    # losses_from_scratch = np.random.lognormal(mean=losses_from_scratch.mean(), sigma=losses_from_scratch.std(), size=1000)\n",
    "    # losses_unlearn = np.random.lognormal(mean=losses_unlearn.mean(), sigma=losses_unlearn.std(), size=1000)\n",
    "\n",
    "    losses_from_scratch = np.array(original_loss)\n",
    "    # losses_unlearn = np.array(unlearn_losses[idx])\n",
    "    losses_unlearn = random.sample(unlearn_losses[idx], len(losses_from_scratch))\n",
    "\n",
    "    # Ensure all losses are non-negative (they should naturally be if they are losses)\n",
    "    # assert np.all(losses_from_scratch >= 0) and np.all(losses_unlearn >= 0), \"Losses must be non-negative\"\n",
    "\n",
    "    # Normalize the losses to sum to one to represent probability distributions\n",
    "    prob_dist_scratch = losses_from_scratch / np.sum(losses_from_scratch)\n",
    "    prob_dist_unlearn = losses_unlearn / np.sum(losses_unlearn)\n",
    "\n",
    "    # Compute the KL divergence (ensure no zero probability to avoid infinity)\n",
    "    # Add a small constant to avoid division by zero or log of zero\n",
    "\n",
    "    prob_dist_scratch += epsilon\n",
    "    prob_dist_unlearn += epsilon\n",
    "\n",
    "    # Normalize again after adding epsilon to ensure they sum to one\n",
    "    prob_dist_scratch /= np.sum(prob_dist_scratch)\n",
    "    prob_dist_unlearn /= np.sum(prob_dist_unlearn)\n",
    "\n",
    "    # Calculate the KL divergence from scratch to unlearn\n",
    "    kl_divergence = kl_div(prob_dist_scratch, prob_dist_unlearn)\n",
    "\n",
    "    # Sum over all elements to get the total divergence\n",
    "    total_kl_divergence = np.sum(kl_divergence)\n",
    "\n",
    "    kl_losses.append(total_kl_divergence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(original_losses[2], bins=6, color='blue', label='Scratch')\n",
    "plt.hist(unlearn_losses[2], bins=6, color='red', label='Unlearn')\n",
    "# plt.xscale('log')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(kl_losses, bins=100, log=True)\n",
    "plt.title(f'KL divergence, sum={np.sum(kl_losses):.2f}, median={np.median(kl_losses):.2f}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Normalize losses, calculate standard deviation, and EMD per sample\n",
    "emd_scores = []\n",
    "\n",
    "for idx, original_loss in enumerate(original_losses):\n",
    "    # normalized_losses = [ul / original_loss for ul in unlearn_losses[idx]]\n",
    "    # std_dev = np.std(normalized_losses)\n",
    "    \n",
    "    # # Create a normal distribution for the original loss with the unlearned std deviation\n",
    "    # original_distribution = np.random.lognormal(loc=original_loss, scale=std_dev, size=100)\n",
    "   \n",
    "    # # Use the normalized losses as the distribution of the unlearned model\n",
    "    # unlearn_distribution = normalized_losses\n",
    "   \n",
    "    # Calculate Earth Mover's Distance\n",
    "    emd_score = wasserstein_distance(original_loss, unlearn_losses[idx])\n",
    "    emd_scores.append(emd_score)\n",
    "\n",
    "plt.hist(emd_scores, bins=50, log=True)\n",
    "plt.title(f'EMD, sum={np.sum(emd_scores):.2f}, median={np.median(emd_scores):.2f}');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# j = 0\n",
    "# plt.hist(losses_from_scratch, color='blue', label='Trained from scratch')\n",
    "# plt.axvline(x=np.mean(losses_from_scratch), color='blue')\n",
    "# plt.hist(losses_unlearn, color='red', label='Unlearn')\n",
    "# plt.axvline(x=np.mean(losses_unlearn), color='red')\n",
    "# plt.yscale('log')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
