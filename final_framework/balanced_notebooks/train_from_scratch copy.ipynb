{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on device: CUDA\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model, model_selection\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.nn.utils import prune\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Running on device:\", DEVICE.upper())\n",
    "\n",
    "# manual random seed is used for dataset partitioning\n",
    "# to ensure reproducible results across runs\n",
    "SEED = 42\n",
    "RNG = torch.Generator().manual_seed(SEED)\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "\n",
    "# Create an unverified SSL context\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# download and pre-process CIFAR10\n",
    "normalize = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "train_set = torchvision.datasets.CIFAR10(\n",
    "    root=\"../example notebooks/data\", train=True, download=False, transform=normalize\n",
    ")\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "# we split held out data into test and validation set\n",
    "held_out = torchvision.datasets.CIFAR10(\n",
    "    root=\"../example notebooks/data\", train=False, download=False, transform=normalize\n",
    ")\n",
    "test_set, val_set = torch.utils.data.random_split(held_out, [0.5, 0.5], generator=RNG)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=1)\n",
    "val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False, num_workers=1)\n",
    "\n",
    "# download the forget and retain index split\n",
    "local_path = \"../example notebooks/forget_idx.npy\"\n",
    "# if not os.path.exists(local_path):\n",
    "#     response = requests.get(\n",
    "#         \"https://storage.googleapis.com/unlearning-challenge/\" + local_path\n",
    "#     )\n",
    "#     open(local_path, \"wb\").write(response.content)\n",
    "forget_idx = np.load(local_path)\n",
    "\n",
    "# construct indices of retain from those of the forget set\n",
    "forget_mask = np.zeros(len(train_set.targets), dtype=bool)\n",
    "forget_mask[forget_idx] = True\n",
    "retain_idx = np.arange(forget_mask.size)[~forget_mask]\n",
    "\n",
    "# split train set into a forget and a retain set\n",
    "forget_set = torch.utils.data.Subset(train_set, forget_idx)\n",
    "retain_set = torch.utils.data.Subset(train_set, retain_idx)\n",
    "\n",
    "forget_loader = torch.utils.data.DataLoader(\n",
    "    forget_set, batch_size=batch_size, shuffle=False, drop_last=True\n",
    ")\n",
    "retain_loader = torch.utils.data.DataLoader(\n",
    "    retain_set, batch_size=batch_size, shuffle=True, generator=RNG, drop_last=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Epoch: 0\n",
      "Val loss: 1.5058852434158325\n",
      "Val set accuracy: 44.5%\n",
      "----------------------------------------\n",
      "Epoch: 1\n",
      "Val loss: 1.2743005752563477\n",
      "Val set accuracy: 52.6%\n",
      "----------------------------------------\n",
      "Epoch: 2\n",
      "Val loss: 1.16933274269104\n",
      "Val set accuracy: 57.7%\n",
      "----------------------------------------\n",
      "Epoch: 3\n",
      "Val loss: 1.1101582050323486\n",
      "Val set accuracy: 62.1%\n",
      "----------------------------------------\n",
      "Epoch: 4\n",
      "Val loss: 1.0009515285491943\n",
      "Val set accuracy: 64.8%\n",
      "----------------------------------------\n",
      "Epoch: 5\n",
      "Val loss: 0.9413677453994751\n",
      "Val set accuracy: 67.4%\n",
      "----------------------------------------\n",
      "Epoch: 6\n",
      "Val loss: 0.932471752166748\n",
      "Val set accuracy: 67.1%\n",
      "----------------------------------------\n",
      "Epoch: 7\n",
      "Val loss: 0.8454344868659973\n",
      "Val set accuracy: 70.5%\n",
      "----------------------------------------\n",
      "Epoch: 8\n",
      "Val loss: 0.8583778738975525\n",
      "Val set accuracy: 70.4%\n",
      "----------------------------------------\n",
      "Epoch: 9\n",
      "Val loss: 0.9198495745658875\n",
      "Val set accuracy: 69.0%\n",
      "----------------------------------------\n",
      "Epoch: 10\n",
      "Val loss: 0.9000030755996704\n",
      "Val set accuracy: 69.5%\n",
      "----------------------------------------\n",
      "Epoch: 11\n",
      "Val loss: 0.8346692323684692\n",
      "Val set accuracy: 71.2%\n",
      "----------------------------------------\n",
      "Epoch: 12\n",
      "Val loss: 0.841737687587738\n",
      "Val set accuracy: 71.2%\n",
      "----------------------------------------\n",
      "Epoch: 13\n",
      "Val loss: 0.8512346744537354\n",
      "Val set accuracy: 71.0%\n",
      "----------------------------------------\n",
      "Epoch: 14\n",
      "Val loss: 0.8932894468307495\n",
      "Val set accuracy: 70.6%\n",
      "----------------------------------------\n",
      "Epoch: 15\n",
      "Val loss: 0.8547571897506714\n",
      "Val set accuracy: 70.9%\n",
      "----------------------------------------\n",
      "Epoch: 16\n",
      "Val loss: 0.6863496899604797\n",
      "Val set accuracy: 76.8%\n",
      "----------------------------------------\n",
      "Epoch: 17\n",
      "Val loss: 0.7802330255508423\n",
      "Val set accuracy: 74.1%\n",
      "----------------------------------------\n",
      "Epoch: 18\n",
      "Val loss: 0.761890709400177\n",
      "Val set accuracy: 75.2%\n",
      "----------------------------------------\n",
      "Epoch: 19\n",
      "Val loss: 0.774254322052002\n",
      "Val set accuracy: 74.8%\n",
      "----------------------------------------\n",
      "Epoch: 20\n",
      "Val loss: 0.7747856378555298\n",
      "Val set accuracy: 74.4%\n",
      "----------------------------------------\n",
      "Epoch: 21\n",
      "Val loss: 0.7341603636741638\n",
      "Val set accuracy: 77.4%\n",
      "----------------------------------------\n",
      "Epoch: 22\n",
      "Val loss: 0.7902752757072449\n",
      "Val set accuracy: 76.6%\n",
      "----------------------------------------\n",
      "Epoch: 23\n",
      "Val loss: 0.8564421534538269\n",
      "Val set accuracy: 74.7%\n",
      "----------------------------------------\n",
      "Epoch: 24\n",
      "Val loss: 0.8313941955566406\n",
      "Val set accuracy: 75.1%\n",
      "----------------------------------------\n",
      "Epoch: 25\n",
      "Val loss: 0.8158457279205322\n",
      "Val set accuracy: 77.6%\n",
      "----------------------------------------\n",
      "Epoch: 26\n",
      "Val loss: 0.8200214505195618\n",
      "Val set accuracy: 78.8%\n",
      "----------------------------------------\n",
      "Epoch: 27\n",
      "Val loss: 0.8926634192466736\n",
      "Val set accuracy: 77.2%\n",
      "----------------------------------------\n",
      "Epoch: 28\n",
      "Val loss: 0.8683186769485474\n",
      "Val set accuracy: 77.2%\n",
      "----------------------------------------\n",
      "Epoch: 29\n",
      "Val loss: 0.8170012831687927\n",
      "Val set accuracy: 79.2%\n",
      "----------------------------------------\n",
      "Epoch: 30\n",
      "Val loss: 0.8209988474845886\n",
      "Val set accuracy: 79.2%\n",
      "----------------------------------------\n",
      "Epoch: 31\n",
      "Val loss: 0.8220366835594177\n",
      "Val set accuracy: 79.6%\n",
      "----------------------------------------\n",
      "Epoch: 32\n",
      "Val loss: 0.8153407573699951\n",
      "Val set accuracy: 79.4%\n",
      "----------------------------------------\n",
      "Epoch: 33\n",
      "Val loss: 0.8113390803337097\n",
      "Val set accuracy: 79.4%\n",
      "----------------------------------------\n",
      "Epoch: 34\n",
      "Val loss: 0.8077115416526794\n",
      "Val set accuracy: 79.3%\n",
      "----------------------------------------\n",
      "Epoch: 35\n",
      "Val loss: 0.804332971572876\n",
      "Val set accuracy: 79.6%\n",
      "----------------------------------------\n",
      "Epoch: 36\n",
      "Val loss: 0.8001024723052979\n",
      "Val set accuracy: 79.5%\n",
      "----------------------------------------\n",
      "Epoch: 37\n",
      "Val loss: 0.792138397693634\n",
      "Val set accuracy: 79.5%\n",
      "----------------------------------------\n",
      "Epoch: 38\n",
      "Val loss: 0.7940083146095276\n",
      "Val set accuracy: 79.7%\n",
      "----------------------------------------\n",
      "Epoch: 39\n",
      "Val loss: 0.7971548438072205\n",
      "Val set accuracy: 79.6%\n",
      "----------------------------------------\n",
      "Epoch: 40\n",
      "Val loss: 0.8043665885925293\n",
      "Val set accuracy: 79.6%\n",
      "----------------------------------------\n",
      "Epoch: 41\n",
      "Val loss: 0.7948880195617676\n",
      "Val set accuracy: 79.5%\n",
      "----------------------------------------\n",
      "Epoch: 42\n",
      "Val loss: 0.8005428314208984\n",
      "Val set accuracy: 79.6%\n",
      "----------------------------------------\n",
      "Epoch: 43\n",
      "Val loss: 0.801304817199707\n",
      "Val set accuracy: 79.5%\n",
      "----------------------------------------\n",
      "Epoch: 44\n",
      "Val loss: 0.8020497560501099\n",
      "Val set accuracy: 79.8%\n",
      "----------------------------------------\n",
      "Epoch: 45\n",
      "Val loss: 0.7955272197723389\n",
      "Val set accuracy: 79.8%\n",
      "----------------------------------------\n",
      "Epoch: 46\n",
      "Val loss: 0.7988497018814087\n",
      "Val set accuracy: 79.7%\n",
      "----------------------------------------\n",
      "Epoch: 47\n",
      "Val loss: 0.7967371940612793\n",
      "Val set accuracy: 79.9%\n",
      "----------------------------------------\n",
      "Epoch: 48\n",
      "Val loss: 0.8000670671463013\n",
      "Val set accuracy: 79.9%\n",
      "----------------------------------------\n",
      "Epoch: 49\n",
      "Val loss: 0.8003031015396118\n",
      "Val set accuracy: 79.6%\n"
     ]
    }
   ],
   "source": [
    "# load model with pre-trained weights\n",
    "net = resnet18(weights=None, num_classes=10)\n",
    "net.to(DEVICE);\n",
    "\n",
    "epochs = 50\n",
    "val_loss = np.inf\n",
    "\n",
    "\n",
    "current_batch = 0\n",
    "total_samples = len(retain_loader.dataset)\n",
    "batch_size = retain_loader.batch_size\n",
    "batches_per_epoch  = math.ceil(total_samples / batch_size)\n",
    "total_batches = epochs * batches_per_epoch\n",
    "initial_lr = 0.01\n",
    "warmup_batches = math.ceil(10*batches_per_epoch)\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=initial_lr, momentum=0.9, weight_decay=5e-3)\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3)\n",
    "net.train()\n",
    "\n",
    "for ep in range(epochs):\n",
    "\n",
    "    net.train()\n",
    "\n",
    "    for inputs, targets in retain_loader:\n",
    "        inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
    "\n",
    "        current_batch += 1\n",
    "\n",
    "        # Warm-up for the first 'warmup_batches' batches\n",
    "        if current_batch <= warmup_batches:\n",
    "            adjust_learning_rate(optimizer, current_batch, warmup_batches, initial_lr)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "\n",
    "        nn.utils.clip_grad_value_(net.parameters(), 10)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "    net.eval()  # handle drop-out/batch norm layers\n",
    "    loss = 0\n",
    "    with torch.no_grad():\n",
    "        for x,y in val_loader:\n",
    "            out = net(x.to(DEVICE))  # only forward pass - NO gradients!!\n",
    "            loss += criterion(out, y.to(DEVICE))\n",
    "    # total loss - divide by number of batches\n",
    "    temp_loss = loss / len(val_loader)\n",
    "\n",
    "    print('--------'*5)\n",
    "    print(f'Epoch: {ep}')\n",
    "    print(f'Val loss: {temp_loss}')\n",
    "    \n",
    "    val_acc = accuracy(net, val_loader)\n",
    "    # print(f\"Retain set accuracy: {100.0 * accuracy(net, retain_loader):0.1f}%\")\n",
    "    # print(f\"Forget set accuracy: {100.0 * accuracy(net, forget_loader):0.1f}%\")\n",
    "    print(f\"Val set accuracy: {100.0 * val_acc:0.1f}%\")\n",
    "    # print(f\"Test set accuracy: {100.0 * accuracy(net, test_loader):0.1f}%\")\n",
    "\n",
    "    # if temp_loss < val_loss:\n",
    "    #     val_loss = temp_loss\n",
    "    \n",
    "    scheduler.step(temp_loss)\n",
    "\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "torch.save({\n",
    "    'net': net.state_dict(),\n",
    "}, f'./checkpoints/checkpoint25.pth')\n",
    "# }, f'../example notebooks/weights/internal_weights_resnet18_cifar10.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
