{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on device: CUDA\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model, model_selection\n",
    "from tqdm import tqdm\n",
    "from scipy.special import kl_div\n",
    "import gc\n",
    "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances\n",
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "\n",
    "import torch\n",
    "from torch.nn import functional\n",
    "from torch import nn\n",
    "from torch.nn.utils import prune\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset, Subset\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.models import resnet18\n",
    "from torchvision.models.feature_extraction import create_feature_extractor\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Running on device:\", DEVICE.upper())\n",
    "\n",
    "# manual random seed is used for dataset partitioning\n",
    "# to ensure reproducible results across runs\n",
    "SEED = 42\n",
    "RNG = torch.Generator().manual_seed(SEED)\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from utils import *\n",
    "\n",
    "# sys.path.append('../SSD/')\n",
    "# import importlib\n",
    "# importlib.reload(ssd)\n",
    "# import ssd as ssd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "\n",
    "# Create an unverified SSL context\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "\n",
    "# download and pre-process CIFAR10\n",
    "normalize = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "train_set = torchvision.datasets.CIFAR10(\n",
    "    root=\"../example notebooks/data\", train=True, download=False, transform=normalize\n",
    ")\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=1)\n",
    "\n",
    "# we split held out data into test and validation set\n",
    "held_out = torchvision.datasets.CIFAR10(\n",
    "    root=\"../example notebooks/data\", train=False, download=False, transform=normalize\n",
    ")\n",
    "test_set, val_set = torch.utils.data.random_split(held_out, [0.5, 0.5], generator=RNG)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=1)\n",
    "val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False, num_workers=1)\n",
    "\n",
    "# download the forget and retain index split\n",
    "local_path = \"../example notebooks/forget_idx.npy\"\n",
    "# if not os.path.exists(local_path):\n",
    "#     response = requests.get(\n",
    "#         \"https://storage.googleapis.com/unlearning-challenge/\" + local_path\n",
    "#     )\n",
    "#     open(local_path, \"wb\").write(response.content)\n",
    "forget_idx = np.load(local_path)\n",
    "forget_idx = random.sample(list(forget_idx),600)\n",
    "\n",
    "# construct indices of retain from those of the forget set\n",
    "forget_mask = np.zeros(len(train_set.targets), dtype=bool)\n",
    "forget_mask[forget_idx] = True\n",
    "retain_idx = np.arange(forget_mask.size)[~forget_mask]\n",
    "retain_idx = random.sample(list(retain_idx),29400)\n",
    "\n",
    "# split train set into a forget and a retain set\n",
    "forget_set = torch.utils.data.Subset(train_set, forget_idx)\n",
    "retain_set = torch.utils.data.Subset(train_set, retain_idx)\n",
    "\n",
    "forget_loader_not_shuffle = torch.utils.data.DataLoader(\n",
    "    forget_set, batch_size=batch_size, shuffle=False, drop_last=False\n",
    ")\n",
    "\n",
    "forget_loader = torch.utils.data.DataLoader(\n",
    "    forget_set, batch_size=batch_size, shuffle=True, drop_last=True\n",
    ")\n",
    "retain_loader = torch.utils.data.DataLoader(\n",
    "    retain_set, batch_size=batch_size, shuffle=True, generator=RNG, drop_last=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_retain_similar_to_forget(feats_retain_df, feats_forget_df, batch_size=64, similarity_metric='cosine', similarity_pct=0.1):\n",
    "    features_retain = feats_retain_df.iloc[:,1:].values\n",
    "    features_forget = feats_forget_df.iloc[:,1:].values\n",
    "\n",
    "    # Compute max similarity\n",
    "    max_similarity = np.empty(features_retain.shape[0])\n",
    "    for i in range(0, features_retain.shape[0], 512):\n",
    "        batch_features_retain = features_retain[i:i+512]\n",
    "        if similarity_metric=='euclidean':\n",
    "            similarity_matrix = euclidean_distances(batch_features_retain, features_forget)\n",
    "            max_similarity[i:i+512] = np.min(similarity_matrix, axis=1)\n",
    "            top_X_pct_idx = np.argsort(max_similarity)[:int(similarity_pct * len(max_similarity))]\n",
    "        elif similarity_metric=='cosine':\n",
    "            similarity_matrix = cosine_similarity(batch_features_retain, features_forget)\n",
    "            max_similarity[i:i+512] = np.max(similarity_matrix, axis=1)\n",
    "            top_X_pct_idx = np.argsort(max_similarity)[-int(similarity_pct * len(max_similarity)):]\n",
    "\n",
    "    # Get X% of data points\n",
    "    similar_df = feats_retain_df.iloc[top_X_pct_idx]\n",
    "    similar_ids_set = set(top_X_pct_idx)\n",
    "    \n",
    "    include_indices = [i for i,data_id in enumerate(feats_retain_df['unique_id']) if data_id not in similar_ids_set]\n",
    "    filtered_dataset = Subset(retain_loader.dataset, include_indices)\n",
    "    \n",
    "    return DataLoader(filtered_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_dataset(\n",
    "    net, \n",
    "    retain_loader, \n",
    "    forget_loader,\n",
    "    similarity_pct\n",
    "):\n",
    "    \n",
    "    '''\n",
    "    Feature extraction\n",
    "    '''\n",
    "    \n",
    "    feat_extractor = create_feature_extractor(net, {'avgpool': 'feat1'})\n",
    "    \n",
    "    '''\n",
    "    Get class weights\n",
    "    '''\n",
    "    \n",
    "    # Retain logits\n",
    "    list_of_targets = []\n",
    "    start_idx = 0\n",
    "    data = np.empty((len(retain_loader.dataset), 513), dtype=object)\n",
    "    idx = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for sample in retain_loader:\n",
    "            # Get logits\n",
    "            targets = sample[1]\n",
    "            list_of_targets.append(np.array(targets))\n",
    "            \n",
    "            # Feature extraction\n",
    "            inputs = sample[0]\n",
    "            person_id = sample[1]\n",
    "            image_id = sample[1]\n",
    "            outputs = feat_extractor(inputs.to(DEVICE))['feat1']\n",
    "            feats = torch.flatten(outputs, start_dim=1)\n",
    "        \n",
    "            for i in range(len(targets)):\n",
    "                data[idx] = [str(person_id[i])+'-'+str(image_id[i])] + feats[i].cpu().numpy().tolist()\n",
    "                idx +=1\n",
    "            \n",
    "    retain_class_weights = torch.tensor(1/np.bincount(np.concatenate(list_of_targets).ravel())).to(DEVICE, dtype=torch.float32)\n",
    "       \n",
    "    columns = ['unique_id'] + [f'feat_{i}' for i in range(512)]\n",
    "    feats_retain_df = pd.DataFrame(data, columns=columns)\n",
    "    \n",
    "    # Forget logits\n",
    "    list_of_targets = []\n",
    "    start_idx = 0\n",
    "    data = np.empty((len(forget_loader.dataset), 513), dtype=object)\n",
    "    idx = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for sample in forget_loader:\n",
    "            # Get logits\n",
    "            targets = sample[1]\n",
    "            list_of_targets.append(np.array(targets))\n",
    "            \n",
    "            # Feature extraction\n",
    "            inputs = sample[0]\n",
    "            person_id = sample[1]\n",
    "            image_id = sample[1]\n",
    "            outputs = feat_extractor(inputs.to(DEVICE))['feat1']\n",
    "            feats = torch.flatten(outputs, start_dim=1)\n",
    "        \n",
    "            for i in range(len(targets)):\n",
    "                data[idx] = [str(person_id[i])+'-'+str(image_id[i])] + feats[i].cpu().numpy().tolist()\n",
    "                idx +=1\n",
    "            \n",
    "    forget_class_weights = torch.tensor(1/np.bincount(np.concatenate(list_of_targets).ravel())).to(DEVICE, dtype=torch.float32)\n",
    "       \n",
    "    columns = ['unique_id'] + [f'feat_{i}' for i in range(512)]\n",
    "    feats_forget_df = pd.DataFrame(data, columns=columns)\n",
    "    \n",
    "    '''\n",
    "    Reduce retain dataset\n",
    "    '''\n",
    "    \n",
    "    retain_loader = remove_retain_similar_to_forget(feats_retain_df, feats_forget_df, batch_size=retain_loader.batch_size, similarity_metric='euclidean', similarity_pct=similarity_pct)\n",
    "    \n",
    "    return retain_class_weights, forget_class_weights, retain_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local_path = \"../example notebooks/weights/weights_resnet18_cifar10.pth\"\n",
    "local_path = \"../example notebooks/weights/internal_weights_resnet18_cifar10.pth\"\n",
    "\n",
    "if not os.path.exists(local_path):\n",
    "    response = requests.get(\n",
    "        \"https://storage.googleapis.com/unlearning-challenge/weights_resnet18_cifar10.pth\"\n",
    "    )\n",
    "    open(local_path, \"wb\").write(response.content)\n",
    "\n",
    "weights_pretrained = torch.load(local_path, map_location=DEVICE) #43Mbs\n",
    "# weights_pretrained = torch.load(\"../checkpoints/0.pt\", map_location=DEVICE)\n",
    "\n",
    "# load model with pre-trained weights\n",
    "net = resnet18(weights=None, num_classes=10)\n",
    "try:\n",
    "    net.load_state_dict(weights_pretrained)\n",
    "except:\n",
    "    net.load_state_dict(weights_pretrained['net'])\n",
    "net.to(DEVICE)\n",
    "net.eval();\n",
    "\n",
    "RAR = accuracy(net, retain_loader)\n",
    "TAR = accuracy(net, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce retain set and calculate class weights\n",
    "# retain_class_weights, forget_class_weights, retain_loader = reduce_dataset(net, retain_loader, forget_loader, similarity_pct=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_loss(model, inputs, targets):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(inputs)\n",
    "        loss = torch.nn.CrossEntropyLoss(reduction=\"none\")(outputs, targets)\n",
    "    return loss.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_gradient_from_loader(model, optimizer, loader, num_batches):\n",
    "    last_linear_layer = model.fc\n",
    "    avg_grad = None\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    count = 0\n",
    "    for i, (data, target) in enumerate(loader):\n",
    "        if i >= num_batches:\n",
    "            break\n",
    "        data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        if avg_grad is None:\n",
    "            avg_grad = last_linear_layer.weight.grad.clone()\n",
    "        else:\n",
    "            avg_grad += last_linear_layer.weight.grad.clone()\n",
    "\n",
    "        count +=1\n",
    "\n",
    "        return avg_grad / count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate losses from trained from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_losses = [[] for _ in range(len(forget_loader.dataset))]\n",
    "\n",
    "for checkpoint in os.listdir('../unlearn metric/checkpoints/'):\n",
    "\n",
    "    weights_pretrained = torch.load(f\"../unlearn metric/checkpoints/{checkpoint}\", map_location=DEVICE)\n",
    "    try:\n",
    "        net.load_state_dict(weights_pretrained['net'])\n",
    "    except:\n",
    "        net.load_state_dict(weights_pretrained['model_state_dict'])\n",
    "    net.to(DEVICE)\n",
    "    net.eval();\n",
    "\n",
    "    run_losses = []\n",
    "\n",
    "    for inputs, targets in forget_loader_not_shuffle:\n",
    "        inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
    "        batch_losses = calculate_loss(net, inputs, targets)\n",
    "        run_losses.extend(batch_losses)\n",
    "\n",
    "    for idx, loss in enumerate(run_losses):\n",
    "        original_losses[idx].append(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unlearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to inject noise into the model's weights\n",
    "def inject_noise(model, noise_level=0.01):\n",
    "    with torch.no_grad():\n",
    "        for name, param in model.named_parameters():\n",
    "            if 'weight' in name:\n",
    "                noise = torch.randn_like(param) * param.abs() * noise_level\n",
    "                param.add_(noise)\n",
    "            elif 'bias' in name:\n",
    "                noise = torch.randn_like(param) * param.abs() * noise_level\n",
    "                param.add_(noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inject_decay_noise(model, base_noise_level, decay_rate, global_step, min_noise_level=1e-6):\n",
    "    with torch.no_grad():\n",
    "        decayed_noise_level = max(base_noise_level * (decay_rate ** global_step), min_noise_level)\n",
    "        if decayed_noise_level <= min_noise_level:\n",
    "            return  # Skip noise injection if the level is below the threshold\n",
    "        for name, param in model.named_parameters():\n",
    "            if 'weight' in name:\n",
    "                noise = torch.randn_like(param) * decayed_noise_level * param.abs()\n",
    "                param.add_(noise)\n",
    "            elif 'bias' in name:\n",
    "                noise = torch.randn_like(param) * decayed_noise_level * param.abs()\n",
    "                param.add_(noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReverseCosineAnnealingLR(_LRScheduler):\n",
    "    def __init__(self, optimizer, T_max, last_epoch=-1, eta_min=0):\n",
    "        self.T_max = T_max\n",
    "        self.eta_min = eta_min\n",
    "        super().__init__(optimizer, last_epoch)\n",
    "\n",
    "    def get_lr(self):\n",
    "        return [\n",
    "            self.eta_min\n",
    "            + (\n",
    "                0.5\n",
    "                * (base_lr - self.eta_min)\n",
    "                * (1 + math.cos(math.pi * (1 - (self.last_epoch) / self.T_max)))\n",
    "            )\n",
    "            for base_lr in self.base_lrs\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rewind(net, retain_loader, forget_loader, LR, epochs=1, noise_level=0):\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss(label_smoothing=0.05)\n",
    "    optimizer = optim.SGD(net.parameters(), lr=LR, momentum=0.9, weight_decay=5e-3)\n",
    "    scheduler = ReverseCosineAnnealingLR(optimizer, T_max=30*(len(retain_loader)+1))\n",
    "\n",
    "    net.train()\n",
    "\n",
    "    for _ in range(epochs):\n",
    "\n",
    "        retain_not_depleted = True\n",
    "        iter_retain = iter(retain_loader)\n",
    "        \n",
    "        if noise_level>0:\n",
    "            inject_noise(net, noise_level=noise_level)\n",
    "\n",
    "        # Retain rewind\n",
    "        while retain_not_depleted:\n",
    "            try:\n",
    "                sample = next(iter_retain)\n",
    "            except StopIteration:\n",
    "                retain_not_depleted = False\n",
    "                break\n",
    "\n",
    "            inputs, targets = sample\n",
    "            inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
    "        \n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inputs)\n",
    "            loss = -1.0*criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "\n",
    "            # nn.utils.clip_grad_value_(net.parameters(), 2)\n",
    "\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "        # Forget rewind\n",
    "        for _ in range(4):\n",
    "\n",
    "            forget_not_depleted = True\n",
    "            iter_forget = iter(forget_loader)\n",
    "\n",
    "            while forget_not_depleted:\n",
    "                try:\n",
    "                    sample = next(iter_forget)\n",
    "                except StopIteration:\n",
    "                    forget_not_depleted = False\n",
    "                    break\n",
    "\n",
    "                inputs, targets = sample\n",
    "                inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                outputs = net(inputs)\n",
    "                loss = -1.0*criterion(outputs, targets)\n",
    "                loss.backward()\n",
    "\n",
    "                # nn.utils.clip_grad_value_(net.parameters(), 2)\n",
    "\n",
    "                optimizer.step()\n",
    "                scheduler.step()\n",
    "\n",
    "        # print(f'Forget acc: {accuracy(net, forget_loader)}')\n",
    "        # print(f'Test acc: {accuracy(net, test_loader)}')\n",
    "\n",
    "\n",
    "    return optimizer.param_groups[0]['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrain_slow(net, retain, initial_lr=0.1, noise_level=0.2, epochs=1, steps_per_epoch=len(retain_loader)):\n",
    "\n",
    "    current_batch = 0\n",
    "    warmup_batches = steps_per_epoch//2\n",
    "    global_step = 0\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss(label_smoothing=0.0)\n",
    "    optimizer = optim.SGD(net.parameters(), lr=initial_lr, momentum=0.9, weight_decay=5e-3)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs*len(retain_loader))\n",
    "\n",
    "    net.train()\n",
    "\n",
    "    if noise_level>0:\n",
    "        inject_noise(net, noise_level=noise_level)\n",
    "\n",
    "    for ep in range(epochs):\n",
    "\n",
    "        for inputs, targets in retain:\n",
    "\n",
    "            inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
    "\n",
    "            current_batch += 1\n",
    "\n",
    "            # Warm-up for the first 'warmup_batches' batches\n",
    "            if current_batch <= warmup_batches:\n",
    "                adjust_learning_rate(optimizer, current_batch, warmup_batches, initial_lr)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "\n",
    "            # nn.utils.clip_grad_value_(net.parameters(), 2)\n",
    "            \n",
    "            optimizer.step()\n",
    "            global_step += 1\n",
    "\n",
    "            # if global_step>=steps_per_epoch:\n",
    "            #     break\n",
    "\n",
    "            scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistillKL(nn.Module):\n",
    "    def __init__(self, T):\n",
    "        super(DistillKL, self).__init__()\n",
    "        self.T = T\n",
    "\n",
    "    def forward(self, y_s, y_t):\n",
    "        p_s = functional.log_softmax(y_s/self.T, dim=1)\n",
    "        p_t = functional.softmax(y_t/self.T, dim=1)\n",
    "        loss = functional.kl_div(p_s, p_t, size_average=False) * (self.T**2) / y_s.shape[0]\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SCRUBTraining:\n",
    "    def __init__(self, teacher, student, retain_dataloader, forget_dataloader, K=4.0, LR=0.01):\n",
    "        self.teacher = teacher\n",
    "        self.student = student\n",
    "        self.retain_dataloader = retain_dataloader\n",
    "        self.forget_dataloader = forget_dataloader\n",
    "        self.LR = LR\n",
    "        self.K = K\n",
    "\n",
    "        self.criterion_cls = nn.CrossEntropyLoss()\n",
    "        self.criterion_div = DistillKL(K)\n",
    "        self.criterion_kd = DistillKL(K)\n",
    "\n",
    "        self.optimizer = optim.SGD(student.parameters(), lr=LR, momentum=0.9, weight_decay=5e-3)\n",
    "\n",
    "    def train_epoch(self):\n",
    "        self.student.train()\n",
    "        self.teacher.eval()\n",
    "\n",
    "        # Function to compute accuracy.\n",
    "        def compute_accuracy(outputs, labels):\n",
    "            _, predicted = outputs.max(1)\n",
    "            total = labels.size(0)\n",
    "            correct = predicted.eq(labels).sum().item()\n",
    "            return 100 * correct / total\n",
    "\n",
    "        total_loss_retain, total_accuracy_retain = 0, 0\n",
    "        total_loss_forget, total_accuracy_forget = 0, 0\n",
    "        counter = 0\n",
    "        # Training with retain data.\n",
    "        for inputs_retain, labels_retain in self.retain_dataloader:\n",
    "            inputs_retain, labels_retain = inputs_retain.cuda(), labels_retain.cuda()\n",
    "\n",
    "            # Forward pass: Student\n",
    "            outputs_retain_student = self.student(inputs_retain)\n",
    "\n",
    "            # Forward pass: Teacher\n",
    "            with torch.no_grad():\n",
    "                outputs_retain_teacher = self.teacher(inputs_retain)\n",
    "\n",
    "            # Loss computation\n",
    "            loss_cls = self.criterion_cls(outputs_retain_student, labels_retain)\n",
    "            loss_div_retain = self.criterion_div(outputs_retain_student, outputs_retain_teacher)\n",
    "\n",
    "            loss = loss_cls + loss_div_retain\n",
    "\n",
    "            # Update total loss and accuracy for retain data.\n",
    "            # total_loss_retain += loss.item()\n",
    "            # total_accuracy_retain += compute_accuracy(outputs_retain_student, labels_retain)\n",
    "\n",
    "            # Backward pass\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            # nn.utils.clip_grad_value_(self.student.parameters(), 2)\n",
    "            self.optimizer.step()\n",
    "\n",
    "            counter += 1\n",
    "            if counter > 20:\n",
    "                break\n",
    "\n",
    "        # Training with forget data.\n",
    "        for inputs_forget, labels_forget in self.forget_dataloader:\n",
    "            inputs_forget, labels_forget = inputs_forget.cuda(), labels_forget.cuda()\n",
    "\n",
    "            # Forward pass: Student\n",
    "            outputs_forget_student = self.student(inputs_forget)\n",
    "\n",
    "            # Forward pass: Teacher\n",
    "            with torch.no_grad():\n",
    "                outputs_forget_teacher = self.teacher(inputs_forget)\n",
    "\n",
    "            # We want to maximize the divergence for the forget data.\n",
    "            loss_div_forget = -self.criterion_div(outputs_forget_student, outputs_forget_teacher)\n",
    "\n",
    "            # Update total loss and accuracy for forget data.\n",
    "            # total_loss_forget += loss_div_forget.item()\n",
    "            # total_accuracy_forget += compute_accuracy(outputs_forget_student, labels_forget)\n",
    "\n",
    "            # Backward pass\n",
    "            self.optimizer.zero_grad()\n",
    "            loss_div_forget.backward()\n",
    "            # nn.utils.clip_grad_value_(self.student.parameters(), 2)\n",
    "            self.optimizer.step()\n",
    "\n",
    "        # # Print average loss and accuracy for the entire epoch\n",
    "        # avg_loss_retain = total_loss_retain / len(self.retain_dataloader)\n",
    "        # avg_accuracy_retain = total_accuracy_retain / len(self.retain_dataloader)\n",
    "\n",
    "        # avg_loss_forget = total_loss_forget / len(self.forget_dataloader)\n",
    "        # avg_accuracy_forget = total_accuracy_forget / len(self.forget_dataloader)\n",
    "\n",
    "        # print(f'Epoch Retain: Avg Loss: {avg_loss_retain:.4f}, Avg Accuracy: {avg_accuracy_retain:.2f}%')\n",
    "        # print(f'Epoch Forget: Avg Loss: {avg_loss_forget:.4f}, Avg Accuracy: {avg_accuracy_forget:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SCRUBAdvancedTraining:\n",
    "    def __init__(self, teacher, student, retain_dataloader, forget_dataloader, K=4.0, LR=0.01):\n",
    "        self.teacher = teacher\n",
    "        self.student = student\n",
    "        self.retain_dataloader = retain_dataloader\n",
    "        self.forget_dataloader = forget_dataloader\n",
    "        self.LR = LR\n",
    "        self.K = K\n",
    "\n",
    "        self.criterion_cls = nn.CrossEntropyLoss()\n",
    "        self.criterion_div = DistillKL(K)\n",
    "        self.criterion_kd = DistillKL(K)\n",
    "\n",
    "        self.optimizer = optim.SGD(student.parameters(), lr=LR, momentum=0.9, weight_decay=5e-3)\n",
    "\n",
    "    def train_epoch(self):\n",
    "        self.student.train()\n",
    "        self.teacher.eval()\n",
    "\n",
    "        # Function to compute accuracy.\n",
    "        def compute_accuracy(outputs, labels):\n",
    "            _, predicted = outputs.max(1)\n",
    "            total = labels.size(0)\n",
    "            correct = predicted.eq(labels).sum().item()\n",
    "            return 100 * correct / total\n",
    "\n",
    "        total_loss_retain, total_accuracy_retain = 0, 0\n",
    "        total_loss_forget, total_accuracy_forget = 0, 0\n",
    "\n",
    "        # Training with retain data.\n",
    "        for inputs_retain, labels_retain in self.retain_dataloader:\n",
    "            inputs_retain, labels_retain = inputs_retain.cuda(), labels_retain.cuda()\n",
    "\n",
    "            iter_forget = iter(forget_loader)\n",
    "            inputs_forget, labels_forget = next(iter_forget)\n",
    "            inputs_forget, labels_forget = inputs_forget.cuda(), labels_forget.cuda()\n",
    "\n",
    "            # Forward pass: Student\n",
    "            outputs_retain_student = self.student(inputs_retain)\n",
    "            outputs_forget_student = self.student(inputs_forget)\n",
    "\n",
    "            # Forward pass: Teacher\n",
    "            with torch.no_grad():\n",
    "                outputs_retain_teacher = self.teacher(inputs_retain)\n",
    "                outputs_forget_teacher = self.teacher(inputs_forget)\n",
    "\n",
    "            # Loss computation\n",
    "            loss_cls = self.criterion_cls(outputs_retain_student, labels_retain)\n",
    "            loss_div_retain = self.criterion_div(outputs_retain_student, outputs_retain_teacher)\n",
    "            loss_div_forget = -self.criterion_div(outputs_forget_student, outputs_forget_teacher)\n",
    "\n",
    "            retain_loss = loss_cls + loss_div_retain \n",
    "            joint_loss = retain_loss + loss_div_forget\n",
    "\n",
    "            # Update total loss and accuracy for retain data.\n",
    "            total_loss_retain += retain_loss.item()\n",
    "            total_accuracy_retain += compute_accuracy(outputs_retain_student, labels_retain)\n",
    "\n",
    "            # Update total loss and accuracy for forget data.\n",
    "            total_loss_forget += loss_div_forget.item()\n",
    "            total_accuracy_forget += compute_accuracy(outputs_forget_student, labels_forget)\n",
    "\n",
    "            # Backward pass\n",
    "            self.optimizer.zero_grad()\n",
    "            joint_loss.backward()\n",
    "            nn.utils.clip_grad_value_(self.student.parameters(), 10)\n",
    "            self.optimizer.step()\n",
    "\n",
    "        # Print average loss and accuracy for the entire epoch\n",
    "        avg_loss_retain = total_loss_retain / len(self.retain_dataloader)\n",
    "        avg_accuracy_retain = total_accuracy_retain / len(self.retain_dataloader)\n",
    "\n",
    "        avg_loss_forget = total_loss_forget / len(self.retain_dataloader)\n",
    "        avg_accuracy_forget = total_accuracy_forget / len(self.retain_dataloader)\n",
    "\n",
    "        print(f'Epoch Retain: Avg Loss: {avg_loss_retain:.4f}, Avg Accuracy: {avg_accuracy_retain:.2f}%')\n",
    "        print(f'Epoch Forget: Avg Loss: {avg_loss_forget:.4f}, Avg Accuracy: {avg_accuracy_forget:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load original model\n",
    "# weights_pretrained = torch.load(local_path, map_location=DEVICE)\n",
    "# original_model = resnet18(weights=None, num_classes=10)\n",
    "# original_model.load_state_dict(weights_pretrained)\n",
    "# original_model.to(DEVICE)\n",
    "# original_model.train()\n",
    "\n",
    "# scrub_model = deepcopy(original_model)\n",
    "# scrub_model.to(DEVICE)\n",
    "# scrub_model.train()\n",
    "# unstructure_prune(net, pruning_amount=0.5, global_pruning=True, random_init=False, only_fc=False)\n",
    "# # inject_noise(net, noise_level=0.1)\n",
    "# # scrub_model.fc.reset_parameters()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# teacher = original_model\n",
    "# student = scrub_model\n",
    "\n",
    "# # Initialize and train\n",
    "# intermid_lr = rewind(student, retain_loader, forget_loader, 0.01, epochs=3)\n",
    "# inject_noise(student, noise_level=0.1)\n",
    "# student.fc.reset_parameters()\n",
    "# scrub_trainer = SCRUBTraining(teacher, student, retain_loader, forget_loader, 0.01)\n",
    "\n",
    "# num_epochs = 15\n",
    "# for epoch in range(num_epochs):\n",
    "#     scrub_trainer.train_epoch()\n",
    "#     print(f\"Epoch {epoch+1} completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate losses from unlearn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...........\n",
      "Forget acc: 0.982421875\n",
      "Test acc: 0.7702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:11<00:00, 11.65s/it]\n"
     ]
    }
   ],
   "source": [
    "X = len(os.listdir('../unlearn metric/checkpoints/'))  # number of times to run the unlearning algorithm\n",
    "unlearn_losses = [[] for _ in range(len(forget_loader.dataset))]  # List of lists to hold losses per sample index\n",
    "forget_accs = []\n",
    "test_accs = []\n",
    "retain_accs = []\n",
    "\n",
    "for i in tqdm(range(1)):\n",
    "    \n",
    "    # Load original model\n",
    "    weights_pretrained = torch.load(local_path, map_location=DEVICE)\n",
    "    teacher = resnet18(weights=None, num_classes=10)\n",
    "    try:\n",
    "        teacher.load_state_dict(weights_pretrained)\n",
    "    except:\n",
    "        teacher.load_state_dict(weights_pretrained['net'])\n",
    "    teacher.to(DEVICE)\n",
    "    teacher.train()\n",
    "\n",
    "    student = deepcopy(teacher)\n",
    "    student.to(DEVICE)\n",
    "    student.train()\n",
    "\n",
    "\n",
    "    # scrub_trainer = SCRUBAdvancedTraining(teacher, student, retain_loader, forget_loader, LR=LR_)\n",
    "\n",
    "    # for _ in range(scrubs_epochs):\n",
    "    #     scrub_trainer.train_epoch()\n",
    "\n",
    "    # Hyperparams\n",
    "    batch_size = 256\n",
    "    noise_level = 0.25\n",
    "    pruning_amount = 0\n",
    "    scrubs_lr = 1e-4\n",
    "    reset_fc = False\n",
    "    scrubs_epochs = 1\n",
    "    \n",
    "    # # Prune\n",
    "    # if pruning_amount>0:\n",
    "    #     unstructure_prune(student, pruning_amount=pruning_amount, global_pruning=True, random_init=False, only_fc=False)\n",
    "    \n",
    "    # # Unlearn\n",
    "    # if reset_fc:\n",
    "    #     student.fc.reset_parameters()\n",
    "        \n",
    "    # if noise_level>0:\n",
    "    inject_noise(student, noise_level=0.25)\n",
    "    # print(accuracy(student, retain_loader))\n",
    "    scrub_trainer = SCRUBTraining(teacher, student, retain_loader, forget_loader, LR=scrubs_lr)\n",
    "\n",
    "    for _ in range(scrubs_epochs):\n",
    "\n",
    "        scrub_trainer.train_epoch()\n",
    "        print('...........')\n",
    "        print(f'Forget acc: {accuracy(student, forget_loader)}')\n",
    "        print(f'Test acc: {accuracy(student, test_loader)}')\n",
    "\n",
    "    # inject_noise(student, noise_level=0.25)\n",
    "    # retrain_slow(student, retain_loader, 1e-4, noise_level=noise_level, epochs=1)\n",
    "\n",
    "\n",
    "    student.eval()\n",
    "    run_losses = []\n",
    "\n",
    "    for inputs, targets in forget_loader_not_shuffle:\n",
    "        inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
    "        batch_losses = calculate_loss(student, inputs, targets)\n",
    "        run_losses.extend(batch_losses)\n",
    "\n",
    "    for idx, loss in enumerate(run_losses):\n",
    "        unlearn_losses[idx].append(loss)\n",
    "\n",
    "    # Calc metrics\n",
    "    retain_accs.append(accuracy(student, retain_loader))\n",
    "    forget_accs.append(accuracy(student, forget_loader))\n",
    "    test_accs.append(accuracy(student, test_loader))\n",
    "\n",
    "    # Clean\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retain acc: 0.9887609649122807\n",
      "Forget acc: 0.98046875\n",
      "Test acc: 0.7718\n"
     ]
    }
   ],
   "source": [
    "print(f'Retain acc: {retain_accs[-1]}')\n",
    "print(f'Forget acc: {forget_accs[-1]}')\n",
    "print(f'Test acc: {test_accs[-1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(forget_accs, color='blue', label='Forget')\n",
    "plt.axvline(x=np.mean(forget_accs), color='blue')\n",
    "plt.hist(test_accs, color='red', label='Test')\n",
    "plt.axvline(x=np.mean(test_accs), color='red')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = 100\n",
    "plt.vlines(original_losses[idx], ymin=0, ymax=1, color='blue', label='Scratch')\n",
    "plt.vlines(unlearn_losses[idx], ymin=0, ymax=1, color='red', label='Unlearn')\n",
    "plt.xscale('log')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple MIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mEmpty\u001b[0m                                     Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\luis.pinto1\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:862\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    861\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 862\u001b[0m     tasks \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_ready_batches\u001b[39m.\u001b[39;49mget(block\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    863\u001b[0m \u001b[39mexcept\u001b[39;00m queue\u001b[39m.\u001b[39mEmpty:\n\u001b[0;32m    864\u001b[0m     \u001b[39m# slice the iterator n_jobs * batchsize items at a time. If the\u001b[39;00m\n\u001b[0;32m    865\u001b[0m     \u001b[39m# slice returns less than that, then the current batchsize puts\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    868\u001b[0m     \u001b[39m# accordingly to distribute evenly the last items between all\u001b[39;00m\n\u001b[0;32m    869\u001b[0m     \u001b[39m# workers.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\luis.pinto1\\AppData\\Local\\Programs\\Python\\Python310\\lib\\queue.py:168\u001b[0m, in \u001b[0;36mQueue.get\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    167\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_qsize():\n\u001b[1;32m--> 168\u001b[0m         \u001b[39mraise\u001b[39;00m Empty\n\u001b[0;32m    169\u001b[0m \u001b[39melif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mEmpty\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\luis.pinto1\\Documents\\GitHub\\machine-unlearning\\unlearn metric\\metric scrubs.ipynb Cell 32\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/luis.pinto1/Documents/GitHub/machine-unlearning/unlearn%20metric/metric%20scrubs.ipynb#X43sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m acc_scores \u001b[39m=\u001b[39m []\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/luis.pinto1/Documents/GitHub/machine-unlearning/unlearn%20metric/metric%20scrubs.ipynb#X43sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfor\u001b[39;00m idx, original_loss \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(original_losses):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/luis.pinto1/Documents/GitHub/machine-unlearning/unlearn%20metric/metric%20scrubs.ipynb#X43sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     acc_scores\u001b[39m.\u001b[39mappend(simple_mia(original_loss, unlearn_losses[idx], n_splits\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, random_state\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\u001b[39m.\u001b[39mmean())\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/luis.pinto1/Documents/GitHub/machine-unlearning/unlearn%20metric/metric%20scrubs.ipynb#X43sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m plt\u001b[39m.\u001b[39mhist(acc_scores, bins\u001b[39m=\u001b[39m\u001b[39m50\u001b[39m, log\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/luis.pinto1/Documents/GitHub/machine-unlearning/unlearn%20metric/metric%20scrubs.ipynb#X43sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m plt\u001b[39m.\u001b[39mtitle(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mSimple MIA, mean=\u001b[39m\u001b[39m{\u001b[39;00mnp\u001b[39m.\u001b[39mmean(acc_scores)\u001b[39m:\u001b[39;00m\u001b[39m.2f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m, median=\u001b[39m\u001b[39m{\u001b[39;00mnp\u001b[39m.\u001b[39mmedian(acc_scores)\u001b[39m:\u001b[39;00m\u001b[39m.2f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m);\n",
      "File \u001b[1;32mc:\\Users\\luis.pinto1\\Documents\\GitHub\\machine-unlearning\\unlearn metric\\..\\utils.py:337\u001b[0m, in \u001b[0;36msimple_mia\u001b[1;34m(test_losses, forget_losses, n_splits, random_state)\u001b[0m\n\u001b[0;32m    333\u001b[0m attack_model \u001b[39m=\u001b[39m linear_model\u001b[39m.\u001b[39mLogisticRegression()\n\u001b[0;32m    334\u001b[0m cv \u001b[39m=\u001b[39m model_selection\u001b[39m.\u001b[39mStratifiedShuffleSplit(\n\u001b[0;32m    335\u001b[0m     n_splits\u001b[39m=\u001b[39mn_splits, random_state\u001b[39m=\u001b[39mrandom_state\n\u001b[0;32m    336\u001b[0m )\n\u001b[1;32m--> 337\u001b[0m \u001b[39mreturn\u001b[39;00m model_selection\u001b[39m.\u001b[39;49mcross_val_score(\n\u001b[0;32m    338\u001b[0m     attack_model, sample_loss, members, cv\u001b[39m=\u001b[39;49mcv, scoring\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39maccuracy\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[0;32m    339\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\luis.pinto1\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:515\u001b[0m, in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[39m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[0;32m    513\u001b[0m scorer \u001b[39m=\u001b[39m check_scoring(estimator, scoring\u001b[39m=\u001b[39mscoring)\n\u001b[1;32m--> 515\u001b[0m cv_results \u001b[39m=\u001b[39m cross_validate(\n\u001b[0;32m    516\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[0;32m    517\u001b[0m     X\u001b[39m=\u001b[39;49mX,\n\u001b[0;32m    518\u001b[0m     y\u001b[39m=\u001b[39;49my,\n\u001b[0;32m    519\u001b[0m     groups\u001b[39m=\u001b[39;49mgroups,\n\u001b[0;32m    520\u001b[0m     scoring\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39mscore\u001b[39;49m\u001b[39m\"\u001b[39;49m: scorer},\n\u001b[0;32m    521\u001b[0m     cv\u001b[39m=\u001b[39;49mcv,\n\u001b[0;32m    522\u001b[0m     n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[0;32m    523\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[0;32m    524\u001b[0m     fit_params\u001b[39m=\u001b[39;49mfit_params,\n\u001b[0;32m    525\u001b[0m     pre_dispatch\u001b[39m=\u001b[39;49mpre_dispatch,\n\u001b[0;32m    526\u001b[0m     error_score\u001b[39m=\u001b[39;49merror_score,\n\u001b[0;32m    527\u001b[0m )\n\u001b[0;32m    528\u001b[0m \u001b[39mreturn\u001b[39;00m cv_results[\u001b[39m\"\u001b[39m\u001b[39mtest_score\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\luis.pinto1\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:266\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[39m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[39m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[0;32m    265\u001b[0m parallel \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39mn_jobs, verbose\u001b[39m=\u001b[39mverbose, pre_dispatch\u001b[39m=\u001b[39mpre_dispatch)\n\u001b[1;32m--> 266\u001b[0m results \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    267\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    268\u001b[0m         clone(estimator),\n\u001b[0;32m    269\u001b[0m         X,\n\u001b[0;32m    270\u001b[0m         y,\n\u001b[0;32m    271\u001b[0m         scorers,\n\u001b[0;32m    272\u001b[0m         train,\n\u001b[0;32m    273\u001b[0m         test,\n\u001b[0;32m    274\u001b[0m         verbose,\n\u001b[0;32m    275\u001b[0m         \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    276\u001b[0m         fit_params,\n\u001b[0;32m    277\u001b[0m         return_train_score\u001b[39m=\u001b[39;49mreturn_train_score,\n\u001b[0;32m    278\u001b[0m         return_times\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m    279\u001b[0m         return_estimator\u001b[39m=\u001b[39;49mreturn_estimator,\n\u001b[0;32m    280\u001b[0m         error_score\u001b[39m=\u001b[39;49merror_score,\n\u001b[0;32m    281\u001b[0m     )\n\u001b[0;32m    282\u001b[0m     \u001b[39mfor\u001b[39;49;00m train, test \u001b[39min\u001b[39;49;00m cv\u001b[39m.\u001b[39;49msplit(X, y, groups)\n\u001b[0;32m    283\u001b[0m )\n\u001b[0;32m    285\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[0;32m    287\u001b[0m \u001b[39m# For callabe scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    288\u001b[0m \u001b[39m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    289\u001b[0m \u001b[39m# the correct key.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\luis.pinto1\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:1085\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1076\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1077\u001b[0m     \u001b[39m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[0;32m   1078\u001b[0m     \u001b[39m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1082\u001b[0m     \u001b[39m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[0;32m   1083\u001b[0m     \u001b[39m# remaining jobs.\u001b[39;00m\n\u001b[0;32m   1084\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m-> 1085\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1088\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[1;32mc:\\Users\\luis.pinto1\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:873\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    870\u001b[0m n_jobs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cached_effective_n_jobs\n\u001b[0;32m    871\u001b[0m big_batch_size \u001b[39m=\u001b[39m batch_size \u001b[39m*\u001b[39m n_jobs\n\u001b[1;32m--> 873\u001b[0m islice \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39;49m(itertools\u001b[39m.\u001b[39;49mislice(iterator, big_batch_size))\n\u001b[0;32m    874\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(islice) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    875\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\luis.pinto1\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:266\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[39m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[39m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[0;32m    265\u001b[0m parallel \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39mn_jobs, verbose\u001b[39m=\u001b[39mverbose, pre_dispatch\u001b[39m=\u001b[39mpre_dispatch)\n\u001b[1;32m--> 266\u001b[0m results \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    267\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    268\u001b[0m         clone(estimator),\n\u001b[0;32m    269\u001b[0m         X,\n\u001b[0;32m    270\u001b[0m         y,\n\u001b[0;32m    271\u001b[0m         scorers,\n\u001b[0;32m    272\u001b[0m         train,\n\u001b[0;32m    273\u001b[0m         test,\n\u001b[0;32m    274\u001b[0m         verbose,\n\u001b[0;32m    275\u001b[0m         \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    276\u001b[0m         fit_params,\n\u001b[0;32m    277\u001b[0m         return_train_score\u001b[39m=\u001b[39mreturn_train_score,\n\u001b[0;32m    278\u001b[0m         return_times\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m    279\u001b[0m         return_estimator\u001b[39m=\u001b[39mreturn_estimator,\n\u001b[0;32m    280\u001b[0m         error_score\u001b[39m=\u001b[39merror_score,\n\u001b[0;32m    281\u001b[0m     )\n\u001b[0;32m    282\u001b[0m     \u001b[39mfor\u001b[39;00m train, test \u001b[39min\u001b[39;00m cv\u001b[39m.\u001b[39msplit(X, y, groups)\n\u001b[0;32m    283\u001b[0m )\n\u001b[0;32m    285\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[0;32m    287\u001b[0m \u001b[39m# For callabe scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    288\u001b[0m \u001b[39m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    289\u001b[0m \u001b[39m# the correct key.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\luis.pinto1\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1689\u001b[0m, in \u001b[0;36mBaseShuffleSplit.split\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m   1659\u001b[0m \u001b[39m\"\"\"Generate indices to split data into training and test set.\u001b[39;00m\n\u001b[0;32m   1660\u001b[0m \n\u001b[0;32m   1661\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1686\u001b[0m \u001b[39mto an integer.\u001b[39;00m\n\u001b[0;32m   1687\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1688\u001b[0m X, y, groups \u001b[39m=\u001b[39m indexable(X, y, groups)\n\u001b[1;32m-> 1689\u001b[0m \u001b[39mfor\u001b[39;00m train, test \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iter_indices(X, y, groups):\n\u001b[0;32m   1690\u001b[0m     \u001b[39myield\u001b[39;00m train, test\n",
      "File \u001b[1;32mc:\\Users\\luis.pinto1\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2078\u001b[0m, in \u001b[0;36mStratifiedShuffleSplit._iter_indices\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m   2076\u001b[0m class_counts \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mbincount(y_indices)\n\u001b[0;32m   2077\u001b[0m \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39mmin(class_counts) \u001b[39m<\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[1;32m-> 2078\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   2079\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe least populated class in y has only 1\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2080\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m member, which is too few. The minimum\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2081\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m number of groups for any class cannot\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2082\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m be less than 2.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2083\u001b[0m     )\n\u001b[0;32m   2085\u001b[0m \u001b[39mif\u001b[39;00m n_train \u001b[39m<\u001b[39m n_classes:\n\u001b[0;32m   2086\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   2087\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe train_size = \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m should be greater or \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2088\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mequal to the number of classes = \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (n_train, n_classes)\n\u001b[0;32m   2089\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2."
     ]
    }
   ],
   "source": [
    "acc_scores = []\n",
    "\n",
    "for idx, original_loss in enumerate(original_losses):\n",
    "    acc_scores.append(simple_mia(original_loss, unlearn_losses[idx], n_splits=10, random_state=0).mean())\n",
    "\n",
    "plt.hist(acc_scores, bins=50, log=True)\n",
    "plt.title(f'Simple MIA, mean={np.mean(acc_scores):.2f}, median={np.median(acc_scores):.2f}');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paper forget score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing F...: 100%|██████████| 25/25 [00:00<00:00, 92.72it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.284384765625"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = forgetting_quality(\n",
    "    unlearn_losses,\n",
    "    original_losses,\n",
    "    attacks=[tree_attack, best_threshold_attack, logistic_regression_attack],\n",
    "    delta=0.01)\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score: 0.2732452084121151\n"
     ]
    }
   ],
   "source": [
    "RA_ratio = np.mean(retain_accs) / RAR\n",
    "TA_ratio = np.mean(test_accs) / TAR\n",
    "print(f'Final score: {f * RA_ratio * TA_ratio}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "kl_losses = []\n",
    "epsilon = 1e-2\n",
    "\n",
    "for idx, original_loss in enumerate(original_losses):\n",
    "    # losses_from_scratch = np.log(np.array(original_loss)/2 + epsilon)\n",
    "    # losses_unlearn = np.log(np.array(unlearn_losses[idx]) + epsilon)\n",
    "\n",
    "    # losses_from_scratch = np.random.lognormal(mean=losses_from_scratch.mean(), sigma=losses_from_scratch.std(), size=1000)\n",
    "    # losses_unlearn = np.random.lognormal(mean=losses_unlearn.mean(), sigma=losses_unlearn.std(), size=1000)\n",
    "\n",
    "    losses_from_scratch = np.array(original_loss)\n",
    "    # losses_unlearn = np.array(unlearn_losses[idx])\n",
    "    losses_unlearn = random.sample(unlearn_losses[idx], len(losses_from_scratch))\n",
    "\n",
    "    # Ensure all losses are non-negative (they should naturally be if they are losses)\n",
    "    # assert np.all(losses_from_scratch >= 0) and np.all(losses_unlearn >= 0), \"Losses must be non-negative\"\n",
    "\n",
    "    # Normalize the losses to sum to one to represent probability distributions\n",
    "    prob_dist_scratch = losses_from_scratch / np.sum(losses_from_scratch)\n",
    "    prob_dist_unlearn = losses_unlearn / np.sum(losses_unlearn)\n",
    "\n",
    "    prob_dist_scratch += epsilon\n",
    "    prob_dist_unlearn += epsilon\n",
    "\n",
    "    # Normalize again after adding epsilon to ensure they sum to one\n",
    "    prob_dist_scratch /= np.sum(prob_dist_scratch)\n",
    "    prob_dist_unlearn /= np.sum(prob_dist_unlearn)\n",
    "\n",
    "    # Calculate the KL divergence from scratch to unlearn\n",
    "    kl_divergence = kl_div(prob_dist_scratch, prob_dist_unlearn)\n",
    "\n",
    "    # Sum over all elements to get the total divergence\n",
    "    total_kl_divergence = np.sum(kl_divergence)\n",
    "\n",
    "    kl_losses.append(total_kl_divergence)\n",
    "\n",
    "plt.hist(kl_losses, bins=100, log=True)\n",
    "plt.title(f'KL divergence, sum={np.sum(kl_losses):.2f}, median={np.median(kl_losses):.2f}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Normalize losses, calculate standard deviation, and EMD per sample\n",
    "emd_scores = []\n",
    "\n",
    "for idx, original_loss in enumerate(original_losses):\n",
    "   \n",
    "    # Calculate Earth Mover's Distance\n",
    "    emd_score = wasserstein_distance(original_loss, unlearn_losses[idx])\n",
    "    emd_scores.append(emd_score)\n",
    "\n",
    "plt.hist(emd_scores, bins=50, log=True)\n",
    "plt.title(f'EMD, sum={np.sum(emd_scores):.2f}, median={np.median(emd_scores):.2f}');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# j = 0\n",
    "# plt.hist(losses_from_scratch, color='blue', label='Trained from scratch')\n",
    "# plt.axvline(x=np.mean(losses_from_scratch), color='blue')\n",
    "# plt.hist(losses_unlearn, color='red', label='Unlearn')\n",
    "# plt.axvline(x=np.mean(losses_unlearn), color='red')\n",
    "# plt.yscale('log')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
