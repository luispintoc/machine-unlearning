{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on device: CUDA\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model, model_selection\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.nn.utils import prune\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Running on device:\", DEVICE.upper())\n",
    "\n",
    "# manual random seed is used for dataset partitioning\n",
    "# to ensure reproducible results across runs\n",
    "SEED = 42\n",
    "RNG = torch.Generator().manual_seed(SEED)\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "from utils import *\n",
    "\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "\n",
    "# Create an unverified SSL context\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./imbalanced_dataset.pkl', 'rb') as file:\n",
    "    imbalanced_aug_dataset_id = pickle.load(file)\n",
    "\n",
    "# Extract the X and Y components from the dataset\n",
    "X = [item[0] for item in imbalanced_aug_dataset_id]\n",
    "Y = [item[1] for item in imbalanced_aug_dataset_id]\n",
    "indices = [x for x in range(len(imbalanced_aug_dataset_id))]\n",
    "\n",
    "# First split: separate out the training set\n",
    "X_temp, X_train, Y_temp, Y_train, indices_temp, indices_train = train_test_split(X, Y, indices, test_size=0.6, stratify=Y, random_state=42)\n",
    "\n",
    "# Second split: separate out the validation and test sets from the temporary set\n",
    "X_val, X_test, Y_val, Y_test, indices_val, indices_test = train_test_split(X_temp, Y_temp, indices_temp, test_size=0.5, stratify=Y_temp, random_state=42)\n",
    "\n",
    "# Re-create the stratified datasets using the new indices\n",
    "train_set = list(zip(X_train, Y_train, indices_train))\n",
    "val_set = list(zip(X_val, Y_val, indices_val))\n",
    "test_set = list(zip(X_test, Y_test, indices_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SAVE:\n",
    "    np.save('./train_idx.npy',indices_train)\n",
    "    np.save('./val_idx.npy',indices_val)\n",
    "    np.save('./test_idx.npy',indices_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data_list, transform=None):\n",
    "        self.data_list = data_list\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x, y, z = self.data_list[idx]\n",
    "\n",
    "        # If x is a PIL.Image, convert it to a tensor\n",
    "        if isinstance(x, PIL.Image.Image):\n",
    "            x = transforms.ToTensor()(x)\n",
    "\n",
    "        # Apply additional transformations (like normalization)s\n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "\n",
    "        return (x, y)  # Explicitly return as tuple\n",
    "\n",
    "# download and pre-process CIFAR10\n",
    "train_normalize = transforms.Compose(\n",
    "    [\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "test_normalize = transforms.Compose(\n",
    "    [\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "train_dataset = CustomDataset(train_set, transform=train_normalize)\n",
    "val_dataset = CustomDataset(val_set, transform=test_normalize)\n",
    "test_dataset = CustomDataset(test_set, transform=test_normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, generator=RNG)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True, generator=RNG)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, generator=RNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_idx = np.load('./train_idx.npy')\n",
    "# retain_idx = np.load('./retain_idx.npy')\n",
    "# forget_idx = np.load('./forget_idx.npy')\n",
    "# val_idx = np.load('./val_idx.npy')\n",
    "# test_idx = np.load('./test_idx.npy')\n",
    "\n",
    "# train_set = torch.utils.data.Subset(imbalanced_aug_dataset_id, train_idx)\n",
    "# forget_set = torch.utils.data.Subset(imbalanced_aug_dataset_id, forget_idx)\n",
    "# retain_set = torch.utils.data.Subset(imbalanced_aug_dataset_id, retain_idx)\n",
    "# val_set = torch.utils.data.Subset(imbalanced_aug_dataset_id, val_idx)\n",
    "# test_set = torch.utils.data.Subset(imbalanced_aug_dataset_id, test_idx)\n",
    "\n",
    "# train_dataset = CustomDataset(train_set, transform=train_normalize)\n",
    "# test_dataset = CustomDataset(test_set, transform=test_normalize)\n",
    "# val_dataset = CustomDataset(val_set, transform=test_normalize)\n",
    "\n",
    "# batch_size = 16\n",
    "\n",
    "# train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)#, generator=RNG)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)#, generator=RNG)\n",
    "# val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)#, generator=RNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_targets = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for sample in train_loader:\n",
    "        # Get logits\n",
    "        targets = sample[1]\n",
    "        list_of_targets.append(np.array(targets))\n",
    "        \n",
    "train_class_weights = torch.tensor(1/np.bincount(np.concatenate(list_of_targets).ravel())).to(DEVICE, dtype=torch.float32)\n",
    "\n",
    "if SAVE:\n",
    "    np.save('./train_class_weights.npy',train_class_weights.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Epoch: 0\n",
      "Train loss: 1.5010720491409302\n",
      "Val loss: 1.560833215713501\n",
      "Train set accuracy: 56.8%\n",
      "Val set accuracy: 56.1%\n",
      "----------------------------------------\n",
      "Epoch: 1\n",
      "Train loss: 1.3116940259933472\n",
      "Val loss: 1.4157854318618774\n",
      "Train set accuracy: 69.4%\n",
      "Val set accuracy: 67.1%\n",
      "----------------------------------------\n",
      "Epoch: 2\n",
      "Train loss: 1.2313557863235474\n",
      "Val loss: 1.3987634181976318\n",
      "Train set accuracy: 71.3%\n",
      "Val set accuracy: 68.9%\n",
      "----------------------------------------\n",
      "Epoch: 3\n",
      "Train loss: 1.1009868383407593\n",
      "Val loss: 1.278664469718933\n",
      "Train set accuracy: 70.1%\n",
      "Val set accuracy: 67.4%\n",
      "----------------------------------------\n",
      "Epoch: 4\n",
      "Train loss: 1.0156947374343872\n",
      "Val loss: 1.2225165367126465\n",
      "Train set accuracy: 74.7%\n",
      "Val set accuracy: 70.5%\n",
      "----------------------------------------\n",
      "Epoch: 5\n",
      "Train loss: 0.9781247973442078\n",
      "Val loss: 1.2327420711517334\n",
      "Train set accuracy: 74.3%\n",
      "Val set accuracy: 69.9%\n",
      "----------------------------------------\n",
      "Epoch: 6\n",
      "Train loss: 0.9773625731468201\n",
      "Val loss: 1.2497479915618896\n",
      "Train set accuracy: 72.9%\n",
      "Val set accuracy: 68.2%\n",
      "----------------------------------------\n",
      "Epoch: 7\n",
      "Train loss: 0.9558240175247192\n",
      "Val loss: 1.2457159757614136\n",
      "Train set accuracy: 77.2%\n",
      "Val set accuracy: 71.4%\n",
      "----------------------------------------\n",
      "Epoch: 8\n",
      "Train loss: 0.831243634223938\n",
      "Val loss: 1.1671119928359985\n",
      "Train set accuracy: 79.3%\n",
      "Val set accuracy: 73.7%\n",
      "----------------------------------------\n",
      "Epoch: 9\n",
      "Train loss: 0.8252878785133362\n",
      "Val loss: 1.1802935600280762\n",
      "Train set accuracy: 81.9%\n",
      "Val set accuracy: 76.4%\n",
      "----------------------------------------\n",
      "Epoch: 10\n",
      "Train loss: 0.7983048558235168\n",
      "Val loss: 1.1481002569198608\n",
      "Train set accuracy: 78.8%\n",
      "Val set accuracy: 73.1%\n",
      "----------------------------------------\n",
      "Epoch: 11\n",
      "Train loss: 0.8432143926620483\n",
      "Val loss: 1.1692430973052979\n",
      "Train set accuracy: 79.8%\n",
      "Val set accuracy: 74.1%\n",
      "----------------------------------------\n",
      "Epoch: 12\n",
      "Train loss: 0.7669095396995544\n",
      "Val loss: 1.1324094533920288\n",
      "Train set accuracy: 81.5%\n",
      "Val set accuracy: 75.6%\n",
      "----------------------------------------\n",
      "Epoch: 13\n",
      "Train loss: 0.7486651539802551\n",
      "Val loss: 1.1370352506637573\n",
      "Train set accuracy: 81.2%\n",
      "Val set accuracy: 75.3%\n",
      "----------------------------------------\n",
      "Epoch: 14\n",
      "Train loss: 0.910033106803894\n",
      "Val loss: 1.3022881746292114\n",
      "Train set accuracy: 79.8%\n",
      "Val set accuracy: 74.6%\n",
      "----------------------------------------\n",
      "Epoch: 15\n",
      "Train loss: 0.7533553838729858\n",
      "Val loss: 1.1487370729446411\n",
      "Train set accuracy: 78.3%\n",
      "Val set accuracy: 71.8%\n",
      "----------------------------------------\n",
      "Epoch: 16\n",
      "Train loss: 0.8214099407196045\n",
      "Val loss: 1.2549086809158325\n",
      "Train set accuracy: 78.9%\n",
      "Val set accuracy: 72.1%\n",
      "----------------------------------------\n",
      "Epoch: 17\n",
      "Train loss: 0.467266321182251\n",
      "Val loss: 1.0847283601760864\n",
      "Train set accuracy: 89.7%\n",
      "Val set accuracy: 80.3%\n",
      "----------------------------------------\n",
      "Epoch: 18\n",
      "Train loss: 0.4908604621887207\n",
      "Val loss: 1.1287413835525513\n",
      "Train set accuracy: 88.9%\n",
      "Val set accuracy: 79.9%\n",
      "----------------------------------------\n",
      "Epoch: 19\n",
      "Train loss: 0.6289482712745667\n",
      "Val loss: 1.3467254638671875\n",
      "Train set accuracy: 85.0%\n",
      "Val set accuracy: 75.9%\n",
      "----------------------------------------\n",
      "Epoch: 20\n",
      "Train loss: 0.49739837646484375\n",
      "Val loss: 1.1670095920562744\n",
      "Train set accuracy: 87.2%\n",
      "Val set accuracy: 77.9%\n",
      "----------------------------------------\n",
      "Epoch: 21\n",
      "Train loss: 0.5012868046760559\n",
      "Val loss: 1.260473608970642\n",
      "Train set accuracy: 89.4%\n",
      "Val set accuracy: 79.1%\n",
      "----------------------------------------\n",
      "Epoch: 22\n",
      "Train loss: 0.22573751211166382\n",
      "Val loss: 1.12196683883667\n",
      "Train set accuracy: 95.2%\n",
      "Val set accuracy: 83.1%\n",
      "----------------------------------------\n",
      "Epoch: 23\n",
      "Train loss: 0.1804007589817047\n",
      "Val loss: 1.1053043603897095\n",
      "Train set accuracy: 95.8%\n",
      "Val set accuracy: 83.0%\n",
      "----------------------------------------\n",
      "Epoch: 24\n",
      "Train loss: 0.17758016288280487\n",
      "Val loss: 1.218293309211731\n",
      "Train set accuracy: 94.6%\n",
      "Val set accuracy: 81.7%\n",
      "----------------------------------------\n",
      "Epoch: 25\n",
      "Train loss: 0.1794745773077011\n",
      "Val loss: 1.1373614072799683\n",
      "Train set accuracy: 95.1%\n",
      "Val set accuracy: 82.2%\n",
      "----------------------------------------\n",
      "Epoch: 26\n",
      "Train loss: 0.10454987734556198\n",
      "Val loss: 1.1364152431488037\n",
      "Train set accuracy: 98.0%\n",
      "Val set accuracy: 84.2%\n",
      "----------------------------------------\n",
      "Epoch: 27\n",
      "Train loss: 0.10221955180168152\n",
      "Val loss: 1.0980284214019775\n",
      "Train set accuracy: 98.8%\n",
      "Val set accuracy: 84.9%\n",
      "----------------------------------------\n",
      "Epoch: 28\n",
      "Train loss: 0.07943763583898544\n",
      "Val loss: 1.1252962350845337\n",
      "Train set accuracy: 98.8%\n",
      "Val set accuracy: 84.9%\n",
      "----------------------------------------\n",
      "Epoch: 29\n",
      "Train loss: 0.078497976064682\n",
      "Val loss: 1.13827383518219\n",
      "Train set accuracy: 99.0%\n",
      "Val set accuracy: 84.6%\n"
     ]
    }
   ],
   "source": [
    "# load model with pre-trained weights\n",
    "net = resnet18(weights=None, num_classes=10)\n",
    "net.to(DEVICE);\n",
    "\n",
    "epochs = 30\n",
    "val_loss = np.inf\n",
    "\n",
    "\n",
    "current_batch = 0\n",
    "total_samples = len(train_loader.dataset)\n",
    "batch_size = train_loader.batch_size\n",
    "batches_per_epoch  = math.ceil(total_samples / batch_size)\n",
    "total_batches = epochs * batches_per_epoch\n",
    "initial_lr = 1e-4\n",
    "warmup_batches = math.ceil(10*total_batches)\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(weight=train_class_weights)\n",
    "optimizer = optim.SGD(net.parameters(), lr=initial_lr, momentum=0.90, weight_decay=5e-2)\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3)\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "train_accs = []\n",
    "val_accs = []\n",
    "\n",
    "for ep in range(epochs):\n",
    "\n",
    "    net.train()\n",
    "\n",
    "    for inputs, targets in train_loader:\n",
    "        inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
    "\n",
    "        current_batch += 1\n",
    "\n",
    "        # Warm-up for the first 'warmup_batches' batches\n",
    "        # if current_batch <= warmup_batches:\n",
    "        #     adjust_learning_rate(optimizer, current_batch, warmup_batches, initial_lr)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "\n",
    "        # nn.utils.clip_grad_value_(net.parameters(), 10)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "    net.eval()  # handle drop-out/batch norm layers\n",
    "\n",
    "    loss = 0\n",
    "    with torch.no_grad():\n",
    "        for x,y in train_loader:\n",
    "            out = net(x.to(DEVICE))  # only forward pass - NO gradients!!\n",
    "            loss += criterion(out, y.to(DEVICE))\n",
    "    # total loss - divide by number of batches\n",
    "    train_loss = loss / len(train_loader)\n",
    "    train_losses.append(train_loss)\n",
    "\n",
    "    loss = 0\n",
    "    with torch.no_grad():\n",
    "        for x,y in val_loader:\n",
    "            out = net(x.to(DEVICE))  # only forward pass - NO gradients!!\n",
    "            loss += criterion(out, y.to(DEVICE))\n",
    "    # total loss - divide by number of batches\n",
    "    val_loss = loss / len(val_loader)\n",
    "    val_losses.append(val_loss)\n",
    "\n",
    "    print('--------'*5)\n",
    "    print(f'Epoch: {ep}')\n",
    "    print(f'Train loss: {train_loss}')\n",
    "    print(f'Val loss: {val_loss}')\n",
    "    \n",
    "    net.eval()\n",
    "    train_acc = accuracy(net, train_loader)\n",
    "    train_accs.append(train_acc)\n",
    "    val_acc = accuracy(net, val_loader)\n",
    "    val_accs.append(val_acc)\n",
    "    print(f\"Train set accuracy: {100.0 * train_acc:0.1f}%\")\n",
    "    # print(f\"Forget set accuracy: {100.0 * accuracy(net, forget_loader):0.1f}%\")\n",
    "    print(f\"Val set accuracy: {100.0 * val_acc:0.1f}%\")\n",
    "    # print(f\"Test set accuracy: {100.0 * accuracy(net, test_loader):0.1f}%\")\n",
    "\n",
    "    # if temp_loss < val_loss:\n",
    "    #     val_loss = temp_loss\n",
    "    \n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if SAVE:\n",
    "torch.save({\n",
    "    'net': net.state_dict(),\n",
    "}, f'./internal_imbalanced_weights_resnet18_cifar10.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_loss(model, inputs, targets):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(inputs)\n",
    "        loss = torch.nn.CrossEntropyLoss(reduction=\"none\")(outputs, targets)\n",
    "    return loss.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_losses = []\n",
    "\n",
    "for inputs, targets in train_loader:\n",
    "    inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
    "    batch_losses = calculate_loss(net, inputs, targets)\n",
    "    original_losses.extend(batch_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_losses = []\n",
    "\n",
    "for inputs, targets in val_loader:\n",
    "    inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
    "    batch_losses = calculate_loss(net, inputs, targets)\n",
    "    val_losses.extend(batch_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.Figure(figsize=(16, 6))\n",
    "\n",
    "\n",
    "plt.hist(val_losses, density=True, alpha=0.5, bins=50, label=\"Val set\")\n",
    "plt.hist(original_losses, density=True, alpha=0.5, bins=50, label=\"Train set\")\n",
    "\n",
    "plt.xlabel(\"Loss\")\n",
    "plt.yscale(\"log\")\n",
    "# plt.xlim((0, np.max(val_losses)))\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Second split: separate out the validation and test sets from the temporary set\n",
    "# X_retain, X_forget, Y_retain, Y_forget, indices_retain, indices_forget = train_test_split(X_train, Y_train, indices_train, test_size=0.02, stratify=Y_train, random_state=42)\n",
    "\n",
    "# if SAVE:\n",
    "#     np.save('./retain_idx.npy', indices_retain)\n",
    "#     np.save('./forget_idx.npy', indices_forget)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
