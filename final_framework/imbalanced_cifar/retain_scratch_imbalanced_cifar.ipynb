{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on device: CUDA\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model, model_selection\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.nn.utils import prune\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from collections import defaultdict\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.models import resnet18\n",
    "import random\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Running on device:\", DEVICE.upper())\n",
    "\n",
    "# manual random seed is used for dataset partitioning\n",
    "# to ensure reproducible results across runs\n",
    "SEED = 42\n",
    "RNG = torch.Generator().manual_seed(SEED)\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "from utils import *\n",
    "\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import PIL\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "\n",
    "# Create an unverified SSL context\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./imbalanced_dataset.pkl', 'rb') as file:\n",
    "    imbalanced_aug_dataset_id = pickle.load(file)\n",
    "\n",
    "train_idx = np.load('./train_idx.npy')\n",
    "retain_idx = np.load('./retain_idx.npy')\n",
    "forget_idx = np.load('./forget_idx.npy')\n",
    "val_idx = np.load('./val_idx.npy')\n",
    "test_idx = np.load('./test_idx.npy')\n",
    "\n",
    "train_set = torch.utils.data.Subset(imbalanced_aug_dataset_id, train_idx)\n",
    "forget_set = torch.utils.data.Subset(train_set, forget_idx)\n",
    "retain_set = torch.utils.data.Subset(train_set, retain_idx)\n",
    "val_set = torch.utils.data.Subset(imbalanced_aug_dataset_id, val_idx)\n",
    "test_set = torch.utils.data.Subset(imbalanced_aug_dataset_id, test_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '''\n",
    "# Get retain forget indices\n",
    "# '''\n",
    "# extracted_data = []\n",
    "# for i in range(len(train_set)):\n",
    "#     dp = train_set[i]\n",
    "#     extracted_data.append(dp)\n",
    "# grouped_data = defaultdict(list)\n",
    "\n",
    "# for item in extracted_data:\n",
    "#     grouped_data[item[2]].append(item)\n",
    "# unique_item = list(grouped_data.keys())\n",
    "\n",
    "# random.shuffle(unique_item)\n",
    "\n",
    "# split_index = int(len(unique_item) * 0.98)\n",
    "# train_item_ids = set(unique_item[:split_index])\n",
    "# test_item_ids = set(unique_item[split_index:])\n",
    "# retain_indices = [i for i, item in enumerate(extracted_data) if item[2] in train_item_ids]\n",
    "# forget_indices = [i for i, item in enumerate(extracted_data) if item[2] in test_item_ids]\n",
    "# np.save('./retain_idx.npy', retain_indices)\n",
    "# np.save('./forget_idx.npy', forget_indices)\n",
    "# len(retain_indices), len(forget_indices), len(forget_indices)/len(retain_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data_list, transform=None):\n",
    "        self.data_list = data_list\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x, y, z = self.data_list[idx]\n",
    "\n",
    "        # If x is a PIL.Image, convert it to a tensor\n",
    "        if isinstance(x, PIL.Image.Image):\n",
    "            x = transforms.ToTensor()(x)\n",
    "\n",
    "        # Apply additional transformations (like normalization)s\n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "\n",
    "        return (x, y)  # Explicitly return as tuple\n",
    "\n",
    "# download and pre-process CIFAR10\n",
    "train_normalize = transforms.Compose(\n",
    "    [\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "test_normalize = transforms.Compose(\n",
    "    [\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "forget_dataset = CustomDataset(forget_set, transform=train_normalize)\n",
    "retain_dataset = CustomDataset(retain_set, transform=test_normalize)\n",
    "val_dataset = CustomDataset(val_set, transform=test_normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "\n",
    "retain_loader = DataLoader(retain_dataset, batch_size=batch_size, shuffle=True)#, generator=RNG)\n",
    "forget_loader = DataLoader(forget_dataset, batch_size=batch_size, shuffle=True)#, generator=RNG)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)#, generator=RNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_targets = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for sample in retain_loader:\n",
    "        # Get logits\n",
    "        targets = sample[1]\n",
    "        list_of_targets.append(np.array(targets))\n",
    "        \n",
    "retain_class_weights = torch.tensor(1/np.bincount(np.concatenate(list_of_targets).ravel())).to(DEVICE, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [5:18:36<00:00, 2124.01s/it]  \n"
     ]
    }
   ],
   "source": [
    "for k in tqdm(range(9)):\n",
    "\n",
    "    # load model with pre-trained weights\n",
    "    net = resnet18(weights=None, num_classes=10)\n",
    "    net.to(DEVICE);\n",
    "\n",
    "    epochs = 30\n",
    "    val_loss = np.inf\n",
    "\n",
    "\n",
    "    current_batch = 0\n",
    "    total_samples = len(retain_loader.dataset)\n",
    "    batch_size = retain_loader.batch_size\n",
    "    batches_per_epoch  = math.ceil(total_samples / batch_size)\n",
    "    total_batches = epochs * batches_per_epoch\n",
    "    initial_lr = 1e-4\n",
    "    warmup_batches = math.ceil(10*total_batches)\n",
    "\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss(weight=retain_class_weights)\n",
    "    optimizer = optim.SGD(net.parameters(), lr=initial_lr, momentum=0.90, weight_decay=5e-2)\n",
    "    # scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3)\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_accs = []\n",
    "    val_accs = []\n",
    "\n",
    "\n",
    "    for ep in range(epochs):\n",
    "\n",
    "        net.train()\n",
    "\n",
    "        for inputs, targets in retain_loader:\n",
    "            inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
    "\n",
    "            current_batch += 1\n",
    "\n",
    "            # # Warm-up for the first 'warmup_batches' batches\n",
    "            # if current_batch <= warmup_batches:\n",
    "            #     adjust_learning_rate(optimizer, current_batch, warmup_batches, initial_lr)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "\n",
    "            # nn.utils.clip_grad_value_(net.parameters(), 10)\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "        net.eval()  # handle drop-out/batch norm layers\n",
    "\n",
    "        loss = 0\n",
    "        with torch.no_grad():\n",
    "            for x,y in retain_loader:\n",
    "                out = net(x.to(DEVICE))  # only forward pass - NO gradients!!\n",
    "                loss += criterion(out, y.to(DEVICE))\n",
    "        # total loss - divide by number of batches\n",
    "        train_loss = loss / len(retain_loader)\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        loss = 0\n",
    "        with torch.no_grad():\n",
    "            for x,y in val_loader:\n",
    "                out = net(x.to(DEVICE))  # only forward pass - NO gradients!!\n",
    "                loss += criterion(out, y.to(DEVICE))\n",
    "        # total loss - divide by number of batches\n",
    "        val_loss = loss / len(val_loader)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        # print('--------'*5)\n",
    "        # print(f'Epoch: {ep}')\n",
    "        # print(f'Retain loss: {train_loss}')\n",
    "        # print(f'Val loss: {val_loss}')\n",
    "        \n",
    "        net.eval()\n",
    "        # train_acc = accuracy(net, retain_loader)\n",
    "        # train_accs.append(train_acc)\n",
    "        # val_acc = accuracy(net, val_loader)\n",
    "        # val_accs.append(val_acc)\n",
    "        # print(f\"Retain set accuracy: {100.0 * train_acc:0.1f}%\")\n",
    "        # # print(f\"Forget set accuracy: {100.0 * accuracy(net, forget_loader):0.1f}%\")\n",
    "        # print(f\"Val set accuracy: {100.0 * val_acc:0.1f}%\")\n",
    "        # # print(f\"Test set accuracy: {100.0 * accuracy(net, test_loader):0.1f}%\")\n",
    "\n",
    "        # if temp_loss < val_loss:\n",
    "        #     val_loss = temp_loss\n",
    "        \n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    torch.save({\n",
    "    'net': net.state_dict(),\n",
    "    }, f'./checkpoints/checkpoint1{k}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save({\n",
    "#     'net': net.state_dict(),\n",
    "# }, f'./checkpoints/checkpoint1.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_loss(model, inputs, targets):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(inputs)\n",
    "        loss = torch.nn.CrossEntropyLoss(reduction=\"none\")(outputs, targets)\n",
    "    return loss.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_losses = []\n",
    "\n",
    "for inputs, targets in retain_loader:\n",
    "    inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
    "    batch_losses = calculate_loss(net, inputs, targets)\n",
    "    original_losses.extend(batch_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_losses = []\n",
    "\n",
    "for inputs, targets in val_loader:\n",
    "    inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
    "    batch_losses = calculate_loss(net, inputs, targets)\n",
    "    val_losses.extend(batch_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.Figure(figsize=(16, 6))\n",
    "\n",
    "\n",
    "plt.hist(val_losses, density=True, alpha=0.5, bins=50, label=\"Val set\")\n",
    "plt.hist(original_losses, density=True, alpha=0.5, bins=50, label=\"Train set\")\n",
    "\n",
    "plt.xlabel(\"Loss\")\n",
    "plt.yscale(\"log\")\n",
    "# plt.xlim((0, np.max(val_losses)))\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
