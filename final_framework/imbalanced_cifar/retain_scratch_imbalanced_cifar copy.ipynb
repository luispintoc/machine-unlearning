{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on device: CUDA\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model, model_selection\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.nn.utils import prune\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from collections import defaultdict\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.models import resnet18\n",
    "import random\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Running on device:\", DEVICE.upper())\n",
    "\n",
    "# manual random seed is used for dataset partitioning\n",
    "# to ensure reproducible results across runs\n",
    "SEED = 42\n",
    "RNG = torch.Generator().manual_seed(SEED)\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "from utils import *\n",
    "\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import PIL\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "\n",
    "# Create an unverified SSL context\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./imbalanced_dataset.pkl', 'rb') as file:\n",
    "    imbalanced_aug_dataset_id = pickle.load(file)\n",
    "\n",
    "train_idx = np.load('./train_idx.npy')\n",
    "retain_idx = np.load('./retain_idx.npy')\n",
    "forget_idx = np.load('./forget_idx.npy')\n",
    "val_idx = np.load('./val_idx.npy')\n",
    "test_idx = np.load('./test_idx.npy')\n",
    "\n",
    "train_set = torch.utils.data.Subset(imbalanced_aug_dataset_id, train_idx)\n",
    "forget_set = torch.utils.data.Subset(train_set, forget_idx)\n",
    "retain_set = torch.utils.data.Subset(train_set, retain_idx)\n",
    "val_set = torch.utils.data.Subset(imbalanced_aug_dataset_id, val_idx)\n",
    "test_set = torch.utils.data.Subset(imbalanced_aug_dataset_id, test_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '''\n",
    "# Get retain forget indices\n",
    "# '''\n",
    "# extracted_data = []\n",
    "# for i in range(len(train_set)):\n",
    "#     dp = train_set[i]\n",
    "#     extracted_data.append(dp)\n",
    "# grouped_data = defaultdict(list)\n",
    "\n",
    "# for item in extracted_data:\n",
    "#     grouped_data[item[2]].append(item)\n",
    "# unique_item = list(grouped_data.keys())\n",
    "\n",
    "# random.shuffle(unique_item)\n",
    "\n",
    "# split_index = int(len(unique_item) * 0.98)\n",
    "# train_item_ids = set(unique_item[:split_index])\n",
    "# test_item_ids = set(unique_item[split_index:])\n",
    "# retain_indices = [i for i, item in enumerate(extracted_data) if item[2] in train_item_ids]\n",
    "# forget_indices = [i for i, item in enumerate(extracted_data) if item[2] in test_item_ids]\n",
    "# np.save('./retain_idx.npy', retain_indices)\n",
    "# np.save('./forget_idx.npy', forget_indices)\n",
    "# len(retain_indices), len(forget_indices), len(forget_indices)/len(retain_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data_list, transform=None):\n",
    "        self.data_list = data_list\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x, y, z = self.data_list[idx]\n",
    "\n",
    "        # If x is a PIL.Image, convert it to a tensor\n",
    "        if isinstance(x, PIL.Image.Image):\n",
    "            x = transforms.ToTensor()(x)\n",
    "\n",
    "        # Apply additional transformations (like normalization)s\n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "\n",
    "        return (x, y)  # Explicitly return as tuple\n",
    "\n",
    "# download and pre-process CIFAR10\n",
    "train_normalize = transforms.Compose(\n",
    "    [\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "test_normalize = transforms.Compose(\n",
    "    [\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "forget_dataset = CustomDataset(forget_set, transform=train_normalize)\n",
    "retain_dataset = CustomDataset(retain_set, transform=test_normalize)\n",
    "val_dataset = CustomDataset(val_set, transform=test_normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "\n",
    "retain_loader = DataLoader(retain_dataset, batch_size=batch_size, shuffle=True)#, generator=RNG)\n",
    "forget_loader = DataLoader(forget_dataset, batch_size=batch_size, shuffle=True)#, generator=RNG)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)#, generator=RNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_targets = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for sample in retain_loader:\n",
    "        # Get logits\n",
    "        targets = sample[1]\n",
    "        list_of_targets.append(np.array(targets))\n",
    "        \n",
    "retain_class_weights = torch.tensor(1/np.bincount(np.concatenate(list_of_targets).ravel())).to(DEVICE, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/9 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [5:20:13<00:00, 2134.80s/it]  \n"
     ]
    }
   ],
   "source": [
    "for k in tqdm(range(9)):\n",
    "\n",
    "    # load model with pre-trained weights\n",
    "    net = resnet18(weights=None, num_classes=10)\n",
    "    net.to(DEVICE);\n",
    "\n",
    "    epochs = 30\n",
    "    val_loss = np.inf\n",
    "\n",
    "\n",
    "    current_batch = 0\n",
    "    total_samples = len(retain_loader.dataset)\n",
    "    batch_size = retain_loader.batch_size\n",
    "    batches_per_epoch  = math.ceil(total_samples / batch_size)\n",
    "    total_batches = epochs * batches_per_epoch\n",
    "    initial_lr = 1e-4\n",
    "    warmup_batches = math.ceil(10*total_batches)\n",
    "\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss(weight=retain_class_weights)\n",
    "    optimizer = optim.SGD(net.parameters(), lr=initial_lr, momentum=0.90, weight_decay=5e-2)\n",
    "    # scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3)\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_accs = []\n",
    "    val_accs = []\n",
    "\n",
    "\n",
    "    for ep in range(epochs):\n",
    "\n",
    "        net.train()\n",
    "\n",
    "        for inputs, targets in retain_loader:\n",
    "            inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
    "\n",
    "            current_batch += 1\n",
    "\n",
    "            # # Warm-up for the first 'warmup_batches' batches\n",
    "            # if current_batch <= warmup_batches:\n",
    "            #     adjust_learning_rate(optimizer, current_batch, warmup_batches, initial_lr)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "\n",
    "            # nn.utils.clip_grad_value_(net.parameters(), 10)\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "        net.eval()  # handle drop-out/batch norm layers\n",
    "\n",
    "        loss = 0\n",
    "        with torch.no_grad():\n",
    "            for x,y in retain_loader:\n",
    "                out = net(x.to(DEVICE))  # only forward pass - NO gradients!!\n",
    "                loss += criterion(out, y.to(DEVICE))\n",
    "        # total loss - divide by number of batches\n",
    "        train_loss = loss / len(retain_loader)\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        loss = 0\n",
    "        with torch.no_grad():\n",
    "            for x,y in val_loader:\n",
    "                out = net(x.to(DEVICE))  # only forward pass - NO gradients!!\n",
    "                loss += criterion(out, y.to(DEVICE))\n",
    "        # total loss - divide by number of batches\n",
    "        val_loss = loss / len(val_loader)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        # print('--------'*5)\n",
    "        # print(f'Epoch: {ep}')\n",
    "        # print(f'Retain loss: {train_loss}')\n",
    "        # print(f'Val loss: {val_loss}')\n",
    "        \n",
    "        net.eval()\n",
    "        # train_acc = accuracy(net, retain_loader)\n",
    "        # train_accs.append(train_acc)\n",
    "        # val_acc = accuracy(net, val_loader)\n",
    "        # val_accs.append(val_acc)\n",
    "        # print(f\"Retain set accuracy: {100.0 * train_acc:0.1f}%\")\n",
    "        # # print(f\"Forget set accuracy: {100.0 * accuracy(net, forget_loader):0.1f}%\")\n",
    "        # print(f\"Val set accuracy: {100.0 * val_acc:0.1f}%\")\n",
    "        # # print(f\"Test set accuracy: {100.0 * accuracy(net, test_loader):0.1f}%\")\n",
    "\n",
    "        # if temp_loss < val_loss:\n",
    "        #     val_loss = temp_loss\n",
    "        \n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    torch.save({\n",
    "    'net': net.state_dict(),\n",
    "    }, f'./checkpoints/checkpoint3{k}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save({\n",
    "#     'net': net.state_dict(),\n",
    "# }, f'./checkpoints/checkpoint1.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_loss(model, inputs, targets):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(inputs)\n",
    "        loss = torch.nn.CrossEntropyLoss(reduction=\"none\")(outputs, targets)\n",
    "    return loss.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_losses = []\n",
    "\n",
    "for inputs, targets in retain_loader:\n",
    "    inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
    "    batch_losses = calculate_loss(net, inputs, targets)\n",
    "    original_losses.extend(batch_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_losses = []\n",
    "\n",
    "for inputs, targets in val_loader:\n",
    "    inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
    "    batch_losses = calculate_loss(net, inputs, targets)\n",
    "    val_losses.extend(batch_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.Figure(figsize=(16, 6))\n",
    "\n",
    "\n",
    "plt.hist(val_losses, density=True, alpha=0.5, bins=50, label=\"Val set\")\n",
    "plt.hist(original_losses, density=True, alpha=0.5, bins=50, label=\"Train set\")\n",
    "\n",
    "plt.xlabel(\"Loss\")\n",
    "plt.yscale(\"log\")\n",
    "# plt.xlim((0, np.max(val_losses)))\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
