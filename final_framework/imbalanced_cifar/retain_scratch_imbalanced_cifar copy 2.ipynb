{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on device: CUDA\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model, model_selection\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.nn.utils import prune\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from collections import defaultdict\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.models import resnet18\n",
    "import random\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Running on device:\", DEVICE.upper())\n",
    "\n",
    "# manual random seed is used for dataset partitioning\n",
    "# to ensure reproducible results across runs\n",
    "SEED = 42\n",
    "RNG = torch.Generator().manual_seed(SEED)\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "from utils import *\n",
    "\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import PIL\n",
    "from tqdm import tqdm\n",
    "from torch.optim.lr_scheduler import _LRScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "\n",
    "# Create an unverified SSL context\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./imbalanced_dataset.pkl', 'rb') as file:\n",
    "    imbalanced_aug_dataset_id = pickle.load(file)\n",
    "\n",
    "train_idx = np.load('./train_idx.npy')\n",
    "retain_idx = np.load('./retain_idx.npy')\n",
    "forget_idx = np.load('./forget_idx.npy')\n",
    "val_idx = np.load('./val_idx.npy')\n",
    "test_idx = np.load('./test_idx.npy')\n",
    "\n",
    "train_set = torch.utils.data.Subset(imbalanced_aug_dataset_id, train_idx)\n",
    "forget_set = torch.utils.data.Subset(train_set, forget_idx)\n",
    "retain_set = torch.utils.data.Subset(train_set, retain_idx)\n",
    "val_set = torch.utils.data.Subset(imbalanced_aug_dataset_id, val_idx)\n",
    "test_set = torch.utils.data.Subset(imbalanced_aug_dataset_id, test_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '''\n",
    "# Get retain forget indices\n",
    "# '''\n",
    "# extracted_data = []\n",
    "# for i in range(len(train_set)):\n",
    "#     dp = train_set[i]\n",
    "#     extracted_data.append(dp)\n",
    "# grouped_data = defaultdict(list)\n",
    "\n",
    "# for item in extracted_data:\n",
    "#     grouped_data[item[2]].append(item)\n",
    "# unique_item = list(grouped_data.keys())\n",
    "\n",
    "# random.shuffle(unique_item)\n",
    "\n",
    "# split_index = int(len(unique_item) * 0.98)\n",
    "# train_item_ids = set(unique_item[:split_index])\n",
    "# test_item_ids = set(unique_item[split_index:])\n",
    "# retain_indices = [i for i, item in enumerate(extracted_data) if item[2] in train_item_ids]\n",
    "# forget_indices = [i for i, item in enumerate(extracted_data) if item[2] in test_item_ids]\n",
    "# np.save('./retain_idx.npy', retain_indices)\n",
    "# np.save('./forget_idx.npy', forget_indices)\n",
    "# len(retain_indices), len(forget_indices), len(forget_indices)/len(retain_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data_list, transform=None):\n",
    "        self.data_list = data_list\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x, y, z = self.data_list[idx]\n",
    "\n",
    "        # If x is a PIL.Image, convert it to a tensor\n",
    "        if isinstance(x, PIL.Image.Image):\n",
    "            x = transforms.ToTensor()(x)\n",
    "\n",
    "        # Apply additional transformations (like normalization)s\n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "\n",
    "        return (x, y)  # Explicitly return as tuple\n",
    "\n",
    "# download and pre-process CIFAR10\n",
    "train_normalize = transforms.Compose(\n",
    "    [\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "test_normalize = transforms.Compose(\n",
    "    [\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "forget_dataset = CustomDataset(forget_set, transform=train_normalize)\n",
    "retain_dataset = CustomDataset(retain_set, transform=test_normalize)\n",
    "val_dataset = CustomDataset(val_set, transform=test_normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "\n",
    "retain_loader = DataLoader(retain_dataset, batch_size=batch_size, shuffle=True)#, generator=RNG)\n",
    "forget_loader = DataLoader(forget_dataset, batch_size=batch_size, shuffle=True)#, generator=RNG)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)#, generator=RNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_targets = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for sample in retain_loader:\n",
    "        # Get logits\n",
    "        targets = sample[1]\n",
    "        list_of_targets.append(np.array(targets))\n",
    "        \n",
    "retain_class_weights = torch.tensor(1/np.bincount(np.concatenate(list_of_targets).ravel())).to(DEVICE, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [5:29:14<00:00, 2194.94s/it]  \n"
     ]
    }
   ],
   "source": [
    "for k in tqdm(range(9)):\n",
    "\n",
    "    # load model with pre-trained weights\n",
    "    net = resnet18(weights=None, num_classes=10)\n",
    "    net.to(DEVICE);\n",
    "\n",
    "    epochs = 30\n",
    "    val_loss = np.inf\n",
    "\n",
    "\n",
    "    current_batch = 0\n",
    "    total_samples = len(retain_loader.dataset)\n",
    "    batch_size = retain_loader.batch_size\n",
    "    batches_per_epoch  = math.ceil(total_samples / batch_size)\n",
    "    total_batches = epochs * batches_per_epoch\n",
    "    initial_lr = 1e-4\n",
    "    warmup_batches = math.ceil(10*total_batches)\n",
    "\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss(weight=retain_class_weights)\n",
    "    optimizer = optim.SGD(net.parameters(), lr=initial_lr, momentum=0.90, weight_decay=5e-2)\n",
    "    # scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3)\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_accs = []\n",
    "    val_accs = []\n",
    "\n",
    "\n",
    "    for ep in range(epochs):\n",
    "\n",
    "        net.train()\n",
    "\n",
    "        for inputs, targets in retain_loader:\n",
    "            inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
    "\n",
    "            current_batch += 1\n",
    "\n",
    "            # # Warm-up for the first 'warmup_batches' batches\n",
    "            # if current_batch <= warmup_batches:\n",
    "            #     adjust_learning_rate(optimizer, current_batch, warmup_batches, initial_lr)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "\n",
    "            # nn.utils.clip_grad_value_(net.parameters(), 10)\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "        net.eval()  # handle drop-out/batch norm layers\n",
    "\n",
    "        loss = 0\n",
    "        with torch.no_grad():\n",
    "            for x,y in retain_loader:\n",
    "                out = net(x.to(DEVICE))  # only forward pass - NO gradients!!\n",
    "                loss += criterion(out, y.to(DEVICE))\n",
    "        # total loss - divide by number of batches\n",
    "        train_loss = loss / len(retain_loader)\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        loss = 0\n",
    "        with torch.no_grad():\n",
    "            for x,y in val_loader:\n",
    "                out = net(x.to(DEVICE))  # only forward pass - NO gradients!!\n",
    "                loss += criterion(out, y.to(DEVICE))\n",
    "        # total loss - divide by number of batches\n",
    "        val_loss = loss / len(val_loader)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        # print('--------'*5)\n",
    "        # print(f'Epoch: {ep}')\n",
    "        # print(f'Retain loss: {train_loss}')\n",
    "        # print(f'Val loss: {val_loss}')\n",
    "        \n",
    "        net.eval()\n",
    "        # train_acc = accuracy(net, retain_loader)\n",
    "        # train_accs.append(train_acc)\n",
    "        # val_acc = accuracy(net, val_loader)\n",
    "        # val_accs.append(val_acc)\n",
    "        # print(f\"Retain set accuracy: {100.0 * train_acc:0.1f}%\")\n",
    "        # # print(f\"Forget set accuracy: {100.0 * accuracy(net, forget_loader):0.1f}%\")\n",
    "        # print(f\"Val set accuracy: {100.0 * val_acc:0.1f}%\")\n",
    "        # # print(f\"Test set accuracy: {100.0 * accuracy(net, test_loader):0.1f}%\")\n",
    "\n",
    "        # if temp_loss < val_loss:\n",
    "        #     val_loss = temp_loss\n",
    "        \n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    torch.save({\n",
    "    'net': net.state_dict(),\n",
    "    }, f'./checkpoints/checkpoint2{k}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save({\n",
    "#     'net': net.state_dict(),\n",
    "# }, f'./checkpoints/checkpoint1.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_loss(model, inputs, targets):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(inputs)\n",
    "        loss = torch.nn.CrossEntropyLoss(reduction=\"none\")(outputs, targets)\n",
    "    return loss.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_losses = []\n",
    "\n",
    "for inputs, targets in retain_loader:\n",
    "    inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
    "    batch_losses = calculate_loss(net, inputs, targets)\n",
    "    original_losses.extend(batch_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_losses = []\n",
    "\n",
    "for inputs, targets in val_loader:\n",
    "    inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
    "    batch_losses = calculate_loss(net, inputs, targets)\n",
    "    val_losses.extend(batch_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.Figure(figsize=(16, 6))\n",
    "\n",
    "\n",
    "plt.hist(val_losses, density=True, alpha=0.5, bins=50, label=\"Val set\")\n",
    "plt.hist(original_losses, density=True, alpha=0.5, bins=50, label=\"Train set\")\n",
    "\n",
    "plt.xlabel(\"Loss\")\n",
    "plt.yscale(\"log\")\n",
    "# plt.xlim((0, np.max(val_losses)))\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
