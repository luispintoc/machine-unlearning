{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on device: CUDA\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1b94b718b70>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model, model_selection\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.nn.utils import prune\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Running on device:\", DEVICE.upper())\n",
    "\n",
    "# manual random seed is used for dataset partitioning\n",
    "# to ensure reproducible results across runs\n",
    "SEED = 42\n",
    "RNG = torch.Generator().manual_seed(SEED)\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "\n",
    "# Create an unverified SSL context\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download and pre-process CIFAR10\n",
    "normalize = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "train_set = torchvision.datasets.CIFAR10(\n",
    "    root=\"../example notebooks/data\", train=True, download=False, transform=normalize\n",
    ")\n",
    "train_loader = DataLoader(train_set, batch_size=128, shuffle=True, num_workers=1)\n",
    "\n",
    "# we split held out data into test and validation set\n",
    "held_out = torchvision.datasets.CIFAR10(\n",
    "    root=\"../example notebooks/data\", train=False, download=False, transform=normalize\n",
    ")\n",
    "test_set, val_set = torch.utils.data.random_split(held_out, [0.5, 0.5], generator=RNG)\n",
    "test_loader = DataLoader(test_set, batch_size=128, shuffle=False, num_workers=1)\n",
    "val_loader = DataLoader(val_set, batch_size=128, shuffle=False, num_workers=1)\n",
    "\n",
    "# download the forget and retain index split\n",
    "local_path = \"../example notebooks/forget_idx.npy\"\n",
    "# if not os.path.exists(local_path):\n",
    "#     response = requests.get(\n",
    "#         \"https://storage.googleapis.com/unlearning-challenge/\" + local_path\n",
    "#     )\n",
    "#     open(local_path, \"wb\").write(response.content)\n",
    "forget_idx = np.load(local_path)\n",
    "\n",
    "# construct indices of retain from those of the forget set\n",
    "forget_mask = np.zeros(len(train_set.targets), dtype=bool)\n",
    "forget_mask[forget_idx] = True\n",
    "retain_idx = np.arange(forget_mask.size)[~forget_mask]\n",
    "\n",
    "# split train set into a forget and a retain set\n",
    "forget_set = torch.utils.data.Subset(train_set, forget_idx)\n",
    "retain_set = torch.utils.data.Subset(train_set, retain_idx)\n",
    "\n",
    "forget_loader = torch.utils.data.DataLoader(\n",
    "    forget_set, batch_size=128, shuffle=False, num_workers=1\n",
    ")\n",
    "# retain_loader = torch.utils.data.DataLoader(\n",
    "#     retain_set, batch_size=128, shuffle=True, num_workers=1, generator=RNG\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "retain_loader = torch.utils.data.DataLoader(\n",
    "    retain_set, batch_size=128, shuffle=False, num_workers=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_path = \"../example notebooks/weights/weights_resnet18_cifar10.pth\"\n",
    "if not os.path.exists(local_path):\n",
    "    response = requests.get(\n",
    "        \"https://storage.googleapis.com/unlearning-challenge/weights_resnet18_cifar10.pth\"\n",
    "    )\n",
    "    open(local_path, \"wb\").write(response.content)\n",
    "\n",
    "weights_pretrained = torch.load(local_path, map_location=DEVICE) #43Mbs\n",
    "\n",
    "# load model with pre-trained weights\n",
    "model = resnet18(weights=None, num_classes=10)\n",
    "model.load_state_dict(weights_pretrained)\n",
    "model.to(DEVICE)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(net, loader):\n",
    "    \"\"\"Return accuracy on a dataset given by the data loader.\"\"\"\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for inputs, targets in loader:\n",
    "        inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
    "        outputs = net(inputs)\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unstructure_prune(model, pruning_amount=0.2, global_pruning=False, random_init=False):\n",
    "\n",
    "    parameters_to_prune = []\n",
    "    if global_pruning:\n",
    "        for name, module in model.named_modules():\n",
    "            if isinstance(module, torch.nn.Conv2d) or isinstance(module, torch.nn.Linear):\n",
    "                parameters_to_prune.append((module, 'weight'))\n",
    "\n",
    "        #Global pruning\n",
    "        prune.global_unstructured(\n",
    "            parameters_to_prune,\n",
    "            pruning_method=prune.L1Unstructured,\n",
    "            amount=pruning_amount\n",
    "        )\n",
    "\n",
    "    else:\n",
    "         for name, module in model.named_modules():\n",
    "            if isinstance(module, torch.nn.Conv2d) or isinstance(module, torch.nn.Linear):\n",
    "                prune.l1_unstructured(module, name='weight', amount=pruning_amount)\n",
    "                parameters_to_prune.append((module, 'weight'))\n",
    "                \n",
    "\n",
    "    # Randomly re-initialize pruned weights while preserving the mask\n",
    "    for module, param_name in parameters_to_prune:\n",
    "        if random_init:\n",
    "            mask = getattr(module, f\"{param_name}_mask\")  # Get the binary mask used for pruning\n",
    "            init_weights = getattr(module, param_name)  # Get the current weights\n",
    "            # Randomly initialize new weights\n",
    "            new_weights = torch.randn_like(init_weights)\n",
    "            # Apply the pruning mask to keep the pruned weights zero\n",
    "            new_weights = new_weights * mask\n",
    "            # Assign the new weights\n",
    "            setattr(module, param_name, torch.nn.Parameter(new_weights))\n",
    "        # Make the pruning permanent by removing the mask\n",
    "        prune.remove(module, param_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_teacher_student_outputs(teacher_logits, student_logits):\n",
    "    teacher_probs = torch.nn.functional.softmax(teacher_logits, dim=0).cpu().numpy()\n",
    "    student_probs = torch.nn.functional.softmax(student_logits, dim=0).cpu().numpy()\n",
    "    plt.plot(teacher_probs, 'ko', label='teacher')\n",
    "    plt.plot(student_probs, 'ro', label='student')\n",
    "    plt.legend()\n",
    "    plt.yscale('log')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_losses(net, loader):\n",
    "    \"\"\"Auxiliary function to compute per-sample losses\"\"\"\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss(reduction=\"none\")\n",
    "    all_losses = []\n",
    "\n",
    "    for inputs, targets in loader:\n",
    "        inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
    "\n",
    "        logits = net(inputs)\n",
    "        losses = criterion(logits, targets).numpy(force=True)\n",
    "        for l in losses:\n",
    "            all_losses.append(l)\n",
    "\n",
    "    return np.array(all_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_mia(sample_loss, members, n_splits=10, random_state=0):\n",
    "    \"\"\"Computes cross-validation score of a membership inference attack.\n",
    "\n",
    "    Args:\n",
    "      sample_loss : array_like of shape (n,).\n",
    "        objective function evaluated on n samples.\n",
    "      members : array_like of shape (n,),\n",
    "        whether a sample was used for training.\n",
    "      n_splits: int\n",
    "        number of splits to use in the cross-validation.\n",
    "    Returns:\n",
    "      scores : array_like of size (n_splits,)\n",
    "    \"\"\"\n",
    "\n",
    "    unique_members = np.unique(members)\n",
    "    if not np.all(unique_members == np.array([0, 1])):\n",
    "        raise ValueError(\"members should only have 0 and 1s\")\n",
    "\n",
    "    attack_model = linear_model.LogisticRegression()\n",
    "    cv = model_selection.StratifiedShuffleSplit(\n",
    "        n_splits=n_splits, random_state=random_state\n",
    "    )\n",
    "    return model_selection.cross_val_score(\n",
    "        attack_model, sample_loss, members, cv=cv, scoring=\"accuracy\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_mia_acc(forget_loss, test_loss):\n",
    "    # make sure we have a balanced dataset for the MIA\n",
    "    assert len(test_loss) == len(forget_loss)\n",
    "\n",
    "    ft_samples_mia = np.concatenate((test_loss, forget_loss)).reshape((-1, 1))\n",
    "    labels_mia = [0] * len(test_loss) + [1] * len(forget_loss)\n",
    "\n",
    "    ft_mia_scores = simple_mia(ft_samples_mia, labels_mia)\n",
    "\n",
    "    return ft_mia_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_metrics(test_losses, student_model, retain_loader, forget_loader, val_loader, test_loader):\n",
    "    \n",
    "    print(f\"Retain set accuracy: {100.0 * accuracy(student_model, retain_loader):0.1f}%\")\n",
    "    print(f\"Forget set accuracy: {100.0 * accuracy(student_model, forget_loader):0.1f}%\")\n",
    "    print(f\"Val set accuracy: {100.0 * accuracy(student_model, val_loader):0.1f}%\")\n",
    "    print(f\"Test set accuracy: {100.0 * accuracy(student_model, test_loader):0.1f}%\")\n",
    "\n",
    "    ft_forget_losses = compute_losses(student_model, forget_loader)\n",
    "    # ft_test_losses = compute_losses(model, test_loader)\n",
    "\n",
    "    ft_mia_scores = calc_mia_acc(ft_forget_losses, test_losses)\n",
    "\n",
    "    print(\n",
    "        f\"The MIA has an accuracy of {ft_mia_scores.mean():.3f} on forgotten vs unseen images\"\n",
    "    )\n",
    "\n",
    "    return ft_forget_losses, test_losses, ft_mia_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retain set accuracy: 99.5%\n",
      "Forget set accuracy: 99.3%\n",
      "Val set accuracy: 88.9%\n",
      "Test set accuracy: 88.3%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Retain set accuracy: {100.0 * accuracy(model, retain_loader):0.1f}%\")\n",
    "print(f\"Forget set accuracy: {100.0 * accuracy(model, forget_loader):0.1f}%\")\n",
    "print(f\"Val set accuracy: {100.0 * accuracy(model, val_loader):0.1f}%\")\n",
    "print(f\"Test set accuracy: {100.0 * accuracy(model, test_loader):0.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_losses = compute_losses(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_gradient_from_loader(model, optimizer, loader, num_batches):\n",
    "    last_linear_layer = model.fc\n",
    "    avg_grad = None\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    count = 0\n",
    "    for i, (data, target) in enumerate(loader):\n",
    "        if i >= num_batches:\n",
    "            break\n",
    "        data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        if avg_grad is None:\n",
    "            avg_grad = last_linear_layer.weight.grad.clone()\n",
    "        else:\n",
    "            avg_grad += last_linear_layer.weight.grad.clone()\n",
    "\n",
    "        count +=1\n",
    "\n",
    "        return avg_grad / count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only re-train last layer\n",
    "for name, param in model.named_parameters():\n",
    "    if name=='fc.weight':\n",
    "        param.requires_grad = True\n",
    "    else:\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(20, 30, 2):\n",
    "\n",
    "    print('---'*5)\n",
    "    print(x/100)\n",
    "\n",
    "    model = resnet18(weights=None, num_classes=10)\n",
    "    model.load_state_dict(weights_pretrained)\n",
    "    model.to(DEVICE)\n",
    "\n",
    "    optimizer = optim.SGD(model.parameters(), lr=1e-4, momentum=0.9, weight_decay=5e-4)\n",
    "\n",
    "    num_batches = len(forget_loader.dataset)\n",
    "\n",
    "    grad1 = average_gradient_from_loader(model, optimizer, retain_loader, num_batches)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    grad2 = average_gradient_from_loader(model, optimizer, forget_loader, num_batches)\n",
    "\n",
    "    grad_diff = torch.abs(grad1 - grad2)\n",
    "\n",
    "    _, indices = torch.sort(grad_diff, descending=True)\n",
    "\n",
    "    top_x_percent = int(x/100 * len(indices))\n",
    "\n",
    "    for idx in indices[:top_x_percent]:\n",
    "        for class_idx in range(0,10):\n",
    "            model.fc.weight.data[class_idx, idx] = torch.randn_like(model.fc.weight.data[class_idx, idx])\n",
    "\n",
    "    get_all_metrics(test_losses, model, retain_loader, forget_loader, val_loader, test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
